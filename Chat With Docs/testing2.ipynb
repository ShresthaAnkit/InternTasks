{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import numpy as np\n",
    "import cohere\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pages(input_pdf, output_pdf, pages_to_extract):\n",
    "    # Create a PDF reader and writer\n",
    "    reader = PdfReader(input_pdf)\n",
    "    writer = PdfWriter()\n",
    "    \n",
    "    # Extract the specified pages\n",
    "    for page_num in pages_to_extract:\n",
    "        writer.add_page(reader.pages[page_num])\n",
    "\n",
    "    # Write the extracted pages to a new PDF\n",
    "    with open(output_pdf, 'wb') as output_file:\n",
    "        writer.write(output_file)\n",
    "\n",
    "    print(f\"New PDF created: {output_pdf}\")\n",
    "\n",
    "\n",
    "# input_pdf = r'D:\\Programming\\AI\\Basics\\AMNIL Tech\\Chat With Docs\\energy.pdf' \n",
    "# output_pdf = 'sample.pdf'       \n",
    "# pages_to_extract = [0,1]           \n",
    "\n",
    "# extract_pages(input_pdf, output_pdf, pages_to_extract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'sir_doc_file.pdf'\n",
    "reader = PdfReader(pdf_path)\n",
    "page = reader.pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyPDF2._page._VirtualList at 0x11cec28da50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = []\n",
    "text_body = []\n",
    "text = ''\n",
    "def visitor_body(text, cm, tm, fontDict, fontSize):\n",
    "    y = tm[5]        \n",
    "    if y > 50 and y < 800:\n",
    "        #print(f\"Text: {repr(text)}, Font Size: {fontSize}\")\n",
    "        parts.append(text)\n",
    "for page in reader.pages:\n",
    "    page.extract_text(visitor_text=visitor_body)\n",
    "    text_body.append(''.join(parts))\n",
    "text = ''.join(text_body)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_sentence(text, max_length):\n",
    "    # Regular expression to match sentence-ending punctuation: . ? !\n",
    "    sentence_endings = re.compile(r'([.!?])')\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Split the text into sentences based on the sentence-ending punctuation\n",
    "    sentences = sentence_endings.split(text)\n",
    "    \n",
    "    # Recombine punctuation with the sentences\n",
    "    sentences = [sentences[i] + (sentences[i+1] if i+1 < len(sentences) else '') for i in range(0, len(sentences), 2)]\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # If adding the sentence exceeds max_length, start a new chunk\n",
    "        if len(current_chunk) + len(sentence) > max_length:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk)\n",
    "            current_chunk = sentence.strip()\n",
    "        else:\n",
    "            current_chunk += sentence  # Add the sentence to the current chunk\n",
    "\n",
    "    if current_chunk:  # Append the last chunk\n",
    "        chunks.append(current_chunk)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc. New York, NY, USADhagash Mehta dhagash.mehta@blackrock.\n",
      "\n",
      "Chunk 2:\n",
      "com BlackRock, Inc.\n",
      "\n",
      "Chunk 3:\n",
      "New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.\n",
      "\n",
      "Chunk 4:\n",
      "We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.\n",
      "\n",
      "Chunk 5:\n",
      "Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.\n",
      "\n",
      "Chunk 6:\n",
      "The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.\n",
      "\n",
      "Chunk 7:\n",
      "However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.\n",
      "\n",
      "Chunk 8:\n",
      "Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].\n",
      "\n",
      "Chunk 9:\n",
      "Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.\n",
      "\n",
      "Chunk 10:\n",
      "In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.\n",
      "\n",
      "Chunk 11:\n",
      "Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.\n",
      "\n",
      "Chunk 12:\n",
      "VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.\n",
      "\n",
      "Chunk 13:\n",
      "For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].\n",
      "\n",
      "Chunk 14:\n",
      "Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.\n",
      "\n",
      "Chunk 15:\n",
      "Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.\n",
      "\n",
      "Chunk 16:\n",
      "com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc. New York, NY, USADhagash Mehta dhagash.mehta@blackrock.com BlackRock, Inc.\n",
      "\n",
      "Chunk 17:\n",
      "New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.\n",
      "\n",
      "Chunk 18:\n",
      "We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.\n",
      "\n",
      "Chunk 19:\n",
      "Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.\n",
      "\n",
      "Chunk 20:\n",
      "The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.\n",
      "\n",
      "Chunk 21:\n",
      "However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.\n",
      "\n",
      "Chunk 22:\n",
      "Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].\n",
      "\n",
      "Chunk 23:\n",
      "Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.\n",
      "\n",
      "Chunk 24:\n",
      "In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.\n",
      "\n",
      "Chunk 25:\n",
      "Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.\n",
      "\n",
      "Chunk 26:\n",
      "VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.\n",
      "\n",
      "Chunk 27:\n",
      "For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].\n",
      "\n",
      "Chunk 28:\n",
      "Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.\n",
      "\n",
      "Chunk 29:\n",
      "Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.\n",
      "\n",
      "Chunk 30:\n",
      "KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.\n",
      "\n",
      "Chunk 31:\n",
      "However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].\n",
      "\n",
      "Chunk 32:\n",
      "Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.\n",
      "\n",
      "Chunk 33:\n",
      "However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.\n",
      "\n",
      "Chunk 34:\n",
      "By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.\n",
      "\n",
      "Chunk 35:\n",
      "In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.\n",
      "\n",
      "Chunk 36:\n",
      "1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].\n",
      "\n",
      "Chunk 37:\n",
      "Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.\n",
      "\n",
      "Chunk 38:\n",
      "We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.\n",
      "\n",
      "Chunk 39:\n",
      "2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.\n",
      "\n",
      "Chunk 40:\n",
      "This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.\n",
      "\n",
      "Chunk 41:\n",
      "This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.\n",
      "\n",
      "Chunk 42:\n",
      "In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.\n",
      "\n",
      "Chunk 43:\n",
      "The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.\n",
      "\n",
      "Chunk 44:\n",
      "The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.\n",
      "\n",
      "Chunk 45:\n",
      ", a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.\n",
      "\n",
      "Chunk 46:\n",
      "htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc. New York, NY, USADhagash Mehta dhagash.mehta@blackrock.\n",
      "\n",
      "Chunk 47:\n",
      "com BlackRock, Inc.\n",
      "\n",
      "Chunk 48:\n",
      "New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.\n",
      "\n",
      "Chunk 49:\n",
      "We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.\n",
      "\n",
      "Chunk 50:\n",
      "Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.\n",
      "\n",
      "Chunk 51:\n",
      "The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.\n",
      "\n",
      "Chunk 52:\n",
      "However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.\n",
      "\n",
      "Chunk 53:\n",
      "Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].\n",
      "\n",
      "Chunk 54:\n",
      "Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.\n",
      "\n",
      "Chunk 55:\n",
      "In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.\n",
      "\n",
      "Chunk 56:\n",
      "Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.\n",
      "\n",
      "Chunk 57:\n",
      "VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.\n",
      "\n",
      "Chunk 58:\n",
      "For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].\n",
      "\n",
      "Chunk 59:\n",
      "Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.\n",
      "\n",
      "Chunk 60:\n",
      "Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.\n",
      "\n",
      "Chunk 61:\n",
      "KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.\n",
      "\n",
      "Chunk 62:\n",
      "However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].\n",
      "\n",
      "Chunk 63:\n",
      "Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.\n",
      "\n",
      "Chunk 64:\n",
      "However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.\n",
      "\n",
      "Chunk 65:\n",
      "By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.\n",
      "\n",
      "Chunk 66:\n",
      "In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.\n",
      "\n",
      "Chunk 67:\n",
      "1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].\n",
      "\n",
      "Chunk 68:\n",
      "Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.\n",
      "\n",
      "Chunk 69:\n",
      "We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.\n",
      "\n",
      "Chunk 70:\n",
      "2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.\n",
      "\n",
      "Chunk 71:\n",
      "This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.\n",
      "\n",
      "Chunk 72:\n",
      "This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.\n",
      "\n",
      "Chunk 73:\n",
      "In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.\n",
      "\n",
      "Chunk 74:\n",
      "The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.\n",
      "\n",
      "Chunk 75:\n",
      "The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.\n",
      "\n",
      "Chunk 76:\n",
      ", a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.\n",
      "\n",
      "Chunk 77:\n",
      "htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Figure 1: A schematic diagram describing the vector database creation of a RAG application. improvement, and knowledge adaptation [ 28]. Here, we do not use knowledge adaptation and treat the KGs as static graphs.\n",
      "\n",
      "Chunk 78:\n",
      "Knowledge Extraction:- This step aims to extract structured in- formation from unstructured or semi-structured data, such as text, databases, and existing ontologies. The main tasks in this step are entity recognition, relationship extraction, and co-reference reso- lution. Entity recognition and relationship extraction techniques use typical NLP tasks to identify entities and their relationships from textual sources [ 29].\n",
      "\n",
      "Chunk 79:\n",
      "Coreference resolution identifies and connects different references of the same entity, keeping coherence within the knowledge graph. For example, if the text refers to a company as both \"the company\" and \"it\", coreference resolution can link these mentions to the same entity node in the graph. Knowledge Improvement:- This step aims to enhance the quality and completeness of the KG by removing redundancies and address- ing gaps in the extracted information.\n",
      "\n",
      "Chunk 80:\n",
      "The primary tasks in this step are KG completion and fusion. KG completion technique infers missing entities and relationships within the graph using meth- ods such as link prediction and entity resolution. Link prediction predicts the existence and type of a relation between two entities based on the graph structure and features, while entity resolution matches and merges different representations of the same entity from different sources.\n",
      "\n",
      "Chunk 81:\n",
      "Knowledge fusion combines information from multiple sources to create a coherent and unified KG. This involves resolving conflicts and redundancies among the sources, such as contradictory or duplicate facts, and aggregating or reconciling the information based on rules, probabilities, or semantic similarity. We utilized a robust methodology for creating KG triplets from unstructured text data, specifically focusing on corporate docu- ments such as earnings call transcripts, adapted from Ref.\n",
      "\n",
      "Chunk 82:\n",
      "[ 18?]. This process involves several interconnected stages, each designed to extract, refine, and structure information effectively. We implement a two-tiered LLM chain for content refinement and information extraction. The first tier employs an LLM to gen- erate an abstract representation of each document chunk.\n",
      "\n",
      "Chunk 83:\n",
      "This refinement process is crucial as it distills the essential information while preserving the original meaning and key relationships be- tween concepts that serves as a more focused input for subsequent processing, enhancing the overall efficiency and accuracy of ourtriplet extraction pipeline. The second tier of our LLM chain is dedicated to entity extraction and relationship identification. Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM.\n",
      "\n",
      "Chunk 84:\n",
      "A detailed discussion on imple- mentation of the methodology will be provided in Section 4.1 2.3 GraphRAG KG based RAG [ 22], or GraphRAG, also begins with a query based on the user’s input same as VectorRAG. The main difference be- tween VectorRAG and GraphRAG lies in the retrieval part. The query here is now used to search the KG to retrieve relevant nodes (entities) and edges (relationships) related to the query.\n",
      "\n",
      "Chunk 85:\n",
      "A subgraph, which consists of these relevant nodes and edges, is extracted from the full KG to provide context. This subgraph is then integrated with the language model’s internal knowledge, by encoding the graph structure into embeddings that the model can interpret. The language model uses this combined context to generate responses that are informed by both the structured information from the KG and its pre-trained knowledge.\n",
      "\n",
      "Chunk 86:\n",
      "Crucially, when responding to user queries about a particular company, we leveraged the metadata information to selectively filter and retrieve only those document segments pertinent to the queried company [ 8]. This integration helps ensure that the generated outputs are accurate, contextually relevant, and grounded in verifiable information. A schematic diagram of the retrieval methodology of GraphRAG is given in Figure 2.\n",
      "\n",
      "Chunk 87:\n",
      "Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section 4.1 Figure 2: A schematic diagram describing knowledge graph creation process of GraphRAG. 2.3.1 HybridRAG. For the HybridRAG technique, we propose to integrate the aforementioned two distinct RAG techniques: Vec- torRAG and GraphRAG.\n",
      "\n",
      "Chunk 88:\n",
      "This integration involves a systematic combination of contextual information retrieved from both the traditional vector-based retrieval mechanism and the KG-based retrieval system, the latter of which was constructed specifically for this study. The amalgamation of these two contexts allows us to leverage the strengths of both approaches.\n",
      "\n",
      "Chunk 89:\n",
      "The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-richHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.\n",
      "\n",
      "Chunk 90:\n",
      "com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc. New York, NY, USADhagash Mehta dhagash.mehta@blackrock.com BlackRock, Inc.\n",
      "\n",
      "Chunk 91:\n",
      "New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.\n",
      "\n",
      "Chunk 92:\n",
      "We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.\n",
      "\n",
      "Chunk 93:\n",
      "Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.\n",
      "\n",
      "Chunk 94:\n",
      "The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.\n",
      "\n",
      "Chunk 95:\n",
      "However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.\n",
      "\n",
      "Chunk 96:\n",
      "Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].\n",
      "\n",
      "Chunk 97:\n",
      "Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.\n",
      "\n",
      "Chunk 98:\n",
      "In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.\n",
      "\n",
      "Chunk 99:\n",
      "Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.\n",
      "\n",
      "Chunk 100:\n",
      "VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.\n",
      "\n",
      "Chunk 101:\n",
      "For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].\n",
      "\n",
      "Chunk 102:\n",
      "Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.\n",
      "\n",
      "Chunk 103:\n",
      "Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.\n",
      "\n",
      "Chunk 104:\n",
      "KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.\n",
      "\n",
      "Chunk 105:\n",
      "However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].\n",
      "\n",
      "Chunk 106:\n",
      "Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.\n",
      "\n",
      "Chunk 107:\n",
      "However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.\n",
      "\n",
      "Chunk 108:\n",
      "By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.\n",
      "\n",
      "Chunk 109:\n",
      "In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.\n",
      "\n",
      "Chunk 110:\n",
      "1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].\n",
      "\n",
      "Chunk 111:\n",
      "Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.\n",
      "\n",
      "Chunk 112:\n",
      "We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.\n",
      "\n",
      "Chunk 113:\n",
      "2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.\n",
      "\n",
      "Chunk 114:\n",
      "This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.\n",
      "\n",
      "Chunk 115:\n",
      "This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.\n",
      "\n",
      "Chunk 116:\n",
      "In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.\n",
      "\n",
      "Chunk 117:\n",
      "The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.\n",
      "\n",
      "Chunk 118:\n",
      "The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.\n",
      "\n",
      "Chunk 119:\n",
      ", a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.\n",
      "\n",
      "Chunk 120:\n",
      "htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Figure 1: A schematic diagram describing the vector database creation of a RAG application. improvement, and knowledge adaptation [ 28]. Here, we do not use knowledge adaptation and treat the KGs as static graphs.\n",
      "\n",
      "Chunk 121:\n",
      "Knowledge Extraction:- This step aims to extract structured in- formation from unstructured or semi-structured data, such as text, databases, and existing ontologies. The main tasks in this step are entity recognition, relationship extraction, and co-reference reso- lution. Entity recognition and relationship extraction techniques use typical NLP tasks to identify entities and their relationships from textual sources [ 29].\n",
      "\n",
      "Chunk 122:\n",
      "Coreference resolution identifies and connects different references of the same entity, keeping coherence within the knowledge graph. For example, if the text refers to a company as both \"the company\" and \"it\", coreference resolution can link these mentions to the same entity node in the graph. Knowledge Improvement:- This step aims to enhance the quality and completeness of the KG by removing redundancies and address- ing gaps in the extracted information.\n",
      "\n",
      "Chunk 123:\n",
      "The primary tasks in this step are KG completion and fusion. KG completion technique infers missing entities and relationships within the graph using meth- ods such as link prediction and entity resolution. Link prediction predicts the existence and type of a relation between two entities based on the graph structure and features, while entity resolution matches and merges different representations of the same entity from different sources.\n",
      "\n",
      "Chunk 124:\n",
      "Knowledge fusion combines information from multiple sources to create a coherent and unified KG. This involves resolving conflicts and redundancies among the sources, such as contradictory or duplicate facts, and aggregating or reconciling the information based on rules, probabilities, or semantic similarity. We utilized a robust methodology for creating KG triplets from unstructured text data, specifically focusing on corporate docu- ments such as earnings call transcripts, adapted from Ref.\n",
      "\n",
      "Chunk 125:\n",
      "[ 18?]. This process involves several interconnected stages, each designed to extract, refine, and structure information effectively. We implement a two-tiered LLM chain for content refinement and information extraction. The first tier employs an LLM to gen- erate an abstract representation of each document chunk.\n",
      "\n",
      "Chunk 126:\n",
      "This refinement process is crucial as it distills the essential information while preserving the original meaning and key relationships be- tween concepts that serves as a more focused input for subsequent processing, enhancing the overall efficiency and accuracy of ourtriplet extraction pipeline. The second tier of our LLM chain is dedicated to entity extraction and relationship identification. Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM.\n",
      "\n",
      "Chunk 127:\n",
      "A detailed discussion on imple- mentation of the methodology will be provided in Section 4.1 2.3 GraphRAG KG based RAG [ 22], or GraphRAG, also begins with a query based on the user’s input same as VectorRAG. The main difference be- tween VectorRAG and GraphRAG lies in the retrieval part. The query here is now used to search the KG to retrieve relevant nodes (entities) and edges (relationships) related to the query.\n",
      "\n",
      "Chunk 128:\n",
      "A subgraph, which consists of these relevant nodes and edges, is extracted from the full KG to provide context. This subgraph is then integrated with the language model’s internal knowledge, by encoding the graph structure into embeddings that the model can interpret. The language model uses this combined context to generate responses that are informed by both the structured information from the KG and its pre-trained knowledge.\n",
      "\n",
      "Chunk 129:\n",
      "Crucially, when responding to user queries about a particular company, we leveraged the metadata information to selectively filter and retrieve only those document segments pertinent to the queried company [ 8]. This integration helps ensure that the generated outputs are accurate, contextually relevant, and grounded in verifiable information. A schematic diagram of the retrieval methodology of GraphRAG is given in Figure 2.\n",
      "\n",
      "Chunk 130:\n",
      "Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section 4.1 Figure 2: A schematic diagram describing knowledge graph creation process of GraphRAG. 2.3.1 HybridRAG. For the HybridRAG technique, we propose to integrate the aforementioned two distinct RAG techniques: Vec- torRAG and GraphRAG.\n",
      "\n",
      "Chunk 131:\n",
      "This integration involves a systematic combination of contextual information retrieved from both the traditional vector-based retrieval mechanism and the KG-based retrieval system, the latter of which was constructed specifically for this study. The amalgamation of these two contexts allows us to leverage the strengths of both approaches.\n",
      "\n",
      "Chunk 132:\n",
      "The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-richSarmah et al. contextual data. This combined context is then utilized as input for a LLM to generate the final responses. Details on the implementation of the HybridRAG will be provided in Section 4.4. 2.\n",
      "\n",
      "Chunk 133:\n",
      "4 Evaluation Metrics To assess the efficacy of this integrated approach, we conducted a comparative analysis among the three approaches in a controlled ex- perimental set up: VectorRAG, GraphRAG and HybridRAG. The re- sponses generated using the combined VectorRAG and GraphRAG contexts were juxtaposed against those produced individually by VectorRAG and GraphRAG.\n",
      "\n",
      "Chunk 134:\n",
      "This comparative evaluation aimed to discern potential improvements in response quality, accuracy, and comprehensiveness that might arise from the synergistic integra- tion of these two RAG methodologies. To objectively evaluate different RAG approaches (VectorRAG and GraphRAG in their case), Ref. [ 22] utilized metrics such as comprehensiveness (i.e., the amount of details the answer provides to cover all aspects and details of the question?); diversity (i.e.\n",
      "\n",
      "Chunk 135:\n",
      ", the richness of the answer in providing different perspectives and insights on the question); empowerment (i.e., the helpfulness of the answer to the reader understand and make informed judgements about the topic); and, directness (i.e., clearness of the answer in addressing the question). here, the LLM was provided tuples of question, target metric, and a pair of answers, and was asked to assess which answer was better according to the metric and why.\n",
      "\n",
      "Chunk 136:\n",
      "These metrics though compare the final generated answers, do not necessarily directly evaluate the retrieval and generation parts separately. Instead, here we implement a comprehensive set of evaluation metrics which are designed to capture different aspects of a given RAG system’s output quality, focusing on faithfulness, answer relevance, and context relevance [ 30]. Each metric provides unique insights into the system’s capabilities and limitations. 2.4.1 Faithfulness.\n",
      "\n",
      "Chunk 137:\n",
      "Faithfulness is a crucial metric that measures the extent to which the generated answer can be inferred from the provided context. Our implementation of the faithfulness metric involves a two-step process: Statement Extraction:- We use an LLM to decompose the gener- ated answer into a set of concise statements. This step is crucial for breaking down complex answers into more manageable and verifiable units.\n",
      "\n",
      "Chunk 138:\n",
      "The prompt used for this step is: \"Given a question and answer, create one or more statements from each sentence in the given answer. question: [question] an- swer: [answer]\". Statement Verification:- For each extracted statement, we employ the LLM to determine if it can be inferred from the given context.\n",
      "\n",
      "Chunk 139:\n",
      "This verification process uses the following prompt: \"Consider the given context and following statements, then de- termine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. statement: [statement 1] ... statement: [statement n]\".\n",
      "\n",
      "Chunk 140:\n",
      "The faithfulness score ( 𝐹) is𝐹=|𝑉|/|𝑆|, where |𝑉|is the number of supported statements and |𝑆|is the total number of statements.2.4.2 Answer Relevance:-. The answer relevance metric assesses how well the generated answer addresses the original question, irrespective of factual accuracy. This metric helps identify cases of incomplete answers or responses containing irrelevant information.\n",
      "\n",
      "Chunk 141:\n",
      "Our implementation involves the following steps: Question Generation: We prompt the LLM to generate n potential questions based on the given answer: \"Generate a question for the given answer. answer: [answer]\". Then, we obtain embeddings for all generated questions and the original question using OpenAI’s text-embedding-ada-002 model2. We then calculate the cosine similarity between each generated question’s embedding and the original question’s embedding.\n",
      "\n",
      "Chunk 142:\n",
      "Finally, the answer relevance score (AR) is computed as the aver- age similarity across all generated questions: 𝐴𝑅=1 𝑛Í(𝑠𝑖𝑚(𝑞,𝑞𝑖)), where𝑠𝑖𝑚(𝑞,𝑞𝑖)is the cosine similarity between the embedding of the original question 𝑞and the embeddings of each of the 𝑛 generated questions 𝑞𝑖. 2.4.3 Context Precision. It is a metric used to evaluate the relevance of retrieved context chunks in relation to a specified ground truth for a given question3.\n",
      "\n",
      "Chunk 143:\n",
      "It calculates the proportion of relevant items that appear in the top ranks of the context. The formula for context precision at K is the sum of the products of precision at each rank k and a binary relevance indicator v_k, divided by the total number of relevant items in the top K results. Precision at each rank k is determined by the ratio of true positives at k to the sum of true positives and false positives at k.\n",
      "\n",
      "Chunk 144:\n",
      "This metric helps in assessing how well the context supports the ground truth, aiming for higher scores which indicate better precision. 2.4.4 Context Recall. It is a metric used to evaluate how well the retrieved context aligns with the ground truth answer, which is considered the definitive correct response4. It is quantified by com- paring each sentence in the ground truth answer to see if it can be traced back to the retrieved context.\n",
      "\n",
      "Chunk 145:\n",
      "The formula for context recall is the ratio of the number of ground truth sentences that can be attributed to the context to the total number of sentences in the ground truth. Higher values, ranging from 0 to 1, indicate bet- ter alignment and thus better context recall. This metric is crucial for assessing the effectiveness of information retrieval systems in providing relevant context.\n",
      "\n",
      "Chunk 146:\n",
      "3 DATA DESCRIPTION Although there do exist some public financial datasets, none of them were suitable for the present experiments: e.g., FinQA [ 31], TAT- QA [ 32], FIQA [ 33], FinanceBench [ 34], etc. datasets are limited to specific usecases such as benchmarking LLMs’ abilities to perform complex numerical reasoning or sentiment analysis. On the other hand, FinTextQA [ 35] dataset was not publicly available at the time of writing the present work.\n",
      "\n",
      "Chunk 147:\n",
      "In addition, in most of these datasets, access to the actual documents from which the ground- truth Q&As were created is not available, making it impossible to use them for our RAG techniques evaluation purposes. Hence, we resorted to a dataset of our own though through publicly available 2https://platform.openai.com/docs/guides/embeddings/embedding-models 3https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html 4https://docs.ragas.io/en/stable/concepts/metrics/context_recall.\n",
      "\n",
      "Chunk 148:\n",
      "htmlHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc. New York, NY, USADhagash Mehta dhagash.mehta@blackrock.\n",
      "\n",
      "Chunk 149:\n",
      "com BlackRock, Inc.\n",
      "\n",
      "Chunk 150:\n",
      "New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.\n",
      "\n",
      "Chunk 151:\n",
      "We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.\n",
      "\n",
      "Chunk 152:\n",
      "Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.\n",
      "\n",
      "Chunk 153:\n",
      "The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.\n",
      "\n",
      "Chunk 154:\n",
      "However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.\n",
      "\n",
      "Chunk 155:\n",
      "Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].\n",
      "\n",
      "Chunk 156:\n",
      "Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.\n",
      "\n",
      "Chunk 157:\n",
      "In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.\n",
      "\n",
      "Chunk 158:\n",
      "Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.\n",
      "\n",
      "Chunk 159:\n",
      "VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.\n",
      "\n",
      "Chunk 160:\n",
      "For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].\n",
      "\n",
      "Chunk 161:\n",
      "Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.\n",
      "\n",
      "Chunk 162:\n",
      "Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.\n",
      "\n",
      "Chunk 163:\n",
      "KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.\n",
      "\n",
      "Chunk 164:\n",
      "However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].\n",
      "\n",
      "Chunk 165:\n",
      "Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.\n",
      "\n",
      "Chunk 166:\n",
      "However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.\n",
      "\n",
      "Chunk 167:\n",
      "By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.\n",
      "\n",
      "Chunk 168:\n",
      "In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.\n",
      "\n",
      "Chunk 169:\n",
      "1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].\n",
      "\n",
      "Chunk 170:\n",
      "Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.\n",
      "\n",
      "Chunk 171:\n",
      "We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.\n",
      "\n",
      "Chunk 172:\n",
      "2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.\n",
      "\n",
      "Chunk 173:\n",
      "This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.\n",
      "\n",
      "Chunk 174:\n",
      "This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.\n",
      "\n",
      "Chunk 175:\n",
      "In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.\n",
      "\n",
      "Chunk 176:\n",
      "The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.\n",
      "\n",
      "Chunk 177:\n",
      "The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.\n",
      "\n",
      "Chunk 178:\n",
      ", a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.\n",
      "\n",
      "Chunk 179:\n",
      "htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Figure 1: A schematic diagram describing the vector database creation of a RAG application. improvement, and knowledge adaptation [ 28]. Here, we do not use knowledge adaptation and treat the KGs as static graphs.\n",
      "\n",
      "Chunk 180:\n",
      "Knowledge Extraction:- This step aims to extract structured in- formation from unstructured or semi-structured data, such as text, databases, and existing ontologies. The main tasks in this step are entity recognition, relationship extraction, and co-reference reso- lution. Entity recognition and relationship extraction techniques use typical NLP tasks to identify entities and their relationships from textual sources [ 29].\n",
      "\n",
      "Chunk 181:\n",
      "Coreference resolution identifies and connects different references of the same entity, keeping coherence within the knowledge graph. For example, if the text refers to a company as both \"the company\" and \"it\", coreference resolution can link these mentions to the same entity node in the graph. Knowledge Improvement:- This step aims to enhance the quality and completeness of the KG by removing redundancies and address- ing gaps in the extracted information.\n",
      "\n",
      "Chunk 182:\n",
      "The primary tasks in this step are KG completion and fusion. KG completion technique infers missing entities and relationships within the graph using meth- ods such as link prediction and entity resolution. Link prediction predicts the existence and type of a relation between two entities based on the graph structure and features, while entity resolution matches and merges different representations of the same entity from different sources.\n",
      "\n",
      "Chunk 183:\n",
      "Knowledge fusion combines information from multiple sources to create a coherent and unified KG. This involves resolving conflicts and redundancies among the sources, such as contradictory or duplicate facts, and aggregating or reconciling the information based on rules, probabilities, or semantic similarity. We utilized a robust methodology for creating KG triplets from unstructured text data, specifically focusing on corporate docu- ments such as earnings call transcripts, adapted from Ref.\n",
      "\n",
      "Chunk 184:\n",
      "[ 18?]. This process involves several interconnected stages, each designed to extract, refine, and structure information effectively. We implement a two-tiered LLM chain for content refinement and information extraction. The first tier employs an LLM to gen- erate an abstract representation of each document chunk.\n",
      "\n",
      "Chunk 185:\n",
      "This refinement process is crucial as it distills the essential information while preserving the original meaning and key relationships be- tween concepts that serves as a more focused input for subsequent processing, enhancing the overall efficiency and accuracy of ourtriplet extraction pipeline. The second tier of our LLM chain is dedicated to entity extraction and relationship identification. Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM.\n",
      "\n",
      "Chunk 186:\n",
      "A detailed discussion on imple- mentation of the methodology will be provided in Section 4.1 2.3 GraphRAG KG based RAG [ 22], or GraphRAG, also begins with a query based on the user’s input same as VectorRAG. The main difference be- tween VectorRAG and GraphRAG lies in the retrieval part. The query here is now used to search the KG to retrieve relevant nodes (entities) and edges (relationships) related to the query.\n",
      "\n",
      "Chunk 187:\n",
      "A subgraph, which consists of these relevant nodes and edges, is extracted from the full KG to provide context. This subgraph is then integrated with the language model’s internal knowledge, by encoding the graph structure into embeddings that the model can interpret. The language model uses this combined context to generate responses that are informed by both the structured information from the KG and its pre-trained knowledge.\n",
      "\n",
      "Chunk 188:\n",
      "Crucially, when responding to user queries about a particular company, we leveraged the metadata information to selectively filter and retrieve only those document segments pertinent to the queried company [ 8]. This integration helps ensure that the generated outputs are accurate, contextually relevant, and grounded in verifiable information. A schematic diagram of the retrieval methodology of GraphRAG is given in Figure 2.\n",
      "\n",
      "Chunk 189:\n",
      "Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section 4.1 Figure 2: A schematic diagram describing knowledge graph creation process of GraphRAG. 2.3.1 HybridRAG. For the HybridRAG technique, we propose to integrate the aforementioned two distinct RAG techniques: Vec- torRAG and GraphRAG.\n",
      "\n",
      "Chunk 190:\n",
      "This integration involves a systematic combination of contextual information retrieved from both the traditional vector-based retrieval mechanism and the KG-based retrieval system, the latter of which was constructed specifically for this study. The amalgamation of these two contexts allows us to leverage the strengths of both approaches.\n",
      "\n",
      "Chunk 191:\n",
      "The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-richSarmah et al. contextual data. This combined context is then utilized as input for a LLM to generate the final responses. Details on the implementation of the HybridRAG will be provided in Section 4.4. 2.\n",
      "\n",
      "Chunk 192:\n",
      "4 Evaluation Metrics To assess the efficacy of this integrated approach, we conducted a comparative analysis among the three approaches in a controlled ex- perimental set up: VectorRAG, GraphRAG and HybridRAG. The re- sponses generated using the combined VectorRAG and GraphRAG contexts were juxtaposed against those produced individually by VectorRAG and GraphRAG.\n",
      "\n",
      "Chunk 193:\n",
      "This comparative evaluation aimed to discern potential improvements in response quality, accuracy, and comprehensiveness that might arise from the synergistic integra- tion of these two RAG methodologies. To objectively evaluate different RAG approaches (VectorRAG and GraphRAG in their case), Ref. [ 22] utilized metrics such as comprehensiveness (i.e., the amount of details the answer provides to cover all aspects and details of the question?); diversity (i.e.\n",
      "\n",
      "Chunk 194:\n",
      ", the richness of the answer in providing different perspectives and insights on the question); empowerment (i.e., the helpfulness of the answer to the reader understand and make informed judgements about the topic); and, directness (i.e., clearness of the answer in addressing the question). here, the LLM was provided tuples of question, target metric, and a pair of answers, and was asked to assess which answer was better according to the metric and why.\n",
      "\n",
      "Chunk 195:\n",
      "These metrics though compare the final generated answers, do not necessarily directly evaluate the retrieval and generation parts separately. Instead, here we implement a comprehensive set of evaluation metrics which are designed to capture different aspects of a given RAG system’s output quality, focusing on faithfulness, answer relevance, and context relevance [ 30]. Each metric provides unique insights into the system’s capabilities and limitations. 2.4.1 Faithfulness.\n",
      "\n",
      "Chunk 196:\n",
      "Faithfulness is a crucial metric that measures the extent to which the generated answer can be inferred from the provided context. Our implementation of the faithfulness metric involves a two-step process: Statement Extraction:- We use an LLM to decompose the gener- ated answer into a set of concise statements. This step is crucial for breaking down complex answers into more manageable and verifiable units.\n",
      "\n",
      "Chunk 197:\n",
      "The prompt used for this step is: \"Given a question and answer, create one or more statements from each sentence in the given answer. question: [question] an- swer: [answer]\". Statement Verification:- For each extracted statement, we employ the LLM to determine if it can be inferred from the given context.\n",
      "\n",
      "Chunk 198:\n",
      "This verification process uses the following prompt: \"Consider the given context and following statements, then de- termine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. statement: [statement 1] ... statement: [statement n]\".\n",
      "\n",
      "Chunk 199:\n",
      "The faithfulness score ( 𝐹) is𝐹=|𝑉|/|𝑆|, where |𝑉|is the number of supported statements and |𝑆|is the total number of statements.2.4.2 Answer Relevance:-. The answer relevance metric assesses how well the generated answer addresses the original question, irrespective of factual accuracy. This metric helps identify cases of incomplete answers or responses containing irrelevant information.\n",
      "\n",
      "Chunk 200:\n",
      "Our implementation involves the following steps: Question Generation: We prompt the LLM to generate n potential questions based on the given answer: \"Generate a question for the given answer. answer: [answer]\". Then, we obtain embeddings for all generated questions and the original question using OpenAI’s text-embedding-ada-002 model2. We then calculate the cosine similarity between each generated question’s embedding and the original question’s embedding.\n",
      "\n",
      "Chunk 201:\n",
      "Finally, the answer relevance score (AR) is computed as the aver- age similarity across all generated questions: 𝐴𝑅=1 𝑛Í(𝑠𝑖𝑚(𝑞,𝑞𝑖)), where𝑠𝑖𝑚(𝑞,𝑞𝑖)is the cosine similarity between the embedding of the original question 𝑞and the embeddings of each of the 𝑛 generated questions 𝑞𝑖. 2.4.3 Context Precision. It is a metric used to evaluate the relevance of retrieved context chunks in relation to a specified ground truth for a given question3.\n",
      "\n",
      "Chunk 202:\n",
      "It calculates the proportion of relevant items that appear in the top ranks of the context. The formula for context precision at K is the sum of the products of precision at each rank k and a binary relevance indicator v_k, divided by the total number of relevant items in the top K results. Precision at each rank k is determined by the ratio of true positives at k to the sum of true positives and false positives at k.\n",
      "\n",
      "Chunk 203:\n",
      "This metric helps in assessing how well the context supports the ground truth, aiming for higher scores which indicate better precision. 2.4.4 Context Recall. It is a metric used to evaluate how well the retrieved context aligns with the ground truth answer, which is considered the definitive correct response4. It is quantified by com- paring each sentence in the ground truth answer to see if it can be traced back to the retrieved context.\n",
      "\n",
      "Chunk 204:\n",
      "The formula for context recall is the ratio of the number of ground truth sentences that can be attributed to the context to the total number of sentences in the ground truth. Higher values, ranging from 0 to 1, indicate bet- ter alignment and thus better context recall. This metric is crucial for assessing the effectiveness of information retrieval systems in providing relevant context.\n",
      "\n",
      "Chunk 205:\n",
      "3 DATA DESCRIPTION Although there do exist some public financial datasets, none of them were suitable for the present experiments: e.g., FinQA [ 31], TAT- QA [ 32], FIQA [ 33], FinanceBench [ 34], etc. datasets are limited to specific usecases such as benchmarking LLMs’ abilities to perform complex numerical reasoning or sentiment analysis. On the other hand, FinTextQA [ 35] dataset was not publicly available at the time of writing the present work.\n",
      "\n",
      "Chunk 206:\n",
      "In addition, in most of these datasets, access to the actual documents from which the ground- truth Q&As were created is not available, making it impossible to use them for our RAG techniques evaluation purposes. Hence, we resorted to a dataset of our own though through publicly available 2https://platform.openai.com/docs/guides/embeddings/embedding-models 3https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html 4https://docs.ragas.io/en/stable/concepts/metrics/context_recall.\n",
      "\n",
      "Chunk 207:\n",
      "htmlHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction documents but such that we finally have access to both the actual financial documents and the ground-truth Q&As. Datasets like FinanceBench5provides question-context-answer triplets but they are not useful as here we are comparing VectorRAG, GraphRAG and HybridRAG and they do not provide the context generated from a KG.\n",
      "\n",
      "Chunk 208:\n",
      "A recent paper [ 22] has not made the KG and triplets constructed by their algorithm public to the best of our knowledge either. In short, there is no publicly available benchmark dataset to compare VectorRAG and GraphRAG either for financial or general domains to the best of our knowledge. Hence, we had to rely on our own dataset constructed as explained below. We used transcripts from earnings calls of Nifty 50 constituents for our analysis.\n",
      "\n",
      "Chunk 209:\n",
      "The NIFTY 50 is popular index in the Indian stock market that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange (NSE). The dataset of the earning call documents of Nifty 50 companies is widely recognized in the investment realm and is esteemed as an authoritative and extensive collection of earnings call transcripts. In our investigation, we focus on data spanning the quarter ending in June, 2023 i.e.\n",
      "\n",
      "Chunk 210:\n",
      "the earnings reports for Q1 of the financial year 2024 (A financial year in India starts on the 1st April and ends in 31st March, so the quarter from 1st April to 30th June is the first quarter of 2024 for the Indian market).\n",
      "\n",
      "Chunk 211:\n",
      "Our dataset encompasses 50 transcripts for this quarter, span- ning over 50 companies within Nifty 50 universe from diverse range of sectors including Infrastructure, Healthcare, Consumer Durables, Banking, Automobile, Financial Services, Energy - Oil & Gas, Telecommunication, Consumer Goods, Pharmaceuticals, Energy - Coal, Materials, Information Technology, Construction, Diversified, Metals, Energy - Power and Chemicals providing a substantial and diverse foundation for our study.\n",
      "\n",
      "Chunk 212:\n",
      "We start the data collection process focused on acquiring earn- ings reports from company websites within the Nifty 50 universe by developing and deploying a custom web scraping tool to navigate through the websites of each company within the Nifty 50 index, systematically retrieving the pertinent earnings reports for Q1 of the financial year 2024. By utilizing this web scraping approach, we aimed to compile a comprehensive dataset encompassing the earnings reports of the constituent companies.\n",
      "\n",
      "Chunk 213:\n",
      "Table 1 summarizes basic statistics of the documents we will be experimenting with in the remainder of this work. Number of companies/documents 50 Average number of pages 27 Average number of questions 16 Average number of tokens 60,000 Table 1: Summary Statistics for the call transcript documents used in the present work.\n",
      "\n",
      "Chunk 214:\n",
      "These call transcripts documents consist of questions and an- swers between financial analysts and the company representatives for the respective companies, hence, there already exist certain Q&A pairs within these documents along with additional text. We examined the earnings reports within the Nifty50 universe, system- atically curated a comprehensive array of randomly selected 400 5https://huggingface.\n",
      "\n",
      "Chunk 215:\n",
      "co/datasets/PatronusAI/financebench-testquestions posed during the earnings calls from all the documents, and gathered the exact responses corresponding to these questions. These questions constitute the specific queries articulated by finan- cial analysts to the management during these calls. 4 IMPLEMENTATION DETAILS In this Section, we provide details of implementation of the pro- posed methodology. 4.\n",
      "\n",
      "Chunk 216:\n",
      "1 Knowledge Graph Construction The initial phase of our approach centers on document preprocess- ing. We utilize the PyPDFLoader6to import PDF documents, which are subsequently segmented into manageable chunks using the RecursiveCharacterTextSplitter. This chunking strategy employs a size of 2024 characters with an overlap of 204 characters, ensuring comprehensive coverage while maintaining context across segment boundaries.\n",
      "\n",
      "Chunk 217:\n",
      "Following the preprocessing stage, we implement the two-tiered language model chain for content refinement and information ex- traction. It is not possible to include the exact prompt here due to the limited space, but a baseline prompt can be found in Ref. [18].\n",
      "\n",
      "Chunk 218:\n",
      "Entity Type Examples Companies and Corpo- rationsOfficial names, abbreviations, infor- mal references Financial Metrics and IndicatorsRevenue, profit margins, EBITDA Corporate Executives and Key PersonnelCEOs, CFOs, board members Products and Services Tangible products and intangible ser- vices Geographical Locations Headquarters, operational regions, markets Corporate Events Mergers, acquisitions, product launches, earnings calls Legal and Regulatory InformationLegal cases, regulatory compliance Table 2: Entities extracted from earnings call transcripts Table 2 summarizes details on entities extracted from the earn- ing calls transcripts using our prompt based method.\n",
      "\n",
      "Chunk 219:\n",
      "Concurrently, LLM identifies relationships between these entities using a curated set of verbs, capturing the nuanced interactions within the cor- porate narrative. A key improvement in our methodology is the enhanced prompt engineering to generate the structured output format for knowledge triplets.\n",
      "\n",
      "Chunk 220:\n",
      "Each triplet is represented as a nested list [’h’, ’type’, ’r’, ’o’, ’type’, ’metadata’], where ’h’ and ’o’ denote the head and object entities respectively, ’type’ specifies the entity category, ’r’ represents the relationship, and ’metadata’ encapsu- lates additional contextual information. This format allows for a rich, multidimensional representation of information, facilitating more nuanced downstream analysis. 6https://python.langchain.com/v0.\n",
      "\n",
      "Chunk 221:\n",
      "1/docs/modules/data_connection/document_ loaders/pdf/HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc.\n",
      "\n",
      "Chunk 222:\n",
      "New York, NY, USADhagash Mehta dhagash.mehta@blackrock.com BlackRock, Inc.\n",
      "\n",
      "Chunk 223:\n",
      "New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.\n",
      "\n",
      "Chunk 224:\n",
      "We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.\n",
      "\n",
      "Chunk 225:\n",
      "Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.\n",
      "\n",
      "Chunk 226:\n",
      "The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.\n",
      "\n",
      "Chunk 227:\n",
      "However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.\n",
      "\n",
      "Chunk 228:\n",
      "Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].\n",
      "\n",
      "Chunk 229:\n",
      "Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.\n",
      "\n",
      "Chunk 230:\n",
      "In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.\n",
      "\n",
      "Chunk 231:\n",
      "Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.\n",
      "\n",
      "Chunk 232:\n",
      "VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.\n",
      "\n",
      "Chunk 233:\n",
      "For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].\n",
      "\n",
      "Chunk 234:\n",
      "Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.\n",
      "\n",
      "Chunk 235:\n",
      "Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.\n",
      "\n",
      "Chunk 236:\n",
      "KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.\n",
      "\n",
      "Chunk 237:\n",
      "However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].\n",
      "\n",
      "Chunk 238:\n",
      "Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.\n",
      "\n",
      "Chunk 239:\n",
      "However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.\n",
      "\n",
      "Chunk 240:\n",
      "By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.\n",
      "\n",
      "Chunk 241:\n",
      "In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.\n",
      "\n",
      "Chunk 242:\n",
      "1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].\n",
      "\n",
      "Chunk 243:\n",
      "Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.\n",
      "\n",
      "Chunk 244:\n",
      "We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.\n",
      "\n",
      "Chunk 245:\n",
      "2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.\n",
      "\n",
      "Chunk 246:\n",
      "This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.\n",
      "\n",
      "Chunk 247:\n",
      "This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.\n",
      "\n",
      "Chunk 248:\n",
      "In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.\n",
      "\n",
      "Chunk 249:\n",
      "The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.\n",
      "\n",
      "Chunk 250:\n",
      "The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.\n",
      "\n",
      "Chunk 251:\n",
      ", a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.\n",
      "\n",
      "Chunk 252:\n",
      "htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Figure 1: A schematic diagram describing the vector database creation of a RAG application. improvement, and knowledge adaptation [ 28]. Here, we do not use knowledge adaptation and treat the KGs as static graphs.\n",
      "\n",
      "Chunk 253:\n",
      "Knowledge Extraction:- This step aims to extract structured in- formation from unstructured or semi-structured data, such as text, databases, and existing ontologies. The main tasks in this step are entity recognition, relationship extraction, and co-reference reso- lution. Entity recognition and relationship extraction techniques use typical NLP tasks to identify entities and their relationships from textual sources [ 29].\n",
      "\n",
      "Chunk 254:\n",
      "Coreference resolution identifies and connects different references of the same entity, keeping coherence within the knowledge graph. For example, if the text refers to a company as both \"the company\" and \"it\", coreference resolution can link these mentions to the same entity node in the graph. Knowledge Improvement:- This step aims to enhance the quality and completeness of the KG by removing redundancies and address- ing gaps in the extracted information.\n",
      "\n",
      "Chunk 255:\n",
      "The primary tasks in this step are KG completion and fusion. KG completion technique infers missing entities and relationships within the graph using meth- ods such as link prediction and entity resolution. Link prediction predicts the existence and type of a relation between two entities based on the graph structure and features, while entity resolution matches and merges different representations of the same entity from different sources.\n",
      "\n",
      "Chunk 256:\n",
      "Knowledge fusion combines information from multiple sources to create a coherent and unified KG. This involves resolving conflicts and redundancies among the sources, such as contradictory or duplicate facts, and aggregating or reconciling the information based on rules, probabilities, or semantic similarity. We utilized a robust methodology for creating KG triplets from unstructured text data, specifically focusing on corporate docu- ments such as earnings call transcripts, adapted from Ref.\n",
      "\n",
      "Chunk 257:\n",
      "[ 18?]. This process involves several interconnected stages, each designed to extract, refine, and structure information effectively. We implement a two-tiered LLM chain for content refinement and information extraction. The first tier employs an LLM to gen- erate an abstract representation of each document chunk.\n",
      "\n",
      "Chunk 258:\n",
      "This refinement process is crucial as it distills the essential information while preserving the original meaning and key relationships be- tween concepts that serves as a more focused input for subsequent processing, enhancing the overall efficiency and accuracy of ourtriplet extraction pipeline. The second tier of our LLM chain is dedicated to entity extraction and relationship identification. Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM.\n",
      "\n",
      "Chunk 259:\n",
      "A detailed discussion on imple- mentation of the methodology will be provided in Section 4.1 2.3 GraphRAG KG based RAG [ 22], or GraphRAG, also begins with a query based on the user’s input same as VectorRAG. The main difference be- tween VectorRAG and GraphRAG lies in the retrieval part. The query here is now used to search the KG to retrieve relevant nodes (entities) and edges (relationships) related to the query.\n",
      "\n",
      "Chunk 260:\n",
      "A subgraph, which consists of these relevant nodes and edges, is extracted from the full KG to provide context. This subgraph is then integrated with the language model’s internal knowledge, by encoding the graph structure into embeddings that the model can interpret. The language model uses this combined context to generate responses that are informed by both the structured information from the KG and its pre-trained knowledge.\n",
      "\n",
      "Chunk 261:\n",
      "Crucially, when responding to user queries about a particular company, we leveraged the metadata information to selectively filter and retrieve only those document segments pertinent to the queried company [ 8]. This integration helps ensure that the generated outputs are accurate, contextually relevant, and grounded in verifiable information. A schematic diagram of the retrieval methodology of GraphRAG is given in Figure 2.\n",
      "\n",
      "Chunk 262:\n",
      "Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section 4.1 Figure 2: A schematic diagram describing knowledge graph creation process of GraphRAG. 2.3.1 HybridRAG. For the HybridRAG technique, we propose to integrate the aforementioned two distinct RAG techniques: Vec- torRAG and GraphRAG.\n",
      "\n",
      "Chunk 263:\n",
      "This integration involves a systematic combination of contextual information retrieved from both the traditional vector-based retrieval mechanism and the KG-based retrieval system, the latter of which was constructed specifically for this study. The amalgamation of these two contexts allows us to leverage the strengths of both approaches.\n",
      "\n",
      "Chunk 264:\n",
      "The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-richSarmah et al. contextual data. This combined context is then utilized as input for a LLM to generate the final responses. Details on the implementation of the HybridRAG will be provided in Section 4.4. 2.\n",
      "\n",
      "Chunk 265:\n",
      "4 Evaluation Metrics To assess the efficacy of this integrated approach, we conducted a comparative analysis among the three approaches in a controlled ex- perimental set up: VectorRAG, GraphRAG and HybridRAG. The re- sponses generated using the combined VectorRAG and GraphRAG contexts were juxtaposed against those produced individually by VectorRAG and GraphRAG.\n",
      "\n",
      "Chunk 266:\n",
      "This comparative evaluation aimed to discern potential improvements in response quality, accuracy, and comprehensiveness that might arise from the synergistic integra- tion of these two RAG methodologies. To objectively evaluate different RAG approaches (VectorRAG and GraphRAG in their case), Ref. [ 22] utilized metrics such as comprehensiveness (i.e., the amount of details the answer provides to cover all aspects and details of the question?); diversity (i.e.\n",
      "\n",
      "Chunk 267:\n",
      ", the richness of the answer in providing different perspectives and insights on the question); empowerment (i.e., the helpfulness of the answer to the reader understand and make informed judgements about the topic); and, directness (i.e., clearness of the answer in addressing the question). here, the LLM was provided tuples of question, target metric, and a pair of answers, and was asked to assess which answer was better according to the metric and why.\n",
      "\n",
      "Chunk 268:\n",
      "These metrics though compare the final generated answers, do not necessarily directly evaluate the retrieval and generation parts separately. Instead, here we implement a comprehensive set of evaluation metrics which are designed to capture different aspects of a given RAG system’s output quality, focusing on faithfulness, answer relevance, and context relevance [ 30]. Each metric provides unique insights into the system’s capabilities and limitations. 2.4.1 Faithfulness.\n",
      "\n",
      "Chunk 269:\n",
      "Faithfulness is a crucial metric that measures the extent to which the generated answer can be inferred from the provided context. Our implementation of the faithfulness metric involves a two-step process: Statement Extraction:- We use an LLM to decompose the gener- ated answer into a set of concise statements. This step is crucial for breaking down complex answers into more manageable and verifiable units.\n",
      "\n",
      "Chunk 270:\n",
      "The prompt used for this step is: \"Given a question and answer, create one or more statements from each sentence in the given answer. question: [question] an- swer: [answer]\". Statement Verification:- For each extracted statement, we employ the LLM to determine if it can be inferred from the given context.\n",
      "\n",
      "Chunk 271:\n",
      "This verification process uses the following prompt: \"Consider the given context and following statements, then de- termine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. statement: [statement 1] ... statement: [statement n]\".\n",
      "\n",
      "Chunk 272:\n",
      "The faithfulness score ( 𝐹) is𝐹=|𝑉|/|𝑆|, where |𝑉|is the number of supported statements and |𝑆|is the total number of statements.2.4.2 Answer Relevance:-. The answer relevance metric assesses how well the generated answer addresses the original question, irrespective of factual accuracy. This metric helps identify cases of incomplete answers or responses containing irrelevant information.\n",
      "\n",
      "Chunk 273:\n",
      "Our implementation involves the following steps: Question Generation: We prompt the LLM to generate n potential questions based on the given answer: \"Generate a question for the given answer. answer: [answer]\". Then, we obtain embeddings for all generated questions and the original question using OpenAI’s text-embedding-ada-002 model2. We then calculate the cosine similarity between each generated question’s embedding and the original question’s embedding.\n",
      "\n",
      "Chunk 274:\n",
      "Finally, the answer relevance score (AR) is computed as the aver- age similarity across all generated questions: 𝐴𝑅=1 𝑛Í(𝑠𝑖𝑚(𝑞,𝑞𝑖)), where𝑠𝑖𝑚(𝑞,𝑞𝑖)is the cosine similarity between the embedding of the original question 𝑞and the embeddings of each of the 𝑛 generated questions 𝑞𝑖. 2.4.3 Context Precision. It is a metric used to evaluate the relevance of retrieved context chunks in relation to a specified ground truth for a given question3.\n",
      "\n",
      "Chunk 275:\n",
      "It calculates the proportion of relevant items that appear in the top ranks of the context. The formula for context precision at K is the sum of the products of precision at each rank k and a binary relevance indicator v_k, divided by the total number of relevant items in the top K results. Precision at each rank k is determined by the ratio of true positives at k to the sum of true positives and false positives at k.\n",
      "\n",
      "Chunk 276:\n",
      "This metric helps in assessing how well the context supports the ground truth, aiming for higher scores which indicate better precision. 2.4.4 Context Recall. It is a metric used to evaluate how well the retrieved context aligns with the ground truth answer, which is considered the definitive correct response4. It is quantified by com- paring each sentence in the ground truth answer to see if it can be traced back to the retrieved context.\n",
      "\n",
      "Chunk 277:\n",
      "The formula for context recall is the ratio of the number of ground truth sentences that can be attributed to the context to the total number of sentences in the ground truth. Higher values, ranging from 0 to 1, indicate bet- ter alignment and thus better context recall. This metric is crucial for assessing the effectiveness of information retrieval systems in providing relevant context.\n",
      "\n",
      "Chunk 278:\n",
      "3 DATA DESCRIPTION Although there do exist some public financial datasets, none of them were suitable for the present experiments: e.g., FinQA [ 31], TAT- QA [ 32], FIQA [ 33], FinanceBench [ 34], etc. datasets are limited to specific usecases such as benchmarking LLMs’ abilities to perform complex numerical reasoning or sentiment analysis. On the other hand, FinTextQA [ 35] dataset was not publicly available at the time of writing the present work.\n",
      "\n",
      "Chunk 279:\n",
      "In addition, in most of these datasets, access to the actual documents from which the ground- truth Q&As were created is not available, making it impossible to use them for our RAG techniques evaluation purposes. Hence, we resorted to a dataset of our own though through publicly available 2https://platform.openai.com/docs/guides/embeddings/embedding-models 3https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html 4https://docs.ragas.io/en/stable/concepts/metrics/context_recall.\n",
      "\n",
      "Chunk 280:\n",
      "htmlHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction documents but such that we finally have access to both the actual financial documents and the ground-truth Q&As. Datasets like FinanceBench5provides question-context-answer triplets but they are not useful as here we are comparing VectorRAG, GraphRAG and HybridRAG and they do not provide the context generated from a KG.\n",
      "\n",
      "Chunk 281:\n",
      "A recent paper [ 22] has not made the KG and triplets constructed by their algorithm public to the best of our knowledge either. In short, there is no publicly available benchmark dataset to compare VectorRAG and GraphRAG either for financial or general domains to the best of our knowledge. Hence, we had to rely on our own dataset constructed as explained below. We used transcripts from earnings calls of Nifty 50 constituents for our analysis.\n",
      "\n",
      "Chunk 282:\n",
      "The NIFTY 50 is popular index in the Indian stock market that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange (NSE). The dataset of the earning call documents of Nifty 50 companies is widely recognized in the investment realm and is esteemed as an authoritative and extensive collection of earnings call transcripts. In our investigation, we focus on data spanning the quarter ending in June, 2023 i.e.\n",
      "\n",
      "Chunk 283:\n",
      "the earnings reports for Q1 of the financial year 2024 (A financial year in India starts on the 1st April and ends in 31st March, so the quarter from 1st April to 30th June is the first quarter of 2024 for the Indian market).\n",
      "\n",
      "Chunk 284:\n",
      "Our dataset encompasses 50 transcripts for this quarter, span- ning over 50 companies within Nifty 50 universe from diverse range of sectors including Infrastructure, Healthcare, Consumer Durables, Banking, Automobile, Financial Services, Energy - Oil & Gas, Telecommunication, Consumer Goods, Pharmaceuticals, Energy - Coal, Materials, Information Technology, Construction, Diversified, Metals, Energy - Power and Chemicals providing a substantial and diverse foundation for our study.\n",
      "\n",
      "Chunk 285:\n",
      "We start the data collection process focused on acquiring earn- ings reports from company websites within the Nifty 50 universe by developing and deploying a custom web scraping tool to navigate through the websites of each company within the Nifty 50 index, systematically retrieving the pertinent earnings reports for Q1 of the financial year 2024. By utilizing this web scraping approach, we aimed to compile a comprehensive dataset encompassing the earnings reports of the constituent companies.\n",
      "\n",
      "Chunk 286:\n",
      "Table 1 summarizes basic statistics of the documents we will be experimenting with in the remainder of this work. Number of companies/documents 50 Average number of pages 27 Average number of questions 16 Average number of tokens 60,000 Table 1: Summary Statistics for the call transcript documents used in the present work.\n",
      "\n",
      "Chunk 287:\n",
      "These call transcripts documents consist of questions and an- swers between financial analysts and the company representatives for the respective companies, hence, there already exist certain Q&A pairs within these documents along with additional text. We examined the earnings reports within the Nifty50 universe, system- atically curated a comprehensive array of randomly selected 400 5https://huggingface.\n",
      "\n",
      "Chunk 288:\n",
      "co/datasets/PatronusAI/financebench-testquestions posed during the earnings calls from all the documents, and gathered the exact responses corresponding to these questions. These questions constitute the specific queries articulated by finan- cial analysts to the management during these calls. 4 IMPLEMENTATION DETAILS In this Section, we provide details of implementation of the pro- posed methodology. 4.\n",
      "\n",
      "Chunk 289:\n",
      "1 Knowledge Graph Construction The initial phase of our approach centers on document preprocess- ing. We utilize the PyPDFLoader6to import PDF documents, which are subsequently segmented into manageable chunks using the RecursiveCharacterTextSplitter. This chunking strategy employs a size of 2024 characters with an overlap of 204 characters, ensuring comprehensive coverage while maintaining context across segment boundaries.\n",
      "\n",
      "Chunk 290:\n",
      "Following the preprocessing stage, we implement the two-tiered language model chain for content refinement and information ex- traction. It is not possible to include the exact prompt here due to the limited space, but a baseline prompt can be found in Ref. [18].\n",
      "\n",
      "Chunk 291:\n",
      "Entity Type Examples Companies and Corpo- rationsOfficial names, abbreviations, infor- mal references Financial Metrics and IndicatorsRevenue, profit margins, EBITDA Corporate Executives and Key PersonnelCEOs, CFOs, board members Products and Services Tangible products and intangible ser- vices Geographical Locations Headquarters, operational regions, markets Corporate Events Mergers, acquisitions, product launches, earnings calls Legal and Regulatory InformationLegal cases, regulatory compliance Table 2: Entities extracted from earnings call transcripts Table 2 summarizes details on entities extracted from the earn- ing calls transcripts using our prompt based method.\n",
      "\n",
      "Chunk 292:\n",
      "Concurrently, LLM identifies relationships between these entities using a curated set of verbs, capturing the nuanced interactions within the cor- porate narrative. A key improvement in our methodology is the enhanced prompt engineering to generate the structured output format for knowledge triplets.\n",
      "\n",
      "Chunk 293:\n",
      "Each triplet is represented as a nested list [’h’, ’type’, ’r’, ’o’, ’type’, ’metadata’], where ’h’ and ’o’ denote the head and object entities respectively, ’type’ specifies the entity category, ’r’ represents the relationship, and ’metadata’ encapsu- lates additional contextual information. This format allows for a rich, multidimensional representation of information, facilitating more nuanced downstream analysis. 6https://python.langchain.com/v0.\n",
      "\n",
      "Chunk 294:\n",
      "1/docs/modules/data_connection/document_ loaders/pdf/Sarmah et al. Our process incorporates several advanced features to enhance the quality and utility of the extracted triplets. Entity disambigua- tion techniques are employed to consolidate different references to the same entity, improving consistency across the KG.\n",
      "\n",
      "Chunk 295:\n",
      "We also pri- oritize conciseness in entity representation, aiming for descriptions of less than four words where possible, which aids in maintaining a clean and navigable graph structure. The extraction pipeline is applied iteratively to each document chunk, with results aggregated to form a comprehensive knowledge graph representation of the entire document, allowing for scalable processing of large documents while maintaining local context within each chunk.\n",
      "\n",
      "Chunk 296:\n",
      "We have added explicit instruction on obtaining metadata following Ref. [8] for both VectorRAG and GraphRAG. Finally, we implement a data persistence strategy, converting the extracted triplets from their initial string format to Python data structures and storing them in a pickle file. This facilitates easy retrieval and further manipulation of the knowledge graph data in subsequent analysis stages.\n",
      "\n",
      "Chunk 297:\n",
      "Our methodology represents a significant advancement in auto- mated knowledge extraction from corporate documents. By com- bining advanced NLP techniques with a structured approach to information representation, we create a rich, queryable knowledge base that captures the complex relationships and key information present in corporate narratives.\n",
      "\n",
      "Chunk 298:\n",
      "This approach opens up new pos- sibilities for financial analysis and automated reasoning in the business domain that will be explored further in the future. 4.2 VectorRAG Our methodology builds upon the concept of RAG [ 9] which al- lows for the creation of a system that can provide context-aware, accurate responses to queries about company financial informa- tion, leveraging both the power of large language models and the efficiency of semantic search.\n",
      "\n",
      "Chunk 299:\n",
      "At the core of our system is a Pinecone vector database7, which serves as the foundation for our information retrieval process. We employ OpenAI’s text-embedding-ada-002 model to transform tex- tual data from earnings call transcripts into high-dimensional vec- tor representations. This vectorization process enables semantic similarity searches, significantly enhancing the relevance and ac- curacy of retrieved information.\n",
      "\n",
      "Chunk 300:\n",
      "Table 3 provides summary of the configuration of the set up in use for our experiments. LLM GPT-3.5-Turbo LLM Temperature 0 Embedding Model text-embedding-ada-002 Framework LangChain Vector Database Pinecone Chunk Size 1024 Chunk Overlap 0 Maximum Output Tokens 1024 Chunks for Similarity Algorithm 20 Number of Context Retrieved 4 Table 3: VectorRAG Configuration 7https://www.pinecone.io/The Q&A pipeline is constructed using the LangChain frame- work8.\n",
      "\n",
      "Chunk 301:\n",
      "The begins with a context retrieval step, where we query the Pinecone vector store to obtain the most relevant document chunks for a given question. This retrieval process is fine-tuned with spe- cific filters for quarters, years, and company names, ensuring that the retrieved information is both relevant and current. Following retrieval, we implement a context formatting step that consolidates the retrieved document chunks into a coherent context string.\n",
      "\n",
      "Chunk 302:\n",
      "This formatted context serves as the informational basis for the language model’s response generation. We have developed a sophisticated prompt template, that instructs the language model to function as an expert Q&A system, emphasizing the importance of utilizing only the provided context information and avoiding direct references to the context in the generated responses. For the core language processing task, we integrate OpenAI’s GPT-3.\n",
      "\n",
      "Chunk 303:\n",
      "5-turbo model which processes the formatted context and query to generate natural language responses that are informative, coherent, and contextually appropriate. To evaluate the performance of our system, we developed a comprehensive framework that includes the preparation of a cus- tom dataset of question-answer pairs specific to each company’s earnings call. Our system processes each question in this dataset, generating answers based on the retrieved context.\n",
      "\n",
      "Chunk 304:\n",
      "The evaluation results, including the original question, generated answer, retrieved contexts, and ground truth, are compiled into structured formats (CSV and JSON) to facilitate further analysis. The outputs generated by our system are stored in both CSV and JSON formats, enabling easy integration with various analysis tools and dashboards.\n",
      "\n",
      "Chunk 305:\n",
      "This approach facilitates both quantitative performance metrics and qualitative assessment of the system’s responses, providing a com- prehensive view of its effectiveness. By parameterizing company names, quarters, and years, we can easily adapt the system to different datasets and time periods. This design choice allows for seamless integration of new data and expansion to cover multiple companies and earnings calls. 4.\n",
      "\n",
      "Chunk 306:\n",
      "3 GraphRAG For GraphRAG, we developed an Q&A system specifically designed for corporate earnings call transcripts. Our implementation of GraphRAG leverages several key components and techniques: LLM GPT-3.5-Turbo LLM Temperature 0 Framework LangChain KG Manipulation Networkx Chunk Size 1024 Chunk Overlap 0 Number of Triplets 13950 Number of nodes 11405 Number of edges 13883 DFS Depth 1 Table 4: GraphRAG Configuration 8https://docs.smith.langchain.\n",
      "\n",
      "Chunk 307:\n",
      "com/old/cookbook/hub-examples/retrieval-qa-chainHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc.\n",
      "\n",
      "Chunk 308:\n",
      "New York, NY, USADhagash Mehta dhagash.mehta@blackrock.com BlackRock, Inc.\n",
      "\n",
      "Chunk 309:\n",
      "New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.\n",
      "\n",
      "Chunk 310:\n",
      "We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.\n",
      "\n",
      "Chunk 311:\n",
      "Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.\n",
      "\n",
      "Chunk 312:\n",
      "The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.\n",
      "\n",
      "Chunk 313:\n",
      "However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.\n",
      "\n",
      "Chunk 314:\n",
      "Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].\n",
      "\n",
      "Chunk 315:\n",
      "Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.\n",
      "\n",
      "Chunk 316:\n",
      "In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.\n",
      "\n",
      "Chunk 317:\n",
      "Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.\n",
      "\n",
      "Chunk 318:\n",
      "VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.\n",
      "\n",
      "Chunk 319:\n",
      "For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].\n",
      "\n",
      "Chunk 320:\n",
      "Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.\n",
      "\n",
      "Chunk 321:\n",
      "Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.\n",
      "\n",
      "Chunk 322:\n",
      "KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.\n",
      "\n",
      "Chunk 323:\n",
      "However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].\n",
      "\n",
      "Chunk 324:\n",
      "Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.\n",
      "\n",
      "Chunk 325:\n",
      "However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.\n",
      "\n",
      "Chunk 326:\n",
      "By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.\n",
      "\n",
      "Chunk 327:\n",
      "In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.\n",
      "\n",
      "Chunk 328:\n",
      "1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].\n",
      "\n",
      "Chunk 329:\n",
      "Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.\n",
      "\n",
      "Chunk 330:\n",
      "We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.\n",
      "\n",
      "Chunk 331:\n",
      "2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.\n",
      "\n",
      "Chunk 332:\n",
      "This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.\n",
      "\n",
      "Chunk 333:\n",
      "This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.\n",
      "\n",
      "Chunk 334:\n",
      "In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.\n",
      "\n",
      "Chunk 335:\n",
      "The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.\n",
      "\n",
      "Chunk 336:\n",
      "The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.\n",
      "\n",
      "Chunk 337:\n",
      ", a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.\n",
      "\n",
      "Chunk 338:\n",
      "htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Figure 1: A schematic diagram describing the vector database creation of a RAG application. improvement, and knowledge adaptation [ 28]. Here, we do not use knowledge adaptation and treat the KGs as static graphs.\n",
      "\n",
      "Chunk 339:\n",
      "Knowledge Extraction:- This step aims to extract structured in- formation from unstructured or semi-structured data, such as text, databases, and existing ontologies. The main tasks in this step are entity recognition, relationship extraction, and co-reference reso- lution. Entity recognition and relationship extraction techniques use typical NLP tasks to identify entities and their relationships from textual sources [ 29].\n",
      "\n",
      "Chunk 340:\n",
      "Coreference resolution identifies and connects different references of the same entity, keeping coherence within the knowledge graph. For example, if the text refers to a company as both \"the company\" and \"it\", coreference resolution can link these mentions to the same entity node in the graph. Knowledge Improvement:- This step aims to enhance the quality and completeness of the KG by removing redundancies and address- ing gaps in the extracted information.\n",
      "\n",
      "Chunk 341:\n",
      "The primary tasks in this step are KG completion and fusion. KG completion technique infers missing entities and relationships within the graph using meth- ods such as link prediction and entity resolution. Link prediction predicts the existence and type of a relation between two entities based on the graph structure and features, while entity resolution matches and merges different representations of the same entity from different sources.\n",
      "\n",
      "Chunk 342:\n",
      "Knowledge fusion combines information from multiple sources to create a coherent and unified KG. This involves resolving conflicts and redundancies among the sources, such as contradictory or duplicate facts, and aggregating or reconciling the information based on rules, probabilities, or semantic similarity. We utilized a robust methodology for creating KG triplets from unstructured text data, specifically focusing on corporate docu- ments such as earnings call transcripts, adapted from Ref.\n",
      "\n",
      "Chunk 343:\n",
      "[ 18?]. This process involves several interconnected stages, each designed to extract, refine, and structure information effectively. We implement a two-tiered LLM chain for content refinement and information extraction. The first tier employs an LLM to gen- erate an abstract representation of each document chunk.\n",
      "\n",
      "Chunk 344:\n",
      "This refinement process is crucial as it distills the essential information while preserving the original meaning and key relationships be- tween concepts that serves as a more focused input for subsequent processing, enhancing the overall efficiency and accuracy of ourtriplet extraction pipeline. The second tier of our LLM chain is dedicated to entity extraction and relationship identification. Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM.\n",
      "\n",
      "Chunk 345:\n",
      "A detailed discussion on imple- mentation of the methodology will be provided in Section 4.1 2.3 GraphRAG KG based RAG [ 22], or GraphRAG, also begins with a query based on the user’s input same as VectorRAG. The main difference be- tween VectorRAG and GraphRAG lies in the retrieval part. The query here is now used to search the KG to retrieve relevant nodes (entities) and edges (relationships) related to the query.\n",
      "\n",
      "Chunk 346:\n",
      "A subgraph, which consists of these relevant nodes and edges, is extracted from the full KG to provide context. This subgraph is then integrated with the language model’s internal knowledge, by encoding the graph structure into embeddings that the model can interpret. The language model uses this combined context to generate responses that are informed by both the structured information from the KG and its pre-trained knowledge.\n",
      "\n",
      "Chunk 347:\n",
      "Crucially, when responding to user queries about a particular company, we leveraged the metadata information to selectively filter and retrieve only those document segments pertinent to the queried company [ 8]. This integration helps ensure that the generated outputs are accurate, contextually relevant, and grounded in verifiable information. A schematic diagram of the retrieval methodology of GraphRAG is given in Figure 2.\n",
      "\n",
      "Chunk 348:\n",
      "Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section 4.1 Figure 2: A schematic diagram describing knowledge graph creation process of GraphRAG. 2.3.1 HybridRAG. For the HybridRAG technique, we propose to integrate the aforementioned two distinct RAG techniques: Vec- torRAG and GraphRAG.\n",
      "\n",
      "Chunk 349:\n",
      "This integration involves a systematic combination of contextual information retrieved from both the traditional vector-based retrieval mechanism and the KG-based retrieval system, the latter of which was constructed specifically for this study. The amalgamation of these two contexts allows us to leverage the strengths of both approaches.\n",
      "\n",
      "Chunk 350:\n",
      "The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-richSarmah et al. contextual data. This combined context is then utilized as input for a LLM to generate the final responses. Details on the implementation of the HybridRAG will be provided in Section 4.4. 2.\n",
      "\n",
      "Chunk 351:\n",
      "4 Evaluation Metrics To assess the efficacy of this integrated approach, we conducted a comparative analysis among the three approaches in a controlled ex- perimental set up: VectorRAG, GraphRAG and HybridRAG. The re- sponses generated using the combined VectorRAG and GraphRAG contexts were juxtaposed against those produced individually by VectorRAG and GraphRAG.\n",
      "\n",
      "Chunk 352:\n",
      "This comparative evaluation aimed to discern potential improvements in response quality, accuracy, and comprehensiveness that might arise from the synergistic integra- tion of these two RAG methodologies. To objectively evaluate different RAG approaches (VectorRAG and GraphRAG in their case), Ref. [ 22] utilized metrics such as comprehensiveness (i.e., the amount of details the answer provides to cover all aspects and details of the question?); diversity (i.e.\n",
      "\n",
      "Chunk 353:\n",
      ", the richness of the answer in providing different perspectives and insights on the question); empowerment (i.e., the helpfulness of the answer to the reader understand and make informed judgements about the topic); and, directness (i.e., clearness of the answer in addressing the question). here, the LLM was provided tuples of question, target metric, and a pair of answers, and was asked to assess which answer was better according to the metric and why.\n",
      "\n",
      "Chunk 354:\n",
      "These metrics though compare the final generated answers, do not necessarily directly evaluate the retrieval and generation parts separately. Instead, here we implement a comprehensive set of evaluation metrics which are designed to capture different aspects of a given RAG system’s output quality, focusing on faithfulness, answer relevance, and context relevance [ 30]. Each metric provides unique insights into the system’s capabilities and limitations. 2.4.1 Faithfulness.\n",
      "\n",
      "Chunk 355:\n",
      "Faithfulness is a crucial metric that measures the extent to which the generated answer can be inferred from the provided context. Our implementation of the faithfulness metric involves a two-step process: Statement Extraction:- We use an LLM to decompose the gener- ated answer into a set of concise statements. This step is crucial for breaking down complex answers into more manageable and verifiable units.\n",
      "\n",
      "Chunk 356:\n",
      "The prompt used for this step is: \"Given a question and answer, create one or more statements from each sentence in the given answer. question: [question] an- swer: [answer]\". Statement Verification:- For each extracted statement, we employ the LLM to determine if it can be inferred from the given context.\n",
      "\n",
      "Chunk 357:\n",
      "This verification process uses the following prompt: \"Consider the given context and following statements, then de- termine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. statement: [statement 1] ... statement: [statement n]\".\n",
      "\n",
      "Chunk 358:\n",
      "The faithfulness score ( 𝐹) is𝐹=|𝑉|/|𝑆|, where |𝑉|is the number of supported statements and |𝑆|is the total number of statements.2.4.2 Answer Relevance:-. The answer relevance metric assesses how well the generated answer addresses the original question, irrespective of factual accuracy. This metric helps identify cases of incomplete answers or responses containing irrelevant information.\n",
      "\n",
      "Chunk 359:\n",
      "Our implementation involves the following steps: Question Generation: We prompt the LLM to generate n potential questions based on the given answer: \"Generate a question for the given answer. answer: [answer]\". Then, we obtain embeddings for all generated questions and the original question using OpenAI’s text-embedding-ada-002 model2. We then calculate the cosine similarity between each generated question’s embedding and the original question’s embedding.\n",
      "\n",
      "Chunk 360:\n",
      "Finally, the answer relevance score (AR) is computed as the aver- age similarity across all generated questions: 𝐴𝑅=1 𝑛Í(𝑠𝑖𝑚(𝑞,𝑞𝑖)), where𝑠𝑖𝑚(𝑞,𝑞𝑖)is the cosine similarity between the embedding of the original question 𝑞and the embeddings of each of the 𝑛 generated questions 𝑞𝑖. 2.4.3 Context Precision. It is a metric used to evaluate the relevance of retrieved context chunks in relation to a specified ground truth for a given question3.\n",
      "\n",
      "Chunk 361:\n",
      "It calculates the proportion of relevant items that appear in the top ranks of the context. The formula for context precision at K is the sum of the products of precision at each rank k and a binary relevance indicator v_k, divided by the total number of relevant items in the top K results. Precision at each rank k is determined by the ratio of true positives at k to the sum of true positives and false positives at k.\n",
      "\n",
      "Chunk 362:\n",
      "This metric helps in assessing how well the context supports the ground truth, aiming for higher scores which indicate better precision. 2.4.4 Context Recall. It is a metric used to evaluate how well the retrieved context aligns with the ground truth answer, which is considered the definitive correct response4. It is quantified by com- paring each sentence in the ground truth answer to see if it can be traced back to the retrieved context.\n",
      "\n",
      "Chunk 363:\n",
      "The formula for context recall is the ratio of the number of ground truth sentences that can be attributed to the context to the total number of sentences in the ground truth. Higher values, ranging from 0 to 1, indicate bet- ter alignment and thus better context recall. This metric is crucial for assessing the effectiveness of information retrieval systems in providing relevant context.\n",
      "\n",
      "Chunk 364:\n",
      "3 DATA DESCRIPTION Although there do exist some public financial datasets, none of them were suitable for the present experiments: e.g., FinQA [ 31], TAT- QA [ 32], FIQA [ 33], FinanceBench [ 34], etc. datasets are limited to specific usecases such as benchmarking LLMs’ abilities to perform complex numerical reasoning or sentiment analysis. On the other hand, FinTextQA [ 35] dataset was not publicly available at the time of writing the present work.\n",
      "\n",
      "Chunk 365:\n",
      "In addition, in most of these datasets, access to the actual documents from which the ground- truth Q&As were created is not available, making it impossible to use them for our RAG techniques evaluation purposes. Hence, we resorted to a dataset of our own though through publicly available 2https://platform.openai.com/docs/guides/embeddings/embedding-models 3https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html 4https://docs.ragas.io/en/stable/concepts/metrics/context_recall.\n",
      "\n",
      "Chunk 366:\n",
      "htmlHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction documents but such that we finally have access to both the actual financial documents and the ground-truth Q&As. Datasets like FinanceBench5provides question-context-answer triplets but they are not useful as here we are comparing VectorRAG, GraphRAG and HybridRAG and they do not provide the context generated from a KG.\n",
      "\n",
      "Chunk 367:\n",
      "A recent paper [ 22] has not made the KG and triplets constructed by their algorithm public to the best of our knowledge either. In short, there is no publicly available benchmark dataset to compare VectorRAG and GraphRAG either for financial or general domains to the best of our knowledge. Hence, we had to rely on our own dataset constructed as explained below. We used transcripts from earnings calls of Nifty 50 constituents for our analysis.\n",
      "\n",
      "Chunk 368:\n",
      "The NIFTY 50 is popular index in the Indian stock market that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange (NSE). The dataset of the earning call documents of Nifty 50 companies is widely recognized in the investment realm and is esteemed as an authoritative and extensive collection of earnings call transcripts. In our investigation, we focus on data spanning the quarter ending in June, 2023 i.e.\n",
      "\n",
      "Chunk 369:\n",
      "the earnings reports for Q1 of the financial year 2024 (A financial year in India starts on the 1st April and ends in 31st March, so the quarter from 1st April to 30th June is the first quarter of 2024 for the Indian market).\n",
      "\n",
      "Chunk 370:\n",
      "Our dataset encompasses 50 transcripts for this quarter, span- ning over 50 companies within Nifty 50 universe from diverse range of sectors including Infrastructure, Healthcare, Consumer Durables, Banking, Automobile, Financial Services, Energy - Oil & Gas, Telecommunication, Consumer Goods, Pharmaceuticals, Energy - Coal, Materials, Information Technology, Construction, Diversified, Metals, Energy - Power and Chemicals providing a substantial and diverse foundation for our study.\n",
      "\n",
      "Chunk 371:\n",
      "We start the data collection process focused on acquiring earn- ings reports from company websites within the Nifty 50 universe by developing and deploying a custom web scraping tool to navigate through the websites of each company within the Nifty 50 index, systematically retrieving the pertinent earnings reports for Q1 of the financial year 2024. By utilizing this web scraping approach, we aimed to compile a comprehensive dataset encompassing the earnings reports of the constituent companies.\n",
      "\n",
      "Chunk 372:\n",
      "Table 1 summarizes basic statistics of the documents we will be experimenting with in the remainder of this work. Number of companies/documents 50 Average number of pages 27 Average number of questions 16 Average number of tokens 60,000 Table 1: Summary Statistics for the call transcript documents used in the present work.\n",
      "\n",
      "Chunk 373:\n",
      "These call transcripts documents consist of questions and an- swers between financial analysts and the company representatives for the respective companies, hence, there already exist certain Q&A pairs within these documents along with additional text. We examined the earnings reports within the Nifty50 universe, system- atically curated a comprehensive array of randomly selected 400 5https://huggingface.\n",
      "\n",
      "Chunk 374:\n",
      "co/datasets/PatronusAI/financebench-testquestions posed during the earnings calls from all the documents, and gathered the exact responses corresponding to these questions. These questions constitute the specific queries articulated by finan- cial analysts to the management during these calls. 4 IMPLEMENTATION DETAILS In this Section, we provide details of implementation of the pro- posed methodology. 4.\n",
      "\n",
      "Chunk 375:\n",
      "1 Knowledge Graph Construction The initial phase of our approach centers on document preprocess- ing. We utilize the PyPDFLoader6to import PDF documents, which are subsequently segmented into manageable chunks using the RecursiveCharacterTextSplitter. This chunking strategy employs a size of 2024 characters with an overlap of 204 characters, ensuring comprehensive coverage while maintaining context across segment boundaries.\n",
      "\n",
      "Chunk 376:\n",
      "Following the preprocessing stage, we implement the two-tiered language model chain for content refinement and information ex- traction. It is not possible to include the exact prompt here due to the limited space, but a baseline prompt can be found in Ref. [18].\n",
      "\n",
      "Chunk 377:\n",
      "Entity Type Examples Companies and Corpo- rationsOfficial names, abbreviations, infor- mal references Financial Metrics and IndicatorsRevenue, profit margins, EBITDA Corporate Executives and Key PersonnelCEOs, CFOs, board members Products and Services Tangible products and intangible ser- vices Geographical Locations Headquarters, operational regions, markets Corporate Events Mergers, acquisitions, product launches, earnings calls Legal and Regulatory InformationLegal cases, regulatory compliance Table 2: Entities extracted from earnings call transcripts Table 2 summarizes details on entities extracted from the earn- ing calls transcripts using our prompt based method.\n",
      "\n",
      "Chunk 378:\n",
      "Concurrently, LLM identifies relationships between these entities using a curated set of verbs, capturing the nuanced interactions within the cor- porate narrative. A key improvement in our methodology is the enhanced prompt engineering to generate the structured output format for knowledge triplets.\n",
      "\n",
      "Chunk 379:\n",
      "Each triplet is represented as a nested list [’h’, ’type’, ’r’, ’o’, ’type’, ’metadata’], where ’h’ and ’o’ denote the head and object entities respectively, ’type’ specifies the entity category, ’r’ represents the relationship, and ’metadata’ encapsu- lates additional contextual information. This format allows for a rich, multidimensional representation of information, facilitating more nuanced downstream analysis. 6https://python.langchain.com/v0.\n",
      "\n",
      "Chunk 380:\n",
      "1/docs/modules/data_connection/document_ loaders/pdf/Sarmah et al. Our process incorporates several advanced features to enhance the quality and utility of the extracted triplets. Entity disambigua- tion techniques are employed to consolidate different references to the same entity, improving consistency across the KG.\n",
      "\n",
      "Chunk 381:\n",
      "We also pri- oritize conciseness in entity representation, aiming for descriptions of less than four words where possible, which aids in maintaining a clean and navigable graph structure. The extraction pipeline is applied iteratively to each document chunk, with results aggregated to form a comprehensive knowledge graph representation of the entire document, allowing for scalable processing of large documents while maintaining local context within each chunk.\n",
      "\n",
      "Chunk 382:\n",
      "We have added explicit instruction on obtaining metadata following Ref. [8] for both VectorRAG and GraphRAG. Finally, we implement a data persistence strategy, converting the extracted triplets from their initial string format to Python data structures and storing them in a pickle file. This facilitates easy retrieval and further manipulation of the knowledge graph data in subsequent analysis stages.\n",
      "\n",
      "Chunk 383:\n",
      "Our methodology represents a significant advancement in auto- mated knowledge extraction from corporate documents. By com- bining advanced NLP techniques with a structured approach to information representation, we create a rich, queryable knowledge base that captures the complex relationships and key information present in corporate narratives.\n",
      "\n",
      "Chunk 384:\n",
      "This approach opens up new pos- sibilities for financial analysis and automated reasoning in the business domain that will be explored further in the future. 4.2 VectorRAG Our methodology builds upon the concept of RAG [ 9] which al- lows for the creation of a system that can provide context-aware, accurate responses to queries about company financial informa- tion, leveraging both the power of large language models and the efficiency of semantic search.\n",
      "\n",
      "Chunk 385:\n",
      "At the core of our system is a Pinecone vector database7, which serves as the foundation for our information retrieval process. We employ OpenAI’s text-embedding-ada-002 model to transform tex- tual data from earnings call transcripts into high-dimensional vec- tor representations. This vectorization process enables semantic similarity searches, significantly enhancing the relevance and ac- curacy of retrieved information.\n",
      "\n",
      "Chunk 386:\n",
      "Table 3 provides summary of the configuration of the set up in use for our experiments. LLM GPT-3.5-Turbo LLM Temperature 0 Embedding Model text-embedding-ada-002 Framework LangChain Vector Database Pinecone Chunk Size 1024 Chunk Overlap 0 Maximum Output Tokens 1024 Chunks for Similarity Algorithm 20 Number of Context Retrieved 4 Table 3: VectorRAG Configuration 7https://www.pinecone.io/The Q&A pipeline is constructed using the LangChain frame- work8.\n",
      "\n",
      "Chunk 387:\n",
      "The begins with a context retrieval step, where we query the Pinecone vector store to obtain the most relevant document chunks for a given question. This retrieval process is fine-tuned with spe- cific filters for quarters, years, and company names, ensuring that the retrieved information is both relevant and current. Following retrieval, we implement a context formatting step that consolidates the retrieved document chunks into a coherent context string.\n",
      "\n",
      "Chunk 388:\n",
      "This formatted context serves as the informational basis for the language model’s response generation. We have developed a sophisticated prompt template, that instructs the language model to function as an expert Q&A system, emphasizing the importance of utilizing only the provided context information and avoiding direct references to the context in the generated responses. For the core language processing task, we integrate OpenAI’s GPT-3.\n",
      "\n",
      "Chunk 389:\n",
      "5-turbo model which processes the formatted context and query to generate natural language responses that are informative, coherent, and contextually appropriate. To evaluate the performance of our system, we developed a comprehensive framework that includes the preparation of a cus- tom dataset of question-answer pairs specific to each company’s earnings call. Our system processes each question in this dataset, generating answers based on the retrieved context.\n",
      "\n",
      "Chunk 390:\n",
      "The evaluation results, including the original question, generated answer, retrieved contexts, and ground truth, are compiled into structured formats (CSV and JSON) to facilitate further analysis. The outputs generated by our system are stored in both CSV and JSON formats, enabling easy integration with various analysis tools and dashboards.\n",
      "\n",
      "Chunk 391:\n",
      "This approach facilitates both quantitative performance metrics and qualitative assessment of the system’s responses, providing a com- prehensive view of its effectiveness. By parameterizing company names, quarters, and years, we can easily adapt the system to different datasets and time periods. This design choice allows for seamless integration of new data and expansion to cover multiple companies and earnings calls. 4.\n",
      "\n",
      "Chunk 392:\n",
      "3 GraphRAG For GraphRAG, we developed an Q&A system specifically designed for corporate earnings call transcripts. Our implementation of GraphRAG leverages several key components and techniques: LLM GPT-3.5-Turbo LLM Temperature 0 Framework LangChain KG Manipulation Networkx Chunk Size 1024 Chunk Overlap 0 Number of Triplets 13950 Number of nodes 11405 Number of edges 13883 DFS Depth 1 Table 4: GraphRAG Configuration 8https://docs.smith.langchain.\n",
      "\n",
      "Chunk 393:\n",
      "com/old/cookbook/hub-examples/retrieval-qa-chainHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Knowledge Graph Construction:- We begin by constructing a KG from a set of knowledge triplets extracted from corporate documents using the prompt engineering based methodology as described in Section 4.1.\n",
      "\n",
      "Chunk 394:\n",
      "These triplets, stored in a pickle file, repre- sent structured information in the form of subject-predicate-object relationships. We use the NetworkxEntityGraph class from the LangChain library to create and manage this graph structure. Each triple is added to the graph, which encapsulates the head entity, relation, tail entity, and additional metadata. We implement the Q&A functionality using the GraphQAChain class from LangChain.\n",
      "\n",
      "Chunk 395:\n",
      "This chain combines the KG with an LLM (in our case, OpenAI’s GPT-3.5-turbo) to generate responses. The GraphQAChain traverses the KG to find relevant information and uses the language model to formulate coherent answers based on the retrieved context. A summary of configuration of our LLM models and other libraries used for GraphRAG is shown in Table 4.\n",
      "\n",
      "Chunk 396:\n",
      "In KG as the information is stored in the form of entities and relationships and there can be multiple relations emanating from one single entity, in this experiment, to extract relevant information from the KG, we employ a depth-first search strategy constrained by a depth of one from the specified entity.\n",
      "\n",
      "Chunk 397:\n",
      "To prepare for assessing the performance of our GraphRAG system, we follow the below steps: Dataset Preparation:- We use a pre-generated CSV file containing question-answer pairs specific to the earnings call transcript. Iterative Processing:- For each question in the dataset, we run the GraphQAChain to generate an answer. Result Compilation:- We compile the results, including the origi- nal questions, generated answers, retrieved contexts, and ground truth answers, into a structured format.\n",
      "\n",
      "Chunk 398:\n",
      "Finally, the evaluation results are saved in both CSV and JSON formats for further analysis and comparison. We then fed these outputs into our RAG evaluation pipeline. For each Q&A pair in our dataset, we compute all three metrics: faithfulness, answer relevance, context precision and context recall. 4.\n",
      "\n",
      "Chunk 399:\n",
      "4 HybridRAG For the proposed HybridRAG technique, upon obtaining all the contextual information from VectorRAG and GraphRAG, we con- catenate these contexts to form a unified context utilizing both techniques. This combined context is then fed into the answer gen- erator model to produce a response. The context used for response generation is relatively larger, which affects the precision of the generated response.\n",
      "\n",
      "Chunk 400:\n",
      "The context from VectorRAG is appended first, followed by the context from GraphRAG. Consequently, the preci- sion of the generated answer depends on the source context. If the answer is generated from the GraphRAG context, it will have lower precision, as the GraphRAG context is added last in the sequence of contexts provided to the answer generator model, and vice versa. 5 RESULTS We evaluate both the retrieval and generation parts of RAG for the three different RAG pipelines.\n",
      "\n",
      "Chunk 401:\n",
      "Evaluating the RAG outputs is also an active area of research there is no standard tool which is universally accepted as of yet, though we use a currently popular framework RAGAS[ 30] to evaluate the three RAG pipelines in thepresent work where we have modified them a bit to make more precise comparisons. The results of our comparative analysis reveal notable differences in performance among VectorRAG, GraphRAG, and HybridRAG approaches as summarized in Table 5.\n",
      "\n",
      "Chunk 402:\n",
      "In terms of Faithfulness, GraphRAG and HybridRAG demonstrated superior performance, both achieving a score of 0.96, while VectorRAG trailed slightly with a score of 0.94. Answer relevancy scores varied across the meth- ods, with HybridRAG outperforming the others at 0.96, followed by VectorRAG at 0.91, and GraphRAG at 0.89. Context precision was highest for GraphRAG at 0.96, significantly surpassing Vec- torRAG (0.84) and HybridRAG (0.79).\n",
      "\n",
      "Chunk 403:\n",
      "However, in context recall, both VectorRAG and HybridRAG achieved perfect scores of 1, while GraphRAG lagged behind at 0.85. Overall, these results suggest that GraphRAG offers improve- ments over VectorRAG, particularly in faithfulness and context pre- cision. Furthermore, HybridRAG emerges as the most balanced and effective approach, outperforming both VectorRAG and GraphRAG in key metrics such as faithfulness and answer relevancy, while maintaining high context recall.\n",
      "\n",
      "Chunk 404:\n",
      "The relatively lower context precision observed for HybridRAG (0.79) can be attributed to its unique approach of combining con- texts from both VectorRAG and GraphRAG methods. While this integration allows for more comprehensive information retrieval, it also introduces additional content that may not align precisely with the ground truth, thus affecting the context precision met- ric.\n",
      "\n",
      "Chunk 405:\n",
      "Despite this trade-off, HybridRAG’s superior performance in faithfulness, answer relevancy, and context recall underscores its effectiveness. When considering the overall evaluation metrics, HybridRAG emerges as the most promising approach, balancing high-quality answers with comprehensive context retrieval. Overall GraphRAG performs better in extractive questions com- pared to VectorRAG.\n",
      "\n",
      "Chunk 406:\n",
      "And VectorRAG does better in abstractive questions where information is not explicitly mentioned in the raw data. And also GraphRAG sometimes fails to answer ques- tions correctly whenever there is no entity explicitly mentioned in the question. So HybridRAG does a good job overall, as whenever VectorRAG fails to fetch correct context in extractive questions it falls back to GraphRAG to generate the answer.\n",
      "\n",
      "Chunk 407:\n",
      "And whenever GraphRAG fails to fetch correct context in abstractive questions it falls back to VectorRAG to generate the answer. VectorRAG GraphRAG HybridRAG F 0.94 0.96 0.96 AR 0.91 0.89 0.96 CP 0.84 0.96 0.79 CR 1 0.85 1 Table 5: Performance Metrics for Different RAG Pipelines. Here, F, AR, CP and CR refer to Faithfulness, Answer Relevence, Context Precision and Context Recall.\n",
      "\n",
      "Chunk 408:\n",
      "6 CONCLUSION AND FUTURE DIRECTIONS Among the current approaches to mitigate issues regarding infor- mation extraction from external documents that were not part ofHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.\n",
      "\n",
      "Chunk 409:\n",
      "com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc. New York, NY, USADhagash Mehta dhagash.mehta@blackrock.com BlackRock, Inc.\n",
      "\n",
      "Chunk 410:\n",
      "New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.\n",
      "\n",
      "Chunk 411:\n",
      "We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.\n",
      "\n",
      "Chunk 412:\n",
      "Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.\n",
      "\n",
      "Chunk 413:\n",
      "The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.\n",
      "\n",
      "Chunk 414:\n",
      "However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.\n",
      "\n",
      "Chunk 415:\n",
      "Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].\n",
      "\n",
      "Chunk 416:\n",
      "Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.\n",
      "\n",
      "Chunk 417:\n",
      "In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.\n",
      "\n",
      "Chunk 418:\n",
      "Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.\n",
      "\n",
      "Chunk 419:\n",
      "VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.\n",
      "\n",
      "Chunk 420:\n",
      "For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].\n",
      "\n",
      "Chunk 421:\n",
      "Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.\n",
      "\n",
      "Chunk 422:\n",
      "Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.\n",
      "\n",
      "Chunk 423:\n",
      "KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.\n",
      "\n",
      "Chunk 424:\n",
      "However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].\n",
      "\n",
      "Chunk 425:\n",
      "Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.\n",
      "\n",
      "Chunk 426:\n",
      "However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.\n",
      "\n",
      "Chunk 427:\n",
      "By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.\n",
      "\n",
      "Chunk 428:\n",
      "In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.\n",
      "\n",
      "Chunk 429:\n",
      "1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].\n",
      "\n",
      "Chunk 430:\n",
      "Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.\n",
      "\n",
      "Chunk 431:\n",
      "We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.\n",
      "\n",
      "Chunk 432:\n",
      "2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.\n",
      "\n",
      "Chunk 433:\n",
      "This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.\n",
      "\n",
      "Chunk 434:\n",
      "This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.\n",
      "\n",
      "Chunk 435:\n",
      "In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.\n",
      "\n",
      "Chunk 436:\n",
      "The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.\n",
      "\n",
      "Chunk 437:\n",
      "The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.\n",
      "\n",
      "Chunk 438:\n",
      ", a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.\n",
      "\n",
      "Chunk 439:\n",
      "htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Figure 1: A schematic diagram describing the vector database creation of a RAG application. improvement, and knowledge adaptation [ 28]. Here, we do not use knowledge adaptation and treat the KGs as static graphs.\n",
      "\n",
      "Chunk 440:\n",
      "Knowledge Extraction:- This step aims to extract structured in- formation from unstructured or semi-structured data, such as text, databases, and existing ontologies. The main tasks in this step are entity recognition, relationship extraction, and co-reference reso- lution. Entity recognition and relationship extraction techniques use typical NLP tasks to identify entities and their relationships from textual sources [ 29].\n",
      "\n",
      "Chunk 441:\n",
      "Coreference resolution identifies and connects different references of the same entity, keeping coherence within the knowledge graph. For example, if the text refers to a company as both \"the company\" and \"it\", coreference resolution can link these mentions to the same entity node in the graph. Knowledge Improvement:- This step aims to enhance the quality and completeness of the KG by removing redundancies and address- ing gaps in the extracted information.\n",
      "\n",
      "Chunk 442:\n",
      "The primary tasks in this step are KG completion and fusion. KG completion technique infers missing entities and relationships within the graph using meth- ods such as link prediction and entity resolution. Link prediction predicts the existence and type of a relation between two entities based on the graph structure and features, while entity resolution matches and merges different representations of the same entity from different sources.\n",
      "\n",
      "Chunk 443:\n",
      "Knowledge fusion combines information from multiple sources to create a coherent and unified KG. This involves resolving conflicts and redundancies among the sources, such as contradictory or duplicate facts, and aggregating or reconciling the information based on rules, probabilities, or semantic similarity. We utilized a robust methodology for creating KG triplets from unstructured text data, specifically focusing on corporate docu- ments such as earnings call transcripts, adapted from Ref.\n",
      "\n",
      "Chunk 444:\n",
      "[ 18?]. This process involves several interconnected stages, each designed to extract, refine, and structure information effectively. We implement a two-tiered LLM chain for content refinement and information extraction. The first tier employs an LLM to gen- erate an abstract representation of each document chunk.\n",
      "\n",
      "Chunk 445:\n",
      "This refinement process is crucial as it distills the essential information while preserving the original meaning and key relationships be- tween concepts that serves as a more focused input for subsequent processing, enhancing the overall efficiency and accuracy of ourtriplet extraction pipeline. The second tier of our LLM chain is dedicated to entity extraction and relationship identification. Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM.\n",
      "\n",
      "Chunk 446:\n",
      "A detailed discussion on imple- mentation of the methodology will be provided in Section 4.1 2.3 GraphRAG KG based RAG [ 22], or GraphRAG, also begins with a query based on the user’s input same as VectorRAG. The main difference be- tween VectorRAG and GraphRAG lies in the retrieval part. The query here is now used to search the KG to retrieve relevant nodes (entities) and edges (relationships) related to the query.\n",
      "\n",
      "Chunk 447:\n",
      "A subgraph, which consists of these relevant nodes and edges, is extracted from the full KG to provide context. This subgraph is then integrated with the language model’s internal knowledge, by encoding the graph structure into embeddings that the model can interpret. The language model uses this combined context to generate responses that are informed by both the structured information from the KG and its pre-trained knowledge.\n",
      "\n",
      "Chunk 448:\n",
      "Crucially, when responding to user queries about a particular company, we leveraged the metadata information to selectively filter and retrieve only those document segments pertinent to the queried company [ 8]. This integration helps ensure that the generated outputs are accurate, contextually relevant, and grounded in verifiable information. A schematic diagram of the retrieval methodology of GraphRAG is given in Figure 2.\n",
      "\n",
      "Chunk 449:\n",
      "Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section 4.1 Figure 2: A schematic diagram describing knowledge graph creation process of GraphRAG. 2.3.1 HybridRAG. For the HybridRAG technique, we propose to integrate the aforementioned two distinct RAG techniques: Vec- torRAG and GraphRAG.\n",
      "\n",
      "Chunk 450:\n",
      "This integration involves a systematic combination of contextual information retrieved from both the traditional vector-based retrieval mechanism and the KG-based retrieval system, the latter of which was constructed specifically for this study. The amalgamation of these two contexts allows us to leverage the strengths of both approaches.\n",
      "\n",
      "Chunk 451:\n",
      "The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-richSarmah et al. contextual data. This combined context is then utilized as input for a LLM to generate the final responses. Details on the implementation of the HybridRAG will be provided in Section 4.4. 2.\n",
      "\n",
      "Chunk 452:\n",
      "4 Evaluation Metrics To assess the efficacy of this integrated approach, we conducted a comparative analysis among the three approaches in a controlled ex- perimental set up: VectorRAG, GraphRAG and HybridRAG. The re- sponses generated using the combined VectorRAG and GraphRAG contexts were juxtaposed against those produced individually by VectorRAG and GraphRAG.\n",
      "\n",
      "Chunk 453:\n",
      "This comparative evaluation aimed to discern potential improvements in response quality, accuracy, and comprehensiveness that might arise from the synergistic integra- tion of these two RAG methodologies. To objectively evaluate different RAG approaches (VectorRAG and GraphRAG in their case), Ref. [ 22] utilized metrics such as comprehensiveness (i.e., the amount of details the answer provides to cover all aspects and details of the question?); diversity (i.e.\n",
      "\n",
      "Chunk 454:\n",
      ", the richness of the answer in providing different perspectives and insights on the question); empowerment (i.e., the helpfulness of the answer to the reader understand and make informed judgements about the topic); and, directness (i.e., clearness of the answer in addressing the question). here, the LLM was provided tuples of question, target metric, and a pair of answers, and was asked to assess which answer was better according to the metric and why.\n",
      "\n",
      "Chunk 455:\n",
      "These metrics though compare the final generated answers, do not necessarily directly evaluate the retrieval and generation parts separately. Instead, here we implement a comprehensive set of evaluation metrics which are designed to capture different aspects of a given RAG system’s output quality, focusing on faithfulness, answer relevance, and context relevance [ 30]. Each metric provides unique insights into the system’s capabilities and limitations. 2.4.1 Faithfulness.\n",
      "\n",
      "Chunk 456:\n",
      "Faithfulness is a crucial metric that measures the extent to which the generated answer can be inferred from the provided context. Our implementation of the faithfulness metric involves a two-step process: Statement Extraction:- We use an LLM to decompose the gener- ated answer into a set of concise statements. This step is crucial for breaking down complex answers into more manageable and verifiable units.\n",
      "\n",
      "Chunk 457:\n",
      "The prompt used for this step is: \"Given a question and answer, create one or more statements from each sentence in the given answer. question: [question] an- swer: [answer]\". Statement Verification:- For each extracted statement, we employ the LLM to determine if it can be inferred from the given context.\n",
      "\n",
      "Chunk 458:\n",
      "This verification process uses the following prompt: \"Consider the given context and following statements, then de- termine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. statement: [statement 1] ... statement: [statement n]\".\n",
      "\n",
      "Chunk 459:\n",
      "The faithfulness score ( 𝐹) is𝐹=|𝑉|/|𝑆|, where |𝑉|is the number of supported statements and |𝑆|is the total number of statements.2.4.2 Answer Relevance:-. The answer relevance metric assesses how well the generated answer addresses the original question, irrespective of factual accuracy. This metric helps identify cases of incomplete answers or responses containing irrelevant information.\n",
      "\n",
      "Chunk 460:\n",
      "Our implementation involves the following steps: Question Generation: We prompt the LLM to generate n potential questions based on the given answer: \"Generate a question for the given answer. answer: [answer]\". Then, we obtain embeddings for all generated questions and the original question using OpenAI’s text-embedding-ada-002 model2. We then calculate the cosine similarity between each generated question’s embedding and the original question’s embedding.\n",
      "\n",
      "Chunk 461:\n",
      "Finally, the answer relevance score (AR) is computed as the aver- age similarity across all generated questions: 𝐴𝑅=1 𝑛Í(𝑠𝑖𝑚(𝑞,𝑞𝑖)), where𝑠𝑖𝑚(𝑞,𝑞𝑖)is the cosine similarity between the embedding of the original question 𝑞and the embeddings of each of the 𝑛 generated questions 𝑞𝑖. 2.4.3 Context Precision. It is a metric used to evaluate the relevance of retrieved context chunks in relation to a specified ground truth for a given question3.\n",
      "\n",
      "Chunk 462:\n",
      "It calculates the proportion of relevant items that appear in the top ranks of the context. The formula for context precision at K is the sum of the products of precision at each rank k and a binary relevance indicator v_k, divided by the total number of relevant items in the top K results. Precision at each rank k is determined by the ratio of true positives at k to the sum of true positives and false positives at k.\n",
      "\n",
      "Chunk 463:\n",
      "This metric helps in assessing how well the context supports the ground truth, aiming for higher scores which indicate better precision. 2.4.4 Context Recall. It is a metric used to evaluate how well the retrieved context aligns with the ground truth answer, which is considered the definitive correct response4. It is quantified by com- paring each sentence in the ground truth answer to see if it can be traced back to the retrieved context.\n",
      "\n",
      "Chunk 464:\n",
      "The formula for context recall is the ratio of the number of ground truth sentences that can be attributed to the context to the total number of sentences in the ground truth. Higher values, ranging from 0 to 1, indicate bet- ter alignment and thus better context recall. This metric is crucial for assessing the effectiveness of information retrieval systems in providing relevant context.\n",
      "\n",
      "Chunk 465:\n",
      "3 DATA DESCRIPTION Although there do exist some public financial datasets, none of them were suitable for the present experiments: e.g., FinQA [ 31], TAT- QA [ 32], FIQA [ 33], FinanceBench [ 34], etc. datasets are limited to specific usecases such as benchmarking LLMs’ abilities to perform complex numerical reasoning or sentiment analysis. On the other hand, FinTextQA [ 35] dataset was not publicly available at the time of writing the present work.\n",
      "\n",
      "Chunk 466:\n",
      "In addition, in most of these datasets, access to the actual documents from which the ground- truth Q&As were created is not available, making it impossible to use them for our RAG techniques evaluation purposes. Hence, we resorted to a dataset of our own though through publicly available 2https://platform.openai.com/docs/guides/embeddings/embedding-models 3https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html 4https://docs.ragas.io/en/stable/concepts/metrics/context_recall.\n",
      "\n",
      "Chunk 467:\n",
      "htmlHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction documents but such that we finally have access to both the actual financial documents and the ground-truth Q&As. Datasets like FinanceBench5provides question-context-answer triplets but they are not useful as here we are comparing VectorRAG, GraphRAG and HybridRAG and they do not provide the context generated from a KG.\n",
      "\n",
      "Chunk 468:\n",
      "A recent paper [ 22] has not made the KG and triplets constructed by their algorithm public to the best of our knowledge either. In short, there is no publicly available benchmark dataset to compare VectorRAG and GraphRAG either for financial or general domains to the best of our knowledge. Hence, we had to rely on our own dataset constructed as explained below. We used transcripts from earnings calls of Nifty 50 constituents for our analysis.\n",
      "\n",
      "Chunk 469:\n",
      "The NIFTY 50 is popular index in the Indian stock market that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange (NSE). The dataset of the earning call documents of Nifty 50 companies is widely recognized in the investment realm and is esteemed as an authoritative and extensive collection of earnings call transcripts. In our investigation, we focus on data spanning the quarter ending in June, 2023 i.e.\n",
      "\n",
      "Chunk 470:\n",
      "the earnings reports for Q1 of the financial year 2024 (A financial year in India starts on the 1st April and ends in 31st March, so the quarter from 1st April to 30th June is the first quarter of 2024 for the Indian market).\n",
      "\n",
      "Chunk 471:\n",
      "Our dataset encompasses 50 transcripts for this quarter, span- ning over 50 companies within Nifty 50 universe from diverse range of sectors including Infrastructure, Healthcare, Consumer Durables, Banking, Automobile, Financial Services, Energy - Oil & Gas, Telecommunication, Consumer Goods, Pharmaceuticals, Energy - Coal, Materials, Information Technology, Construction, Diversified, Metals, Energy - Power and Chemicals providing a substantial and diverse foundation for our study.\n",
      "\n",
      "Chunk 472:\n",
      "We start the data collection process focused on acquiring earn- ings reports from company websites within the Nifty 50 universe by developing and deploying a custom web scraping tool to navigate through the websites of each company within the Nifty 50 index, systematically retrieving the pertinent earnings reports for Q1 of the financial year 2024. By utilizing this web scraping approach, we aimed to compile a comprehensive dataset encompassing the earnings reports of the constituent companies.\n",
      "\n",
      "Chunk 473:\n",
      "Table 1 summarizes basic statistics of the documents we will be experimenting with in the remainder of this work. Number of companies/documents 50 Average number of pages 27 Average number of questions 16 Average number of tokens 60,000 Table 1: Summary Statistics for the call transcript documents used in the present work.\n",
      "\n",
      "Chunk 474:\n",
      "These call transcripts documents consist of questions and an- swers between financial analysts and the company representatives for the respective companies, hence, there already exist certain Q&A pairs within these documents along with additional text. We examined the earnings reports within the Nifty50 universe, system- atically curated a comprehensive array of randomly selected 400 5https://huggingface.\n",
      "\n",
      "Chunk 475:\n",
      "co/datasets/PatronusAI/financebench-testquestions posed during the earnings calls from all the documents, and gathered the exact responses corresponding to these questions. These questions constitute the specific queries articulated by finan- cial analysts to the management during these calls. 4 IMPLEMENTATION DETAILS In this Section, we provide details of implementation of the pro- posed methodology. 4.\n",
      "\n",
      "Chunk 476:\n",
      "1 Knowledge Graph Construction The initial phase of our approach centers on document preprocess- ing. We utilize the PyPDFLoader6to import PDF documents, which are subsequently segmented into manageable chunks using the RecursiveCharacterTextSplitter. This chunking strategy employs a size of 2024 characters with an overlap of 204 characters, ensuring comprehensive coverage while maintaining context across segment boundaries.\n",
      "\n",
      "Chunk 477:\n",
      "Following the preprocessing stage, we implement the two-tiered language model chain for content refinement and information ex- traction. It is not possible to include the exact prompt here due to the limited space, but a baseline prompt can be found in Ref. [18].\n",
      "\n",
      "Chunk 478:\n",
      "Entity Type Examples Companies and Corpo- rationsOfficial names, abbreviations, infor- mal references Financial Metrics and IndicatorsRevenue, profit margins, EBITDA Corporate Executives and Key PersonnelCEOs, CFOs, board members Products and Services Tangible products and intangible ser- vices Geographical Locations Headquarters, operational regions, markets Corporate Events Mergers, acquisitions, product launches, earnings calls Legal and Regulatory InformationLegal cases, regulatory compliance Table 2: Entities extracted from earnings call transcripts Table 2 summarizes details on entities extracted from the earn- ing calls transcripts using our prompt based method.\n",
      "\n",
      "Chunk 479:\n",
      "Concurrently, LLM identifies relationships between these entities using a curated set of verbs, capturing the nuanced interactions within the cor- porate narrative. A key improvement in our methodology is the enhanced prompt engineering to generate the structured output format for knowledge triplets.\n",
      "\n",
      "Chunk 480:\n",
      "Each triplet is represented as a nested list [’h’, ’type’, ’r’, ’o’, ’type’, ’metadata’], where ’h’ and ’o’ denote the head and object entities respectively, ’type’ specifies the entity category, ’r’ represents the relationship, and ’metadata’ encapsu- lates additional contextual information. This format allows for a rich, multidimensional representation of information, facilitating more nuanced downstream analysis. 6https://python.langchain.com/v0.\n",
      "\n",
      "Chunk 481:\n",
      "1/docs/modules/data_connection/document_ loaders/pdf/Sarmah et al. Our process incorporates several advanced features to enhance the quality and utility of the extracted triplets. Entity disambigua- tion techniques are employed to consolidate different references to the same entity, improving consistency across the KG.\n",
      "\n",
      "Chunk 482:\n",
      "We also pri- oritize conciseness in entity representation, aiming for descriptions of less than four words where possible, which aids in maintaining a clean and navigable graph structure. The extraction pipeline is applied iteratively to each document chunk, with results aggregated to form a comprehensive knowledge graph representation of the entire document, allowing for scalable processing of large documents while maintaining local context within each chunk.\n",
      "\n",
      "Chunk 483:\n",
      "We have added explicit instruction on obtaining metadata following Ref. [8] for both VectorRAG and GraphRAG. Finally, we implement a data persistence strategy, converting the extracted triplets from their initial string format to Python data structures and storing them in a pickle file. This facilitates easy retrieval and further manipulation of the knowledge graph data in subsequent analysis stages.\n",
      "\n",
      "Chunk 484:\n",
      "Our methodology represents a significant advancement in auto- mated knowledge extraction from corporate documents. By com- bining advanced NLP techniques with a structured approach to information representation, we create a rich, queryable knowledge base that captures the complex relationships and key information present in corporate narratives.\n",
      "\n",
      "Chunk 485:\n",
      "This approach opens up new pos- sibilities for financial analysis and automated reasoning in the business domain that will be explored further in the future. 4.2 VectorRAG Our methodology builds upon the concept of RAG [ 9] which al- lows for the creation of a system that can provide context-aware, accurate responses to queries about company financial informa- tion, leveraging both the power of large language models and the efficiency of semantic search.\n",
      "\n",
      "Chunk 486:\n",
      "At the core of our system is a Pinecone vector database7, which serves as the foundation for our information retrieval process. We employ OpenAI’s text-embedding-ada-002 model to transform tex- tual data from earnings call transcripts into high-dimensional vec- tor representations. This vectorization process enables semantic similarity searches, significantly enhancing the relevance and ac- curacy of retrieved information.\n",
      "\n",
      "Chunk 487:\n",
      "Table 3 provides summary of the configuration of the set up in use for our experiments. LLM GPT-3.5-Turbo LLM Temperature 0 Embedding Model text-embedding-ada-002 Framework LangChain Vector Database Pinecone Chunk Size 1024 Chunk Overlap 0 Maximum Output Tokens 1024 Chunks for Similarity Algorithm 20 Number of Context Retrieved 4 Table 3: VectorRAG Configuration 7https://www.pinecone.io/The Q&A pipeline is constructed using the LangChain frame- work8.\n",
      "\n",
      "Chunk 488:\n",
      "The begins with a context retrieval step, where we query the Pinecone vector store to obtain the most relevant document chunks for a given question. This retrieval process is fine-tuned with spe- cific filters for quarters, years, and company names, ensuring that the retrieved information is both relevant and current. Following retrieval, we implement a context formatting step that consolidates the retrieved document chunks into a coherent context string.\n",
      "\n",
      "Chunk 489:\n",
      "This formatted context serves as the informational basis for the language model’s response generation. We have developed a sophisticated prompt template, that instructs the language model to function as an expert Q&A system, emphasizing the importance of utilizing only the provided context information and avoiding direct references to the context in the generated responses. For the core language processing task, we integrate OpenAI’s GPT-3.\n",
      "\n",
      "Chunk 490:\n",
      "5-turbo model which processes the formatted context and query to generate natural language responses that are informative, coherent, and contextually appropriate. To evaluate the performance of our system, we developed a comprehensive framework that includes the preparation of a cus- tom dataset of question-answer pairs specific to each company’s earnings call. Our system processes each question in this dataset, generating answers based on the retrieved context.\n",
      "\n",
      "Chunk 491:\n",
      "The evaluation results, including the original question, generated answer, retrieved contexts, and ground truth, are compiled into structured formats (CSV and JSON) to facilitate further analysis. The outputs generated by our system are stored in both CSV and JSON formats, enabling easy integration with various analysis tools and dashboards.\n",
      "\n",
      "Chunk 492:\n",
      "This approach facilitates both quantitative performance metrics and qualitative assessment of the system’s responses, providing a com- prehensive view of its effectiveness. By parameterizing company names, quarters, and years, we can easily adapt the system to different datasets and time periods. This design choice allows for seamless integration of new data and expansion to cover multiple companies and earnings calls. 4.\n",
      "\n",
      "Chunk 493:\n",
      "3 GraphRAG For GraphRAG, we developed an Q&A system specifically designed for corporate earnings call transcripts. Our implementation of GraphRAG leverages several key components and techniques: LLM GPT-3.5-Turbo LLM Temperature 0 Framework LangChain KG Manipulation Networkx Chunk Size 1024 Chunk Overlap 0 Number of Triplets 13950 Number of nodes 11405 Number of edges 13883 DFS Depth 1 Table 4: GraphRAG Configuration 8https://docs.smith.langchain.\n",
      "\n",
      "Chunk 494:\n",
      "com/old/cookbook/hub-examples/retrieval-qa-chainHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Knowledge Graph Construction:- We begin by constructing a KG from a set of knowledge triplets extracted from corporate documents using the prompt engineering based methodology as described in Section 4.1.\n",
      "\n",
      "Chunk 495:\n",
      "These triplets, stored in a pickle file, repre- sent structured information in the form of subject-predicate-object relationships. We use the NetworkxEntityGraph class from the LangChain library to create and manage this graph structure. Each triple is added to the graph, which encapsulates the head entity, relation, tail entity, and additional metadata. We implement the Q&A functionality using the GraphQAChain class from LangChain.\n",
      "\n",
      "Chunk 496:\n",
      "This chain combines the KG with an LLM (in our case, OpenAI’s GPT-3.5-turbo) to generate responses. The GraphQAChain traverses the KG to find relevant information and uses the language model to formulate coherent answers based on the retrieved context. A summary of configuration of our LLM models and other libraries used for GraphRAG is shown in Table 4.\n",
      "\n",
      "Chunk 497:\n",
      "In KG as the information is stored in the form of entities and relationships and there can be multiple relations emanating from one single entity, in this experiment, to extract relevant information from the KG, we employ a depth-first search strategy constrained by a depth of one from the specified entity.\n",
      "\n",
      "Chunk 498:\n",
      "To prepare for assessing the performance of our GraphRAG system, we follow the below steps: Dataset Preparation:- We use a pre-generated CSV file containing question-answer pairs specific to the earnings call transcript. Iterative Processing:- For each question in the dataset, we run the GraphQAChain to generate an answer. Result Compilation:- We compile the results, including the origi- nal questions, generated answers, retrieved contexts, and ground truth answers, into a structured format.\n",
      "\n",
      "Chunk 499:\n",
      "Finally, the evaluation results are saved in both CSV and JSON formats for further analysis and comparison. We then fed these outputs into our RAG evaluation pipeline. For each Q&A pair in our dataset, we compute all three metrics: faithfulness, answer relevance, context precision and context recall. 4.\n",
      "\n",
      "Chunk 500:\n",
      "4 HybridRAG For the proposed HybridRAG technique, upon obtaining all the contextual information from VectorRAG and GraphRAG, we con- catenate these contexts to form a unified context utilizing both techniques. This combined context is then fed into the answer gen- erator model to produce a response. The context used for response generation is relatively larger, which affects the precision of the generated response.\n",
      "\n",
      "Chunk 501:\n",
      "The context from VectorRAG is appended first, followed by the context from GraphRAG. Consequently, the preci- sion of the generated answer depends on the source context. If the answer is generated from the GraphRAG context, it will have lower precision, as the GraphRAG context is added last in the sequence of contexts provided to the answer generator model, and vice versa. 5 RESULTS We evaluate both the retrieval and generation parts of RAG for the three different RAG pipelines.\n",
      "\n",
      "Chunk 502:\n",
      "Evaluating the RAG outputs is also an active area of research there is no standard tool which is universally accepted as of yet, though we use a currently popular framework RAGAS[ 30] to evaluate the three RAG pipelines in thepresent work where we have modified them a bit to make more precise comparisons. The results of our comparative analysis reveal notable differences in performance among VectorRAG, GraphRAG, and HybridRAG approaches as summarized in Table 5.\n",
      "\n",
      "Chunk 503:\n",
      "In terms of Faithfulness, GraphRAG and HybridRAG demonstrated superior performance, both achieving a score of 0.96, while VectorRAG trailed slightly with a score of 0.94. Answer relevancy scores varied across the meth- ods, with HybridRAG outperforming the others at 0.96, followed by VectorRAG at 0.91, and GraphRAG at 0.89. Context precision was highest for GraphRAG at 0.96, significantly surpassing Vec- torRAG (0.84) and HybridRAG (0.79).\n",
      "\n",
      "Chunk 504:\n",
      "However, in context recall, both VectorRAG and HybridRAG achieved perfect scores of 1, while GraphRAG lagged behind at 0.85. Overall, these results suggest that GraphRAG offers improve- ments over VectorRAG, particularly in faithfulness and context pre- cision. Furthermore, HybridRAG emerges as the most balanced and effective approach, outperforming both VectorRAG and GraphRAG in key metrics such as faithfulness and answer relevancy, while maintaining high context recall.\n",
      "\n",
      "Chunk 505:\n",
      "The relatively lower context precision observed for HybridRAG (0.79) can be attributed to its unique approach of combining con- texts from both VectorRAG and GraphRAG methods. While this integration allows for more comprehensive information retrieval, it also introduces additional content that may not align precisely with the ground truth, thus affecting the context precision met- ric.\n",
      "\n",
      "Chunk 506:\n",
      "Despite this trade-off, HybridRAG’s superior performance in faithfulness, answer relevancy, and context recall underscores its effectiveness. When considering the overall evaluation metrics, HybridRAG emerges as the most promising approach, balancing high-quality answers with comprehensive context retrieval. Overall GraphRAG performs better in extractive questions com- pared to VectorRAG.\n",
      "\n",
      "Chunk 507:\n",
      "And VectorRAG does better in abstractive questions where information is not explicitly mentioned in the raw data. And also GraphRAG sometimes fails to answer ques- tions correctly whenever there is no entity explicitly mentioned in the question. So HybridRAG does a good job overall, as whenever VectorRAG fails to fetch correct context in extractive questions it falls back to GraphRAG to generate the answer.\n",
      "\n",
      "Chunk 508:\n",
      "And whenever GraphRAG fails to fetch correct context in abstractive questions it falls back to VectorRAG to generate the answer. VectorRAG GraphRAG HybridRAG F 0.94 0.96 0.96 AR 0.91 0.89 0.96 CP 0.84 0.96 0.79 CR 1 0.85 1 Table 5: Performance Metrics for Different RAG Pipelines. Here, F, AR, CP and CR refer to Faithfulness, Answer Relevence, Context Precision and Context Recall.\n",
      "\n",
      "Chunk 509:\n",
      "6 CONCLUSION AND FUTURE DIRECTIONS Among the current approaches to mitigate issues regarding infor- mation extraction from external documents that were not part ofSarmah et al. training data for the LLM, Retrieval Augmented Generation (RAG) techniques have emerged as the most popular ones that aim to improve the performance of LLMs by incorporating relevant re- trieval mechanisms.\n",
      "\n",
      "Chunk 510:\n",
      "RAG methods enhance the LLMs’ capabilities by retrieving pertinent documents or text to provide additional context during the generation process. However, these approaches encounter significant limitations when applied to the specialized and intricate domain of financial documents. Furthermore, the qual- ity of the retrieved context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses.\n",
      "\n",
      "Chunk 511:\n",
      "These challenges highlight the need for more sophisticated methods that can effectively integrate and process the detailed and domain- specific information found in financial documents, ensuring more reliable and accurate outputs for informed decision-making. In the present work, we have introduced a novel approach that significantly advances the field of information extraction from finan- cial documents through the development of a hybrid RAG system.\n",
      "\n",
      "Chunk 512:\n",
      "This system, called HybridRAG, which integrates the strengths of both Knowledge Graphs (KGs) and advanced language models, represents a leap forward in our ability to extract and interpret complex information from unstructured financial texts. The hybrid RAG system, by combining traditional vector-based RAG and KG- based RAG, has shown superior performance in terms of retrieval accuracy and answer generation, marking a pivotal step towards more effective financial analysis tools.\n",
      "\n",
      "Chunk 513:\n",
      "Through a comparative analysis using objecive evaluation met- rics, we have highlighted the distinct performance advantages of the HybridRAG approach over its vector-based and KG-based coun- terparts. The HybridRAG system excels in faithfulness, answer relevancy, and context recall, demonstrating the benefits of inte- grating contexts from both VectorRAG and GraphRAG methods, despite potential trade-offs in context precision.\n",
      "\n",
      "Chunk 514:\n",
      "The implications of this research extend beyond the immedi- ate realm of financial analysis. By developing a system capable of understanding and responding to nuanced queries about com- plex financial documents, we pave the way for more sophisticated AI-assisted financial decision-making tools that could potentially democratize access to financial insights, allowing a broader range of stakeholders to engage with and understand financial information.\n",
      "\n",
      "Chunk 515:\n",
      "Future directions for this research include expanding the system to handle multi-modal inputs, incorporating numerical data analysis capabilities, and developing more sophisticated evaluation metrics that capture the nuances of financial language and the accuracy of numerical information in the responses. Additionally, exploring the integration of this system with real-time financial data streams could further enhance its utility in dynamic financial environments.\n",
      "\n",
      "Chunk 516:\n",
      "7 ACKNOWLEDGEMENT The views expressed here are those of the authors alone and not of BlackRock, Inc or NVIDIA. We are grateful to Emma Lind for her invaluable support for this collaboration. REFERENCES [1] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. 2013. [2]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need.\n",
      "\n",
      "Chunk 517:\n",
      "Advances inneural information processing systems, 30, 2017.[3]Yi Yang, Mark Christopher Siy Uy, and Allen Huang. Finbert: A pretrained language model for financial communications. arXiv preprint arXiv:2006.08097 , 2020. [4]Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Se- bastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann. Bloomberggpt: A large language model for finance. arXiv preprint arXiv:2303.17564, 2023.\n",
      "\n",
      "Chunk 518:\n",
      "[5] Yuqi Nie, Yaxuan Kong, Xiaowen Dong, John M Mulvey, H Vincent Poor, Qing- song Wen, and Stefan Zohren. A survey of large language models for financial ap- plications: Progress, prospects and challenges. arXiv preprint arXiv:2406.11903 , 2024. [6]Huaqin Zhao, Zhengliang Liu, Zihao Wu, Yiwei Li, Tianze Yang, Peng Shu, Shaochen Xu, Haixing Dai, Lin Zhao, Gengchen Mai, Ninghao Liu, and Tianming Liu. Revolutionizing finance with llms: An overview of applications and insights, 2024.\n",
      "\n",
      "Chunk 519:\n",
      "[7] Chen Ling, Xujiang Zhao, Jiaying Lu, Chengyuan Deng, Can Zheng, Junxiang Wang, Tanmoy Chowdhury, Yun Li, Hejie Cui, Xuchao Zhang, et al. Domain spe- cialization as the key to make large language models disruptive: A comprehensive survey. arXiv preprint arXiv:2305.18703, 2023. [8] Bhaskarjit Sarmah, Dhagash Mehta, Stefano Pasquali, and Tianjie Zhu. Towards reducing hallucination in extracting information from financial reports using large language models.\n",
      "\n",
      "Chunk 520:\n",
      "In Proceedings oftheThird International Conference onAI-ML Systems, pages 1–5, 2023. [9]Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances inNeural Information Processing Systems , 33:9459–9474, 2020. [10] Gautier Izacard and Edouard Grave.\n",
      "\n",
      "Chunk 521:\n",
      "Leveraging passage retrieval with generative models for open domain question answering. arXiv preprint arXiv:2007.01282 , 2021. [11] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. Realm: Retrieval-augmented language model pre-training. arXiv preprint arXiv:2002.08909, 2020. [12] Antonio Jose Jimeno Yepes et al. Financial report chunking for effective retrieval augmented generation. arXiv preprint arXiv:2402.05131, 2024. [13] SuperAcc.\n",
      "\n",
      "Chunk 522:\n",
      "Retrieval-augmented generation on financial statements. SuperAcc Insights, 2024. [14] Shaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, and S Yu Philip. A survey on knowledge graphs: Representation, acquisition, and applications. IEEE transactions onneural networks andlearning systems, 33(2):494–514, 2021. [15] Heiko Paulheim. Knowledge graphs: State of the art and future directions. Semantic Web Journal, 10(4):1–20, 2017.\n",
      "\n",
      "Chunk 523:\n",
      "[16] Aidan Hogan, Eva Blomqvist, Michael Cochez, Claudia D’Amato, Gerard de Melo, Claudio Gutiérrez, and Maria ... Maleshkova. Knowledge graphs. arXiv preprint arXiv:2003.02320, 2021. [17] Lisa Ehrlinger and Wolfram Wöß. Towards a definition of knowledge graphs. In SEMANTiCS (Posters, Demos, SuCCESS), pages 1–4, 2016. [18] Xiaohui Victor Li and Francesco Sanna Passino. Findkg: Dynamic knowledge graphs with large language models for detecting global trends in financial mar- kets.\n",
      "\n",
      "Chunk 524:\n",
      "arXiv preprint arXiv:2407.10909, 2024. [19] Shourya De, Anima Aggarwal, and Anna Cinzia Squicciarini. Financial knowl- edge graphs: A novel approach to empower data-driven financial applications. In IEEE International Conference onBigData (Big Data), pages 1311–1320, 2018. [20] Marina Petrova and Birgit Reinwald. Knowledge graphs in finance: Applications and opportunities. Journal ofFinancial Data Science, 2(2):10–19, 2020. [21] Wei Liu, Jun Zhang, and Li Pan.\n",
      "\n",
      "Chunk 525:\n",
      "Utilizing knowledge graphs for financial data integration and analysis. Data Science Journal, 18(1):1–15, 2019. [22] Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, and Jonathan Larson. From local to global: A graph rag approach to query-focused summarization. arXiv preprint arXiv:2404.16130 , 2024. [23] Xuchen Yao, Yanan Sun, Zhen Huang, and Dong Li. Retrieval-augmented gener- ation for knowledge-intensive nlp tasks. arXiv preprint arXiv:2101.\n",
      "\n",
      "Chunk 526:\n",
      "07554 , 2021. [24] Weizhi Zhao, Haoyu Chen, Kai Liu, and Jun Zhao. Graph-based retrieval- augmented generation for open-domain question answering. In Proceedings oftheAAAI Conference onArtificial Intelligence , volume 36, pages 3098–3106, 2022. [25] Bill Yuchen Lin, Yuanhe Liu, Ming Shen, and Xiang Ren. Kgpt: Knowledge- grounded pre-training for data-to-text generation. In Findings oftheAssociation forComputational Linguistics: EMNLP 2020, pages 710–724, 2020.\n",
      "\n",
      "Chunk 527:\n",
      "[26] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Ji- awei Sun, and Haofen Wang. Retrieval-augmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997, 2023. [27] Tyler Procko. Graph retrieval-augmented generation for large language models: A survey. Available atSSRN, 2024. [28] Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, and Xindong Wu. A comprehensive survey on automatic knowledge graph construction.\n",
      "\n",
      "Chunk 528:\n",
      "ACM Computing Surveys , 56(4):1–62, 2023.HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc.\n",
      "\n",
      "Chunk 529:\n",
      "New York, NY, USADhagash Mehta dhagash.mehta@blackrock.com BlackRock, Inc.\n",
      "\n",
      "Chunk 530:\n",
      "New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.\n",
      "\n",
      "Chunk 531:\n",
      "We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.\n",
      "\n",
      "Chunk 532:\n",
      "Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.\n",
      "\n",
      "Chunk 533:\n",
      "The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.\n",
      "\n",
      "Chunk 534:\n",
      "However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.\n",
      "\n",
      "Chunk 535:\n",
      "Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].\n",
      "\n",
      "Chunk 536:\n",
      "Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.\n",
      "\n",
      "Chunk 537:\n",
      "In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.\n",
      "\n",
      "Chunk 538:\n",
      "Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.\n",
      "\n",
      "Chunk 539:\n",
      "VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.\n",
      "\n",
      "Chunk 540:\n",
      "For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].\n",
      "\n",
      "Chunk 541:\n",
      "Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.\n",
      "\n",
      "Chunk 542:\n",
      "Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.\n",
      "\n",
      "Chunk 543:\n",
      "KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.\n",
      "\n",
      "Chunk 544:\n",
      "However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].\n",
      "\n",
      "Chunk 545:\n",
      "Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.\n",
      "\n",
      "Chunk 546:\n",
      "However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.\n",
      "\n",
      "Chunk 547:\n",
      "By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.\n",
      "\n",
      "Chunk 548:\n",
      "In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.\n",
      "\n",
      "Chunk 549:\n",
      "1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].\n",
      "\n",
      "Chunk 550:\n",
      "Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.\n",
      "\n",
      "Chunk 551:\n",
      "We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.\n",
      "\n",
      "Chunk 552:\n",
      "2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.\n",
      "\n",
      "Chunk 553:\n",
      "This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.\n",
      "\n",
      "Chunk 554:\n",
      "This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.\n",
      "\n",
      "Chunk 555:\n",
      "In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.\n",
      "\n",
      "Chunk 556:\n",
      "The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.\n",
      "\n",
      "Chunk 557:\n",
      "The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.\n",
      "\n",
      "Chunk 558:\n",
      ", a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.\n",
      "\n",
      "Chunk 559:\n",
      "htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Figure 1: A schematic diagram describing the vector database creation of a RAG application. improvement, and knowledge adaptation [ 28]. Here, we do not use knowledge adaptation and treat the KGs as static graphs.\n",
      "\n",
      "Chunk 560:\n",
      "Knowledge Extraction:- This step aims to extract structured in- formation from unstructured or semi-structured data, such as text, databases, and existing ontologies. The main tasks in this step are entity recognition, relationship extraction, and co-reference reso- lution. Entity recognition and relationship extraction techniques use typical NLP tasks to identify entities and their relationships from textual sources [ 29].\n",
      "\n",
      "Chunk 561:\n",
      "Coreference resolution identifies and connects different references of the same entity, keeping coherence within the knowledge graph. For example, if the text refers to a company as both \"the company\" and \"it\", coreference resolution can link these mentions to the same entity node in the graph. Knowledge Improvement:- This step aims to enhance the quality and completeness of the KG by removing redundancies and address- ing gaps in the extracted information.\n",
      "\n",
      "Chunk 562:\n",
      "The primary tasks in this step are KG completion and fusion. KG completion technique infers missing entities and relationships within the graph using meth- ods such as link prediction and entity resolution. Link prediction predicts the existence and type of a relation between two entities based on the graph structure and features, while entity resolution matches and merges different representations of the same entity from different sources.\n",
      "\n",
      "Chunk 563:\n",
      "Knowledge fusion combines information from multiple sources to create a coherent and unified KG. This involves resolving conflicts and redundancies among the sources, such as contradictory or duplicate facts, and aggregating or reconciling the information based on rules, probabilities, or semantic similarity. We utilized a robust methodology for creating KG triplets from unstructured text data, specifically focusing on corporate docu- ments such as earnings call transcripts, adapted from Ref.\n",
      "\n",
      "Chunk 564:\n",
      "[ 18?]. This process involves several interconnected stages, each designed to extract, refine, and structure information effectively. We implement a two-tiered LLM chain for content refinement and information extraction. The first tier employs an LLM to gen- erate an abstract representation of each document chunk.\n",
      "\n",
      "Chunk 565:\n",
      "This refinement process is crucial as it distills the essential information while preserving the original meaning and key relationships be- tween concepts that serves as a more focused input for subsequent processing, enhancing the overall efficiency and accuracy of ourtriplet extraction pipeline. The second tier of our LLM chain is dedicated to entity extraction and relationship identification. Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM.\n",
      "\n",
      "Chunk 566:\n",
      "A detailed discussion on imple- mentation of the methodology will be provided in Section 4.1 2.3 GraphRAG KG based RAG [ 22], or GraphRAG, also begins with a query based on the user’s input same as VectorRAG. The main difference be- tween VectorRAG and GraphRAG lies in the retrieval part. The query here is now used to search the KG to retrieve relevant nodes (entities) and edges (relationships) related to the query.\n",
      "\n",
      "Chunk 567:\n",
      "A subgraph, which consists of these relevant nodes and edges, is extracted from the full KG to provide context. This subgraph is then integrated with the language model’s internal knowledge, by encoding the graph structure into embeddings that the model can interpret. The language model uses this combined context to generate responses that are informed by both the structured information from the KG and its pre-trained knowledge.\n",
      "\n",
      "Chunk 568:\n",
      "Crucially, when responding to user queries about a particular company, we leveraged the metadata information to selectively filter and retrieve only those document segments pertinent to the queried company [ 8]. This integration helps ensure that the generated outputs are accurate, contextually relevant, and grounded in verifiable information. A schematic diagram of the retrieval methodology of GraphRAG is given in Figure 2.\n",
      "\n",
      "Chunk 569:\n",
      "Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section 4.1 Figure 2: A schematic diagram describing knowledge graph creation process of GraphRAG. 2.3.1 HybridRAG. For the HybridRAG technique, we propose to integrate the aforementioned two distinct RAG techniques: Vec- torRAG and GraphRAG.\n",
      "\n",
      "Chunk 570:\n",
      "This integration involves a systematic combination of contextual information retrieved from both the traditional vector-based retrieval mechanism and the KG-based retrieval system, the latter of which was constructed specifically for this study. The amalgamation of these two contexts allows us to leverage the strengths of both approaches.\n",
      "\n",
      "Chunk 571:\n",
      "The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-richSarmah et al. contextual data. This combined context is then utilized as input for a LLM to generate the final responses. Details on the implementation of the HybridRAG will be provided in Section 4.4. 2.\n",
      "\n",
      "Chunk 572:\n",
      "4 Evaluation Metrics To assess the efficacy of this integrated approach, we conducted a comparative analysis among the three approaches in a controlled ex- perimental set up: VectorRAG, GraphRAG and HybridRAG. The re- sponses generated using the combined VectorRAG and GraphRAG contexts were juxtaposed against those produced individually by VectorRAG and GraphRAG.\n",
      "\n",
      "Chunk 573:\n",
      "This comparative evaluation aimed to discern potential improvements in response quality, accuracy, and comprehensiveness that might arise from the synergistic integra- tion of these two RAG methodologies. To objectively evaluate different RAG approaches (VectorRAG and GraphRAG in their case), Ref. [ 22] utilized metrics such as comprehensiveness (i.e., the amount of details the answer provides to cover all aspects and details of the question?); diversity (i.e.\n",
      "\n",
      "Chunk 574:\n",
      ", the richness of the answer in providing different perspectives and insights on the question); empowerment (i.e., the helpfulness of the answer to the reader understand and make informed judgements about the topic); and, directness (i.e., clearness of the answer in addressing the question). here, the LLM was provided tuples of question, target metric, and a pair of answers, and was asked to assess which answer was better according to the metric and why.\n",
      "\n",
      "Chunk 575:\n",
      "These metrics though compare the final generated answers, do not necessarily directly evaluate the retrieval and generation parts separately. Instead, here we implement a comprehensive set of evaluation metrics which are designed to capture different aspects of a given RAG system’s output quality, focusing on faithfulness, answer relevance, and context relevance [ 30]. Each metric provides unique insights into the system’s capabilities and limitations. 2.4.1 Faithfulness.\n",
      "\n",
      "Chunk 576:\n",
      "Faithfulness is a crucial metric that measures the extent to which the generated answer can be inferred from the provided context. Our implementation of the faithfulness metric involves a two-step process: Statement Extraction:- We use an LLM to decompose the gener- ated answer into a set of concise statements. This step is crucial for breaking down complex answers into more manageable and verifiable units.\n",
      "\n",
      "Chunk 577:\n",
      "The prompt used for this step is: \"Given a question and answer, create one or more statements from each sentence in the given answer. question: [question] an- swer: [answer]\". Statement Verification:- For each extracted statement, we employ the LLM to determine if it can be inferred from the given context.\n",
      "\n",
      "Chunk 578:\n",
      "This verification process uses the following prompt: \"Consider the given context and following statements, then de- termine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. statement: [statement 1] ... statement: [statement n]\".\n",
      "\n",
      "Chunk 579:\n",
      "The faithfulness score ( 𝐹) is𝐹=|𝑉|/|𝑆|, where |𝑉|is the number of supported statements and |𝑆|is the total number of statements.2.4.2 Answer Relevance:-. The answer relevance metric assesses how well the generated answer addresses the original question, irrespective of factual accuracy. This metric helps identify cases of incomplete answers or responses containing irrelevant information.\n",
      "\n",
      "Chunk 580:\n",
      "Our implementation involves the following steps: Question Generation: We prompt the LLM to generate n potential questions based on the given answer: \"Generate a question for the given answer. answer: [answer]\". Then, we obtain embeddings for all generated questions and the original question using OpenAI’s text-embedding-ada-002 model2. We then calculate the cosine similarity between each generated question’s embedding and the original question’s embedding.\n",
      "\n",
      "Chunk 581:\n",
      "Finally, the answer relevance score (AR) is computed as the aver- age similarity across all generated questions: 𝐴𝑅=1 𝑛Í(𝑠𝑖𝑚(𝑞,𝑞𝑖)), where𝑠𝑖𝑚(𝑞,𝑞𝑖)is the cosine similarity between the embedding of the original question 𝑞and the embeddings of each of the 𝑛 generated questions 𝑞𝑖. 2.4.3 Context Precision. It is a metric used to evaluate the relevance of retrieved context chunks in relation to a specified ground truth for a given question3.\n",
      "\n",
      "Chunk 582:\n",
      "It calculates the proportion of relevant items that appear in the top ranks of the context. The formula for context precision at K is the sum of the products of precision at each rank k and a binary relevance indicator v_k, divided by the total number of relevant items in the top K results. Precision at each rank k is determined by the ratio of true positives at k to the sum of true positives and false positives at k.\n",
      "\n",
      "Chunk 583:\n",
      "This metric helps in assessing how well the context supports the ground truth, aiming for higher scores which indicate better precision. 2.4.4 Context Recall. It is a metric used to evaluate how well the retrieved context aligns with the ground truth answer, which is considered the definitive correct response4. It is quantified by com- paring each sentence in the ground truth answer to see if it can be traced back to the retrieved context.\n",
      "\n",
      "Chunk 584:\n",
      "The formula for context recall is the ratio of the number of ground truth sentences that can be attributed to the context to the total number of sentences in the ground truth. Higher values, ranging from 0 to 1, indicate bet- ter alignment and thus better context recall. This metric is crucial for assessing the effectiveness of information retrieval systems in providing relevant context.\n",
      "\n",
      "Chunk 585:\n",
      "3 DATA DESCRIPTION Although there do exist some public financial datasets, none of them were suitable for the present experiments: e.g., FinQA [ 31], TAT- QA [ 32], FIQA [ 33], FinanceBench [ 34], etc. datasets are limited to specific usecases such as benchmarking LLMs’ abilities to perform complex numerical reasoning or sentiment analysis. On the other hand, FinTextQA [ 35] dataset was not publicly available at the time of writing the present work.\n",
      "\n",
      "Chunk 586:\n",
      "In addition, in most of these datasets, access to the actual documents from which the ground- truth Q&As were created is not available, making it impossible to use them for our RAG techniques evaluation purposes. Hence, we resorted to a dataset of our own though through publicly available 2https://platform.openai.com/docs/guides/embeddings/embedding-models 3https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html 4https://docs.ragas.io/en/stable/concepts/metrics/context_recall.\n",
      "\n",
      "Chunk 587:\n",
      "htmlHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction documents but such that we finally have access to both the actual financial documents and the ground-truth Q&As. Datasets like FinanceBench5provides question-context-answer triplets but they are not useful as here we are comparing VectorRAG, GraphRAG and HybridRAG and they do not provide the context generated from a KG.\n",
      "\n",
      "Chunk 588:\n",
      "A recent paper [ 22] has not made the KG and triplets constructed by their algorithm public to the best of our knowledge either. In short, there is no publicly available benchmark dataset to compare VectorRAG and GraphRAG either for financial or general domains to the best of our knowledge. Hence, we had to rely on our own dataset constructed as explained below. We used transcripts from earnings calls of Nifty 50 constituents for our analysis.\n",
      "\n",
      "Chunk 589:\n",
      "The NIFTY 50 is popular index in the Indian stock market that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange (NSE). The dataset of the earning call documents of Nifty 50 companies is widely recognized in the investment realm and is esteemed as an authoritative and extensive collection of earnings call transcripts. In our investigation, we focus on data spanning the quarter ending in June, 2023 i.e.\n",
      "\n",
      "Chunk 590:\n",
      "the earnings reports for Q1 of the financial year 2024 (A financial year in India starts on the 1st April and ends in 31st March, so the quarter from 1st April to 30th June is the first quarter of 2024 for the Indian market).\n",
      "\n",
      "Chunk 591:\n",
      "Our dataset encompasses 50 transcripts for this quarter, span- ning over 50 companies within Nifty 50 universe from diverse range of sectors including Infrastructure, Healthcare, Consumer Durables, Banking, Automobile, Financial Services, Energy - Oil & Gas, Telecommunication, Consumer Goods, Pharmaceuticals, Energy - Coal, Materials, Information Technology, Construction, Diversified, Metals, Energy - Power and Chemicals providing a substantial and diverse foundation for our study.\n",
      "\n",
      "Chunk 592:\n",
      "We start the data collection process focused on acquiring earn- ings reports from company websites within the Nifty 50 universe by developing and deploying a custom web scraping tool to navigate through the websites of each company within the Nifty 50 index, systematically retrieving the pertinent earnings reports for Q1 of the financial year 2024. By utilizing this web scraping approach, we aimed to compile a comprehensive dataset encompassing the earnings reports of the constituent companies.\n",
      "\n",
      "Chunk 593:\n",
      "Table 1 summarizes basic statistics of the documents we will be experimenting with in the remainder of this work. Number of companies/documents 50 Average number of pages 27 Average number of questions 16 Average number of tokens 60,000 Table 1: Summary Statistics for the call transcript documents used in the present work.\n",
      "\n",
      "Chunk 594:\n",
      "These call transcripts documents consist of questions and an- swers between financial analysts and the company representatives for the respective companies, hence, there already exist certain Q&A pairs within these documents along with additional text. We examined the earnings reports within the Nifty50 universe, system- atically curated a comprehensive array of randomly selected 400 5https://huggingface.\n",
      "\n",
      "Chunk 595:\n",
      "co/datasets/PatronusAI/financebench-testquestions posed during the earnings calls from all the documents, and gathered the exact responses corresponding to these questions. These questions constitute the specific queries articulated by finan- cial analysts to the management during these calls. 4 IMPLEMENTATION DETAILS In this Section, we provide details of implementation of the pro- posed methodology. 4.\n",
      "\n",
      "Chunk 596:\n",
      "1 Knowledge Graph Construction The initial phase of our approach centers on document preprocess- ing. We utilize the PyPDFLoader6to import PDF documents, which are subsequently segmented into manageable chunks using the RecursiveCharacterTextSplitter. This chunking strategy employs a size of 2024 characters with an overlap of 204 characters, ensuring comprehensive coverage while maintaining context across segment boundaries.\n",
      "\n",
      "Chunk 597:\n",
      "Following the preprocessing stage, we implement the two-tiered language model chain for content refinement and information ex- traction. It is not possible to include the exact prompt here due to the limited space, but a baseline prompt can be found in Ref. [18].\n",
      "\n",
      "Chunk 598:\n",
      "Entity Type Examples Companies and Corpo- rationsOfficial names, abbreviations, infor- mal references Financial Metrics and IndicatorsRevenue, profit margins, EBITDA Corporate Executives and Key PersonnelCEOs, CFOs, board members Products and Services Tangible products and intangible ser- vices Geographical Locations Headquarters, operational regions, markets Corporate Events Mergers, acquisitions, product launches, earnings calls Legal and Regulatory InformationLegal cases, regulatory compliance Table 2: Entities extracted from earnings call transcripts Table 2 summarizes details on entities extracted from the earn- ing calls transcripts using our prompt based method.\n",
      "\n",
      "Chunk 599:\n",
      "Concurrently, LLM identifies relationships between these entities using a curated set of verbs, capturing the nuanced interactions within the cor- porate narrative. A key improvement in our methodology is the enhanced prompt engineering to generate the structured output format for knowledge triplets.\n",
      "\n",
      "Chunk 600:\n",
      "Each triplet is represented as a nested list [’h’, ’type’, ’r’, ’o’, ’type’, ’metadata’], where ’h’ and ’o’ denote the head and object entities respectively, ’type’ specifies the entity category, ’r’ represents the relationship, and ’metadata’ encapsu- lates additional contextual information. This format allows for a rich, multidimensional representation of information, facilitating more nuanced downstream analysis. 6https://python.langchain.com/v0.\n",
      "\n",
      "Chunk 601:\n",
      "1/docs/modules/data_connection/document_ loaders/pdf/Sarmah et al. Our process incorporates several advanced features to enhance the quality and utility of the extracted triplets. Entity disambigua- tion techniques are employed to consolidate different references to the same entity, improving consistency across the KG.\n",
      "\n",
      "Chunk 602:\n",
      "We also pri- oritize conciseness in entity representation, aiming for descriptions of less than four words where possible, which aids in maintaining a clean and navigable graph structure. The extraction pipeline is applied iteratively to each document chunk, with results aggregated to form a comprehensive knowledge graph representation of the entire document, allowing for scalable processing of large documents while maintaining local context within each chunk.\n",
      "\n",
      "Chunk 603:\n",
      "We have added explicit instruction on obtaining metadata following Ref. [8] for both VectorRAG and GraphRAG. Finally, we implement a data persistence strategy, converting the extracted triplets from their initial string format to Python data structures and storing them in a pickle file. This facilitates easy retrieval and further manipulation of the knowledge graph data in subsequent analysis stages.\n",
      "\n",
      "Chunk 604:\n",
      "Our methodology represents a significant advancement in auto- mated knowledge extraction from corporate documents. By com- bining advanced NLP techniques with a structured approach to information representation, we create a rich, queryable knowledge base that captures the complex relationships and key information present in corporate narratives.\n",
      "\n",
      "Chunk 605:\n",
      "This approach opens up new pos- sibilities for financial analysis and automated reasoning in the business domain that will be explored further in the future. 4.2 VectorRAG Our methodology builds upon the concept of RAG [ 9] which al- lows for the creation of a system that can provide context-aware, accurate responses to queries about company financial informa- tion, leveraging both the power of large language models and the efficiency of semantic search.\n",
      "\n",
      "Chunk 606:\n",
      "At the core of our system is a Pinecone vector database7, which serves as the foundation for our information retrieval process. We employ OpenAI’s text-embedding-ada-002 model to transform tex- tual data from earnings call transcripts into high-dimensional vec- tor representations. This vectorization process enables semantic similarity searches, significantly enhancing the relevance and ac- curacy of retrieved information.\n",
      "\n",
      "Chunk 607:\n",
      "Table 3 provides summary of the configuration of the set up in use for our experiments. LLM GPT-3.5-Turbo LLM Temperature 0 Embedding Model text-embedding-ada-002 Framework LangChain Vector Database Pinecone Chunk Size 1024 Chunk Overlap 0 Maximum Output Tokens 1024 Chunks for Similarity Algorithm 20 Number of Context Retrieved 4 Table 3: VectorRAG Configuration 7https://www.pinecone.io/The Q&A pipeline is constructed using the LangChain frame- work8.\n",
      "\n",
      "Chunk 608:\n",
      "The begins with a context retrieval step, where we query the Pinecone vector store to obtain the most relevant document chunks for a given question. This retrieval process is fine-tuned with spe- cific filters for quarters, years, and company names, ensuring that the retrieved information is both relevant and current. Following retrieval, we implement a context formatting step that consolidates the retrieved document chunks into a coherent context string.\n",
      "\n",
      "Chunk 609:\n",
      "This formatted context serves as the informational basis for the language model’s response generation. We have developed a sophisticated prompt template, that instructs the language model to function as an expert Q&A system, emphasizing the importance of utilizing only the provided context information and avoiding direct references to the context in the generated responses. For the core language processing task, we integrate OpenAI’s GPT-3.\n",
      "\n",
      "Chunk 610:\n",
      "5-turbo model which processes the formatted context and query to generate natural language responses that are informative, coherent, and contextually appropriate. To evaluate the performance of our system, we developed a comprehensive framework that includes the preparation of a cus- tom dataset of question-answer pairs specific to each company’s earnings call. Our system processes each question in this dataset, generating answers based on the retrieved context.\n",
      "\n",
      "Chunk 611:\n",
      "The evaluation results, including the original question, generated answer, retrieved contexts, and ground truth, are compiled into structured formats (CSV and JSON) to facilitate further analysis. The outputs generated by our system are stored in both CSV and JSON formats, enabling easy integration with various analysis tools and dashboards.\n",
      "\n",
      "Chunk 612:\n",
      "This approach facilitates both quantitative performance metrics and qualitative assessment of the system’s responses, providing a com- prehensive view of its effectiveness. By parameterizing company names, quarters, and years, we can easily adapt the system to different datasets and time periods. This design choice allows for seamless integration of new data and expansion to cover multiple companies and earnings calls. 4.\n",
      "\n",
      "Chunk 613:\n",
      "3 GraphRAG For GraphRAG, we developed an Q&A system specifically designed for corporate earnings call transcripts. Our implementation of GraphRAG leverages several key components and techniques: LLM GPT-3.5-Turbo LLM Temperature 0 Framework LangChain KG Manipulation Networkx Chunk Size 1024 Chunk Overlap 0 Number of Triplets 13950 Number of nodes 11405 Number of edges 13883 DFS Depth 1 Table 4: GraphRAG Configuration 8https://docs.smith.langchain.\n",
      "\n",
      "Chunk 614:\n",
      "com/old/cookbook/hub-examples/retrieval-qa-chainHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Knowledge Graph Construction:- We begin by constructing a KG from a set of knowledge triplets extracted from corporate documents using the prompt engineering based methodology as described in Section 4.1.\n",
      "\n",
      "Chunk 615:\n",
      "These triplets, stored in a pickle file, repre- sent structured information in the form of subject-predicate-object relationships. We use the NetworkxEntityGraph class from the LangChain library to create and manage this graph structure. Each triple is added to the graph, which encapsulates the head entity, relation, tail entity, and additional metadata. We implement the Q&A functionality using the GraphQAChain class from LangChain.\n",
      "\n",
      "Chunk 616:\n",
      "This chain combines the KG with an LLM (in our case, OpenAI’s GPT-3.5-turbo) to generate responses. The GraphQAChain traverses the KG to find relevant information and uses the language model to formulate coherent answers based on the retrieved context. A summary of configuration of our LLM models and other libraries used for GraphRAG is shown in Table 4.\n",
      "\n",
      "Chunk 617:\n",
      "In KG as the information is stored in the form of entities and relationships and there can be multiple relations emanating from one single entity, in this experiment, to extract relevant information from the KG, we employ a depth-first search strategy constrained by a depth of one from the specified entity.\n",
      "\n",
      "Chunk 618:\n",
      "To prepare for assessing the performance of our GraphRAG system, we follow the below steps: Dataset Preparation:- We use a pre-generated CSV file containing question-answer pairs specific to the earnings call transcript. Iterative Processing:- For each question in the dataset, we run the GraphQAChain to generate an answer. Result Compilation:- We compile the results, including the origi- nal questions, generated answers, retrieved contexts, and ground truth answers, into a structured format.\n",
      "\n",
      "Chunk 619:\n",
      "Finally, the evaluation results are saved in both CSV and JSON formats for further analysis and comparison. We then fed these outputs into our RAG evaluation pipeline. For each Q&A pair in our dataset, we compute all three metrics: faithfulness, answer relevance, context precision and context recall. 4.\n",
      "\n",
      "Chunk 620:\n",
      "4 HybridRAG For the proposed HybridRAG technique, upon obtaining all the contextual information from VectorRAG and GraphRAG, we con- catenate these contexts to form a unified context utilizing both techniques. This combined context is then fed into the answer gen- erator model to produce a response. The context used for response generation is relatively larger, which affects the precision of the generated response.\n",
      "\n",
      "Chunk 621:\n",
      "The context from VectorRAG is appended first, followed by the context from GraphRAG. Consequently, the preci- sion of the generated answer depends on the source context. If the answer is generated from the GraphRAG context, it will have lower precision, as the GraphRAG context is added last in the sequence of contexts provided to the answer generator model, and vice versa. 5 RESULTS We evaluate both the retrieval and generation parts of RAG for the three different RAG pipelines.\n",
      "\n",
      "Chunk 622:\n",
      "Evaluating the RAG outputs is also an active area of research there is no standard tool which is universally accepted as of yet, though we use a currently popular framework RAGAS[ 30] to evaluate the three RAG pipelines in thepresent work where we have modified them a bit to make more precise comparisons. The results of our comparative analysis reveal notable differences in performance among VectorRAG, GraphRAG, and HybridRAG approaches as summarized in Table 5.\n",
      "\n",
      "Chunk 623:\n",
      "In terms of Faithfulness, GraphRAG and HybridRAG demonstrated superior performance, both achieving a score of 0.96, while VectorRAG trailed slightly with a score of 0.94. Answer relevancy scores varied across the meth- ods, with HybridRAG outperforming the others at 0.96, followed by VectorRAG at 0.91, and GraphRAG at 0.89. Context precision was highest for GraphRAG at 0.96, significantly surpassing Vec- torRAG (0.84) and HybridRAG (0.79).\n",
      "\n",
      "Chunk 624:\n",
      "However, in context recall, both VectorRAG and HybridRAG achieved perfect scores of 1, while GraphRAG lagged behind at 0.85. Overall, these results suggest that GraphRAG offers improve- ments over VectorRAG, particularly in faithfulness and context pre- cision. Furthermore, HybridRAG emerges as the most balanced and effective approach, outperforming both VectorRAG and GraphRAG in key metrics such as faithfulness and answer relevancy, while maintaining high context recall.\n",
      "\n",
      "Chunk 625:\n",
      "The relatively lower context precision observed for HybridRAG (0.79) can be attributed to its unique approach of combining con- texts from both VectorRAG and GraphRAG methods. While this integration allows for more comprehensive information retrieval, it also introduces additional content that may not align precisely with the ground truth, thus affecting the context precision met- ric.\n",
      "\n",
      "Chunk 626:\n",
      "Despite this trade-off, HybridRAG’s superior performance in faithfulness, answer relevancy, and context recall underscores its effectiveness. When considering the overall evaluation metrics, HybridRAG emerges as the most promising approach, balancing high-quality answers with comprehensive context retrieval. Overall GraphRAG performs better in extractive questions com- pared to VectorRAG.\n",
      "\n",
      "Chunk 627:\n",
      "And VectorRAG does better in abstractive questions where information is not explicitly mentioned in the raw data. And also GraphRAG sometimes fails to answer ques- tions correctly whenever there is no entity explicitly mentioned in the question. So HybridRAG does a good job overall, as whenever VectorRAG fails to fetch correct context in extractive questions it falls back to GraphRAG to generate the answer.\n",
      "\n",
      "Chunk 628:\n",
      "And whenever GraphRAG fails to fetch correct context in abstractive questions it falls back to VectorRAG to generate the answer. VectorRAG GraphRAG HybridRAG F 0.94 0.96 0.96 AR 0.91 0.89 0.96 CP 0.84 0.96 0.79 CR 1 0.85 1 Table 5: Performance Metrics for Different RAG Pipelines. Here, F, AR, CP and CR refer to Faithfulness, Answer Relevence, Context Precision and Context Recall.\n",
      "\n",
      "Chunk 629:\n",
      "6 CONCLUSION AND FUTURE DIRECTIONS Among the current approaches to mitigate issues regarding infor- mation extraction from external documents that were not part ofSarmah et al. training data for the LLM, Retrieval Augmented Generation (RAG) techniques have emerged as the most popular ones that aim to improve the performance of LLMs by incorporating relevant re- trieval mechanisms.\n",
      "\n",
      "Chunk 630:\n",
      "RAG methods enhance the LLMs’ capabilities by retrieving pertinent documents or text to provide additional context during the generation process. However, these approaches encounter significant limitations when applied to the specialized and intricate domain of financial documents. Furthermore, the qual- ity of the retrieved context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses.\n",
      "\n",
      "Chunk 631:\n",
      "These challenges highlight the need for more sophisticated methods that can effectively integrate and process the detailed and domain- specific information found in financial documents, ensuring more reliable and accurate outputs for informed decision-making. In the present work, we have introduced a novel approach that significantly advances the field of information extraction from finan- cial documents through the development of a hybrid RAG system.\n",
      "\n",
      "Chunk 632:\n",
      "This system, called HybridRAG, which integrates the strengths of both Knowledge Graphs (KGs) and advanced language models, represents a leap forward in our ability to extract and interpret complex information from unstructured financial texts. The hybrid RAG system, by combining traditional vector-based RAG and KG- based RAG, has shown superior performance in terms of retrieval accuracy and answer generation, marking a pivotal step towards more effective financial analysis tools.\n",
      "\n",
      "Chunk 633:\n",
      "Through a comparative analysis using objecive evaluation met- rics, we have highlighted the distinct performance advantages of the HybridRAG approach over its vector-based and KG-based coun- terparts. The HybridRAG system excels in faithfulness, answer relevancy, and context recall, demonstrating the benefits of inte- grating contexts from both VectorRAG and GraphRAG methods, despite potential trade-offs in context precision.\n",
      "\n",
      "Chunk 634:\n",
      "The implications of this research extend beyond the immedi- ate realm of financial analysis. By developing a system capable of understanding and responding to nuanced queries about com- plex financial documents, we pave the way for more sophisticated AI-assisted financial decision-making tools that could potentially democratize access to financial insights, allowing a broader range of stakeholders to engage with and understand financial information.\n",
      "\n",
      "Chunk 635:\n",
      "Future directions for this research include expanding the system to handle multi-modal inputs, incorporating numerical data analysis capabilities, and developing more sophisticated evaluation metrics that capture the nuances of financial language and the accuracy of numerical information in the responses. Additionally, exploring the integration of this system with real-time financial data streams could further enhance its utility in dynamic financial environments.\n",
      "\n",
      "Chunk 636:\n",
      "7 ACKNOWLEDGEMENT The views expressed here are those of the authors alone and not of BlackRock, Inc or NVIDIA. We are grateful to Emma Lind for her invaluable support for this collaboration. REFERENCES [1] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. 2013. [2]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need.\n",
      "\n",
      "Chunk 637:\n",
      "Advances inneural information processing systems, 30, 2017.[3]Yi Yang, Mark Christopher Siy Uy, and Allen Huang. Finbert: A pretrained language model for financial communications. arXiv preprint arXiv:2006.08097 , 2020. [4]Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Se- bastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann. Bloomberggpt: A large language model for finance. arXiv preprint arXiv:2303.17564, 2023.\n",
      "\n",
      "Chunk 638:\n",
      "[5] Yuqi Nie, Yaxuan Kong, Xiaowen Dong, John M Mulvey, H Vincent Poor, Qing- song Wen, and Stefan Zohren. A survey of large language models for financial ap- plications: Progress, prospects and challenges. arXiv preprint arXiv:2406.11903 , 2024. [6]Huaqin Zhao, Zhengliang Liu, Zihao Wu, Yiwei Li, Tianze Yang, Peng Shu, Shaochen Xu, Haixing Dai, Lin Zhao, Gengchen Mai, Ninghao Liu, and Tianming Liu. Revolutionizing finance with llms: An overview of applications and insights, 2024.\n",
      "\n",
      "Chunk 639:\n",
      "[7] Chen Ling, Xujiang Zhao, Jiaying Lu, Chengyuan Deng, Can Zheng, Junxiang Wang, Tanmoy Chowdhury, Yun Li, Hejie Cui, Xuchao Zhang, et al. Domain spe- cialization as the key to make large language models disruptive: A comprehensive survey. arXiv preprint arXiv:2305.18703, 2023. [8] Bhaskarjit Sarmah, Dhagash Mehta, Stefano Pasquali, and Tianjie Zhu. Towards reducing hallucination in extracting information from financial reports using large language models.\n",
      "\n",
      "Chunk 640:\n",
      "In Proceedings oftheThird International Conference onAI-ML Systems, pages 1–5, 2023. [9]Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances inNeural Information Processing Systems , 33:9459–9474, 2020. [10] Gautier Izacard and Edouard Grave.\n",
      "\n",
      "Chunk 641:\n",
      "Leveraging passage retrieval with generative models for open domain question answering. arXiv preprint arXiv:2007.01282 , 2021. [11] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. Realm: Retrieval-augmented language model pre-training. arXiv preprint arXiv:2002.08909, 2020. [12] Antonio Jose Jimeno Yepes et al. Financial report chunking for effective retrieval augmented generation. arXiv preprint arXiv:2402.05131, 2024. [13] SuperAcc.\n",
      "\n",
      "Chunk 642:\n",
      "Retrieval-augmented generation on financial statements. SuperAcc Insights, 2024. [14] Shaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, and S Yu Philip. A survey on knowledge graphs: Representation, acquisition, and applications. IEEE transactions onneural networks andlearning systems, 33(2):494–514, 2021. [15] Heiko Paulheim. Knowledge graphs: State of the art and future directions. Semantic Web Journal, 10(4):1–20, 2017.\n",
      "\n",
      "Chunk 643:\n",
      "[16] Aidan Hogan, Eva Blomqvist, Michael Cochez, Claudia D’Amato, Gerard de Melo, Claudio Gutiérrez, and Maria ... Maleshkova. Knowledge graphs. arXiv preprint arXiv:2003.02320, 2021. [17] Lisa Ehrlinger and Wolfram Wöß. Towards a definition of knowledge graphs. In SEMANTiCS (Posters, Demos, SuCCESS), pages 1–4, 2016. [18] Xiaohui Victor Li and Francesco Sanna Passino. Findkg: Dynamic knowledge graphs with large language models for detecting global trends in financial mar- kets.\n",
      "\n",
      "Chunk 644:\n",
      "arXiv preprint arXiv:2407.10909, 2024. [19] Shourya De, Anima Aggarwal, and Anna Cinzia Squicciarini. Financial knowl- edge graphs: A novel approach to empower data-driven financial applications. In IEEE International Conference onBigData (Big Data), pages 1311–1320, 2018. [20] Marina Petrova and Birgit Reinwald. Knowledge graphs in finance: Applications and opportunities. Journal ofFinancial Data Science, 2(2):10–19, 2020. [21] Wei Liu, Jun Zhang, and Li Pan.\n",
      "\n",
      "Chunk 645:\n",
      "Utilizing knowledge graphs for financial data integration and analysis. Data Science Journal, 18(1):1–15, 2019. [22] Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, and Jonathan Larson. From local to global: A graph rag approach to query-focused summarization. arXiv preprint arXiv:2404.16130 , 2024. [23] Xuchen Yao, Yanan Sun, Zhen Huang, and Dong Li. Retrieval-augmented gener- ation for knowledge-intensive nlp tasks. arXiv preprint arXiv:2101.\n",
      "\n",
      "Chunk 646:\n",
      "07554 , 2021. [24] Weizhi Zhao, Haoyu Chen, Kai Liu, and Jun Zhao. Graph-based retrieval- augmented generation for open-domain question answering. In Proceedings oftheAAAI Conference onArtificial Intelligence , volume 36, pages 3098–3106, 2022. [25] Bill Yuchen Lin, Yuanhe Liu, Ming Shen, and Xiang Ren. Kgpt: Knowledge- grounded pre-training for data-to-text generation. In Findings oftheAssociation forComputational Linguistics: EMNLP 2020, pages 710–724, 2020.\n",
      "\n",
      "Chunk 647:\n",
      "[26] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Ji- awei Sun, and Haofen Wang. Retrieval-augmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997, 2023. [27] Tyler Procko. Graph retrieval-augmented generation for large language models: A survey. Available atSSRN, 2024. [28] Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, and Xindong Wu. A comprehensive survey on automatic knowledge graph construction.\n",
      "\n",
      "Chunk 648:\n",
      "ACM Computing Surveys , 56(4):1–62, 2023.HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction [29] Ishani Mondal, Yufang Hou, and Charles Jochim. End-to-end nlp knowledge graph construction. arXiv preprint arXiv:2106.01167, 2021. [30] Shahul Es, Jithin James, Luis Espinosa-Anke, and Steven Schockaert. Ra- gas: Automated evaluation of retrieval augmented generation. arXiv preprint arXiv:2309.15217, 2023.\n",
      "\n",
      "Chunk 649:\n",
      "[31] Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan Routledge, et al. Finqa: A dataset of numerical reasoning over financial data. arXiv preprint arXiv:2109.00122, 2021. [32] Macedo Maia, Siegfried Handschuh, André Freitas, Brian Davis, Ross McDermott, Manel Zarrouk, and Alexandra Balahur. Www’18 open challenge: financial opinion mining and question answering.\n",
      "\n",
      "Chunk 650:\n",
      "In Companion proceedings ofthetheweb conference 2018, pages 1941–1942, 2018. [33] Fengbin Zhu, Wenqiang Lei, Youcheng Huang, Chao Wang, Shuo Zhang, Jiancheng Lv, Fuli Feng, and Tat-Seng Chua. Tat-qa: A question answering benchmark on a hybrid of tabular and textual content in finance. arXiv preprint arXiv:2105.07624, 2021. [34] Pranab Islam, Anand Kannappan, Douwe Kiela, Rebecca Qian, Nino Scherrer, and Bertie Vidgen. Financebench: A new benchmark for financial question answering.\n",
      "\n",
      "Chunk 651:\n",
      "arXiv preprint arXiv:2311.11944, 2023. [35] Jian Chen, Peilin Zhou, Yining Hua, Yingxin Loh, Kehui Chen, Ziyuan Li, Bing Zhu, and Junwei Liang. Fintextqa: A dataset for long-form financial question answering. arXiv preprint arXiv:2405.09980, 2024.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_by_sentence(text,500)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}:\\n{chunk}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc. New York, NY, USADhagash Mehta dhagash.mehta@blackrock.',\n",
       " 'com BlackRock, Inc.',\n",
       " 'New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.',\n",
       " 'We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.',\n",
       " 'Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.',\n",
       " 'The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.',\n",
       " 'However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.',\n",
       " 'Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].',\n",
       " 'Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.',\n",
       " 'In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.',\n",
       " 'Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.',\n",
       " 'VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.',\n",
       " 'For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].',\n",
       " 'Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.',\n",
       " 'Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.',\n",
       " 'com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc. New York, NY, USADhagash Mehta dhagash.mehta@blackrock.com BlackRock, Inc.',\n",
       " 'New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.',\n",
       " 'We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.',\n",
       " 'Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.',\n",
       " 'The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.',\n",
       " 'However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.',\n",
       " 'Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].',\n",
       " 'Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.',\n",
       " 'In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.',\n",
       " 'Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.',\n",
       " 'VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.',\n",
       " 'For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].',\n",
       " 'Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.',\n",
       " 'Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.',\n",
       " 'KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.',\n",
       " 'However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].',\n",
       " 'Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.',\n",
       " 'However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.',\n",
       " 'By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.',\n",
       " 'In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.',\n",
       " '1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].',\n",
       " 'Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.',\n",
       " 'We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.',\n",
       " '2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.',\n",
       " 'This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.',\n",
       " 'This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.',\n",
       " 'In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.',\n",
       " 'The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.',\n",
       " 'The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.',\n",
       " ', a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.',\n",
       " 'htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc. New York, NY, USADhagash Mehta dhagash.mehta@blackrock.',\n",
       " 'com BlackRock, Inc.',\n",
       " 'New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.',\n",
       " 'We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.',\n",
       " 'Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.',\n",
       " 'The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.',\n",
       " 'However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.',\n",
       " 'Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].',\n",
       " 'Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.',\n",
       " 'In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.',\n",
       " 'Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.',\n",
       " 'VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.',\n",
       " 'For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].',\n",
       " 'Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.',\n",
       " 'Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.',\n",
       " 'KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.',\n",
       " 'However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].',\n",
       " 'Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.',\n",
       " 'However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.',\n",
       " 'By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.',\n",
       " 'In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.',\n",
       " '1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].',\n",
       " 'Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.',\n",
       " 'We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.',\n",
       " '2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.',\n",
       " 'This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.',\n",
       " 'This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.',\n",
       " 'In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.',\n",
       " 'The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.',\n",
       " 'The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.',\n",
       " ', a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.',\n",
       " 'htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Figure 1: A schematic diagram describing the vector database creation of a RAG application. improvement, and knowledge adaptation [ 28]. Here, we do not use knowledge adaptation and treat the KGs as static graphs.',\n",
       " 'Knowledge Extraction:- This step aims to extract structured in- formation from unstructured or semi-structured data, such as text, databases, and existing ontologies. The main tasks in this step are entity recognition, relationship extraction, and co-reference reso- lution. Entity recognition and relationship extraction techniques use typical NLP tasks to identify entities and their relationships from textual sources [ 29].',\n",
       " 'Coreference resolution identifies and connects different references of the same entity, keeping coherence within the knowledge graph. For example, if the text refers to a company as both \"the company\" and \"it\", coreference resolution can link these mentions to the same entity node in the graph. Knowledge Improvement:- This step aims to enhance the quality and completeness of the KG by removing redundancies and address- ing gaps in the extracted information.',\n",
       " 'The primary tasks in this step are KG completion and fusion. KG completion technique infers missing entities and relationships within the graph using meth- ods such as link prediction and entity resolution. Link prediction predicts the existence and type of a relation between two entities based on the graph structure and features, while entity resolution matches and merges different representations of the same entity from different sources.',\n",
       " 'Knowledge fusion combines information from multiple sources to create a coherent and unified KG. This involves resolving conflicts and redundancies among the sources, such as contradictory or duplicate facts, and aggregating or reconciling the information based on rules, probabilities, or semantic similarity. We utilized a robust methodology for creating KG triplets from unstructured text data, specifically focusing on corporate docu- ments such as earnings call transcripts, adapted from Ref.',\n",
       " '[ 18?]. This process involves several interconnected stages, each designed to extract, refine, and structure information effectively. We implement a two-tiered LLM chain for content refinement and information extraction. The first tier employs an LLM to gen- erate an abstract representation of each document chunk.',\n",
       " 'This refinement process is crucial as it distills the essential information while preserving the original meaning and key relationships be- tween concepts that serves as a more focused input for subsequent processing, enhancing the overall efficiency and accuracy of ourtriplet extraction pipeline. The second tier of our LLM chain is dedicated to entity extraction and relationship identification. Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM.',\n",
       " 'A detailed discussion on imple- mentation of the methodology will be provided in Section 4.1 2.3 GraphRAG KG based RAG [ 22], or GraphRAG, also begins with a query based on the user’s input same as VectorRAG. The main difference be- tween VectorRAG and GraphRAG lies in the retrieval part. The query here is now used to search the KG to retrieve relevant nodes (entities) and edges (relationships) related to the query.',\n",
       " 'A subgraph, which consists of these relevant nodes and edges, is extracted from the full KG to provide context. This subgraph is then integrated with the language model’s internal knowledge, by encoding the graph structure into embeddings that the model can interpret. The language model uses this combined context to generate responses that are informed by both the structured information from the KG and its pre-trained knowledge.',\n",
       " 'Crucially, when responding to user queries about a particular company, we leveraged the metadata information to selectively filter and retrieve only those document segments pertinent to the queried company [ 8]. This integration helps ensure that the generated outputs are accurate, contextually relevant, and grounded in verifiable information. A schematic diagram of the retrieval methodology of GraphRAG is given in Figure 2.',\n",
       " 'Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section 4.1 Figure 2: A schematic diagram describing knowledge graph creation process of GraphRAG. 2.3.1 HybridRAG. For the HybridRAG technique, we propose to integrate the aforementioned two distinct RAG techniques: Vec- torRAG and GraphRAG.',\n",
       " 'This integration involves a systematic combination of contextual information retrieved from both the traditional vector-based retrieval mechanism and the KG-based retrieval system, the latter of which was constructed specifically for this study. The amalgamation of these two contexts allows us to leverage the strengths of both approaches.',\n",
       " 'The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-richHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.',\n",
       " 'com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc. New York, NY, USADhagash Mehta dhagash.mehta@blackrock.com BlackRock, Inc.',\n",
       " 'New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.',\n",
       " 'We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.',\n",
       " 'Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.',\n",
       " 'The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.',\n",
       " 'However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.',\n",
       " 'Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].',\n",
       " 'Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.',\n",
       " 'In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.',\n",
       " 'Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.',\n",
       " 'VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.',\n",
       " 'For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].',\n",
       " 'Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.',\n",
       " 'Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.',\n",
       " 'KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.',\n",
       " 'However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].',\n",
       " 'Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.',\n",
       " 'However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.',\n",
       " 'By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.',\n",
       " 'In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.',\n",
       " '1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].',\n",
       " 'Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.',\n",
       " 'We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.',\n",
       " '2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.',\n",
       " 'This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.',\n",
       " 'This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.',\n",
       " 'In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.',\n",
       " 'The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.',\n",
       " 'The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.',\n",
       " ', a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.',\n",
       " 'htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Figure 1: A schematic diagram describing the vector database creation of a RAG application. improvement, and knowledge adaptation [ 28]. Here, we do not use knowledge adaptation and treat the KGs as static graphs.',\n",
       " 'Knowledge Extraction:- This step aims to extract structured in- formation from unstructured or semi-structured data, such as text, databases, and existing ontologies. The main tasks in this step are entity recognition, relationship extraction, and co-reference reso- lution. Entity recognition and relationship extraction techniques use typical NLP tasks to identify entities and their relationships from textual sources [ 29].',\n",
       " 'Coreference resolution identifies and connects different references of the same entity, keeping coherence within the knowledge graph. For example, if the text refers to a company as both \"the company\" and \"it\", coreference resolution can link these mentions to the same entity node in the graph. Knowledge Improvement:- This step aims to enhance the quality and completeness of the KG by removing redundancies and address- ing gaps in the extracted information.',\n",
       " 'The primary tasks in this step are KG completion and fusion. KG completion technique infers missing entities and relationships within the graph using meth- ods such as link prediction and entity resolution. Link prediction predicts the existence and type of a relation between two entities based on the graph structure and features, while entity resolution matches and merges different representations of the same entity from different sources.',\n",
       " 'Knowledge fusion combines information from multiple sources to create a coherent and unified KG. This involves resolving conflicts and redundancies among the sources, such as contradictory or duplicate facts, and aggregating or reconciling the information based on rules, probabilities, or semantic similarity. We utilized a robust methodology for creating KG triplets from unstructured text data, specifically focusing on corporate docu- ments such as earnings call transcripts, adapted from Ref.',\n",
       " '[ 18?]. This process involves several interconnected stages, each designed to extract, refine, and structure information effectively. We implement a two-tiered LLM chain for content refinement and information extraction. The first tier employs an LLM to gen- erate an abstract representation of each document chunk.',\n",
       " 'This refinement process is crucial as it distills the essential information while preserving the original meaning and key relationships be- tween concepts that serves as a more focused input for subsequent processing, enhancing the overall efficiency and accuracy of ourtriplet extraction pipeline. The second tier of our LLM chain is dedicated to entity extraction and relationship identification. Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM.',\n",
       " 'A detailed discussion on imple- mentation of the methodology will be provided in Section 4.1 2.3 GraphRAG KG based RAG [ 22], or GraphRAG, also begins with a query based on the user’s input same as VectorRAG. The main difference be- tween VectorRAG and GraphRAG lies in the retrieval part. The query here is now used to search the KG to retrieve relevant nodes (entities) and edges (relationships) related to the query.',\n",
       " 'A subgraph, which consists of these relevant nodes and edges, is extracted from the full KG to provide context. This subgraph is then integrated with the language model’s internal knowledge, by encoding the graph structure into embeddings that the model can interpret. The language model uses this combined context to generate responses that are informed by both the structured information from the KG and its pre-trained knowledge.',\n",
       " 'Crucially, when responding to user queries about a particular company, we leveraged the metadata information to selectively filter and retrieve only those document segments pertinent to the queried company [ 8]. This integration helps ensure that the generated outputs are accurate, contextually relevant, and grounded in verifiable information. A schematic diagram of the retrieval methodology of GraphRAG is given in Figure 2.',\n",
       " 'Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section 4.1 Figure 2: A schematic diagram describing knowledge graph creation process of GraphRAG. 2.3.1 HybridRAG. For the HybridRAG technique, we propose to integrate the aforementioned two distinct RAG techniques: Vec- torRAG and GraphRAG.',\n",
       " 'This integration involves a systematic combination of contextual information retrieved from both the traditional vector-based retrieval mechanism and the KG-based retrieval system, the latter of which was constructed specifically for this study. The amalgamation of these two contexts allows us to leverage the strengths of both approaches.',\n",
       " 'The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-richSarmah et al. contextual data. This combined context is then utilized as input for a LLM to generate the final responses. Details on the implementation of the HybridRAG will be provided in Section 4.4. 2.',\n",
       " '4 Evaluation Metrics To assess the efficacy of this integrated approach, we conducted a comparative analysis among the three approaches in a controlled ex- perimental set up: VectorRAG, GraphRAG and HybridRAG. The re- sponses generated using the combined VectorRAG and GraphRAG contexts were juxtaposed against those produced individually by VectorRAG and GraphRAG.',\n",
       " 'This comparative evaluation aimed to discern potential improvements in response quality, accuracy, and comprehensiveness that might arise from the synergistic integra- tion of these two RAG methodologies. To objectively evaluate different RAG approaches (VectorRAG and GraphRAG in their case), Ref. [ 22] utilized metrics such as comprehensiveness (i.e., the amount of details the answer provides to cover all aspects and details of the question?); diversity (i.e.',\n",
       " ', the richness of the answer in providing different perspectives and insights on the question); empowerment (i.e., the helpfulness of the answer to the reader understand and make informed judgements about the topic); and, directness (i.e., clearness of the answer in addressing the question). here, the LLM was provided tuples of question, target metric, and a pair of answers, and was asked to assess which answer was better according to the metric and why.',\n",
       " 'These metrics though compare the final generated answers, do not necessarily directly evaluate the retrieval and generation parts separately. Instead, here we implement a comprehensive set of evaluation metrics which are designed to capture different aspects of a given RAG system’s output quality, focusing on faithfulness, answer relevance, and context relevance [ 30]. Each metric provides unique insights into the system’s capabilities and limitations. 2.4.1 Faithfulness.',\n",
       " 'Faithfulness is a crucial metric that measures the extent to which the generated answer can be inferred from the provided context. Our implementation of the faithfulness metric involves a two-step process: Statement Extraction:- We use an LLM to decompose the gener- ated answer into a set of concise statements. This step is crucial for breaking down complex answers into more manageable and verifiable units.',\n",
       " 'The prompt used for this step is: \"Given a question and answer, create one or more statements from each sentence in the given answer. question: [question] an- swer: [answer]\". Statement Verification:- For each extracted statement, we employ the LLM to determine if it can be inferred from the given context.',\n",
       " 'This verification process uses the following prompt: \"Consider the given context and following statements, then de- termine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. statement: [statement 1] ... statement: [statement n]\".',\n",
       " 'The faithfulness score ( 𝐹) is𝐹=|𝑉|/|𝑆|, where |𝑉|is the number of supported statements and |𝑆|is the total number of statements.2.4.2 Answer Relevance:-. The answer relevance metric assesses how well the generated answer addresses the original question, irrespective of factual accuracy. This metric helps identify cases of incomplete answers or responses containing irrelevant information.',\n",
       " 'Our implementation involves the following steps: Question Generation: We prompt the LLM to generate n potential questions based on the given answer: \"Generate a question for the given answer. answer: [answer]\". Then, we obtain embeddings for all generated questions and the original question using OpenAI’s text-embedding-ada-002 model2. We then calculate the cosine similarity between each generated question’s embedding and the original question’s embedding.',\n",
       " 'Finally, the answer relevance score (AR) is computed as the aver- age similarity across all generated questions: 𝐴𝑅=1 𝑛Í(𝑠𝑖𝑚(𝑞,𝑞𝑖)), where𝑠𝑖𝑚(𝑞,𝑞𝑖)is the cosine similarity between the embedding of the original question 𝑞and the embeddings of each of the 𝑛 generated questions 𝑞𝑖. 2.4.3 Context Precision. It is a metric used to evaluate the relevance of retrieved context chunks in relation to a specified ground truth for a given question3.',\n",
       " 'It calculates the proportion of relevant items that appear in the top ranks of the context. The formula for context precision at K is the sum of the products of precision at each rank k and a binary relevance indicator v_k, divided by the total number of relevant items in the top K results. Precision at each rank k is determined by the ratio of true positives at k to the sum of true positives and false positives at k.',\n",
       " 'This metric helps in assessing how well the context supports the ground truth, aiming for higher scores which indicate better precision. 2.4.4 Context Recall. It is a metric used to evaluate how well the retrieved context aligns with the ground truth answer, which is considered the definitive correct response4. It is quantified by com- paring each sentence in the ground truth answer to see if it can be traced back to the retrieved context.',\n",
       " 'The formula for context recall is the ratio of the number of ground truth sentences that can be attributed to the context to the total number of sentences in the ground truth. Higher values, ranging from 0 to 1, indicate bet- ter alignment and thus better context recall. This metric is crucial for assessing the effectiveness of information retrieval systems in providing relevant context.',\n",
       " '3 DATA DESCRIPTION Although there do exist some public financial datasets, none of them were suitable for the present experiments: e.g., FinQA [ 31], TAT- QA [ 32], FIQA [ 33], FinanceBench [ 34], etc. datasets are limited to specific usecases such as benchmarking LLMs’ abilities to perform complex numerical reasoning or sentiment analysis. On the other hand, FinTextQA [ 35] dataset was not publicly available at the time of writing the present work.',\n",
       " 'In addition, in most of these datasets, access to the actual documents from which the ground- truth Q&As were created is not available, making it impossible to use them for our RAG techniques evaluation purposes. Hence, we resorted to a dataset of our own though through publicly available 2https://platform.openai.com/docs/guides/embeddings/embedding-models 3https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html 4https://docs.ragas.io/en/stable/concepts/metrics/context_recall.',\n",
       " 'htmlHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc. New York, NY, USADhagash Mehta dhagash.mehta@blackrock.',\n",
       " 'com BlackRock, Inc.',\n",
       " 'New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.',\n",
       " 'We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.',\n",
       " 'Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.',\n",
       " 'The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.',\n",
       " 'However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.',\n",
       " 'Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].',\n",
       " 'Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.',\n",
       " 'In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.',\n",
       " 'Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.',\n",
       " 'VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.',\n",
       " 'For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].',\n",
       " 'Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.',\n",
       " 'Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.',\n",
       " 'KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.',\n",
       " 'However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].',\n",
       " 'Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.',\n",
       " 'However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.',\n",
       " 'By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.',\n",
       " 'In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.',\n",
       " '1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].',\n",
       " 'Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.',\n",
       " 'We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.',\n",
       " '2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.',\n",
       " 'This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.',\n",
       " 'This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.',\n",
       " 'In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.',\n",
       " 'The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.',\n",
       " 'The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.',\n",
       " ', a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.',\n",
       " 'htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Figure 1: A schematic diagram describing the vector database creation of a RAG application. improvement, and knowledge adaptation [ 28]. Here, we do not use knowledge adaptation and treat the KGs as static graphs.',\n",
       " 'Knowledge Extraction:- This step aims to extract structured in- formation from unstructured or semi-structured data, such as text, databases, and existing ontologies. The main tasks in this step are entity recognition, relationship extraction, and co-reference reso- lution. Entity recognition and relationship extraction techniques use typical NLP tasks to identify entities and their relationships from textual sources [ 29].',\n",
       " 'Coreference resolution identifies and connects different references of the same entity, keeping coherence within the knowledge graph. For example, if the text refers to a company as both \"the company\" and \"it\", coreference resolution can link these mentions to the same entity node in the graph. Knowledge Improvement:- This step aims to enhance the quality and completeness of the KG by removing redundancies and address- ing gaps in the extracted information.',\n",
       " 'The primary tasks in this step are KG completion and fusion. KG completion technique infers missing entities and relationships within the graph using meth- ods such as link prediction and entity resolution. Link prediction predicts the existence and type of a relation between two entities based on the graph structure and features, while entity resolution matches and merges different representations of the same entity from different sources.',\n",
       " 'Knowledge fusion combines information from multiple sources to create a coherent and unified KG. This involves resolving conflicts and redundancies among the sources, such as contradictory or duplicate facts, and aggregating or reconciling the information based on rules, probabilities, or semantic similarity. We utilized a robust methodology for creating KG triplets from unstructured text data, specifically focusing on corporate docu- ments such as earnings call transcripts, adapted from Ref.',\n",
       " '[ 18?]. This process involves several interconnected stages, each designed to extract, refine, and structure information effectively. We implement a two-tiered LLM chain for content refinement and information extraction. The first tier employs an LLM to gen- erate an abstract representation of each document chunk.',\n",
       " 'This refinement process is crucial as it distills the essential information while preserving the original meaning and key relationships be- tween concepts that serves as a more focused input for subsequent processing, enhancing the overall efficiency and accuracy of ourtriplet extraction pipeline. The second tier of our LLM chain is dedicated to entity extraction and relationship identification. Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM.',\n",
       " 'A detailed discussion on imple- mentation of the methodology will be provided in Section 4.1 2.3 GraphRAG KG based RAG [ 22], or GraphRAG, also begins with a query based on the user’s input same as VectorRAG. The main difference be- tween VectorRAG and GraphRAG lies in the retrieval part. The query here is now used to search the KG to retrieve relevant nodes (entities) and edges (relationships) related to the query.',\n",
       " 'A subgraph, which consists of these relevant nodes and edges, is extracted from the full KG to provide context. This subgraph is then integrated with the language model’s internal knowledge, by encoding the graph structure into embeddings that the model can interpret. The language model uses this combined context to generate responses that are informed by both the structured information from the KG and its pre-trained knowledge.',\n",
       " 'Crucially, when responding to user queries about a particular company, we leveraged the metadata information to selectively filter and retrieve only those document segments pertinent to the queried company [ 8]. This integration helps ensure that the generated outputs are accurate, contextually relevant, and grounded in verifiable information. A schematic diagram of the retrieval methodology of GraphRAG is given in Figure 2.',\n",
       " 'Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section 4.1 Figure 2: A schematic diagram describing knowledge graph creation process of GraphRAG. 2.3.1 HybridRAG. For the HybridRAG technique, we propose to integrate the aforementioned two distinct RAG techniques: Vec- torRAG and GraphRAG.',\n",
       " 'This integration involves a systematic combination of contextual information retrieved from both the traditional vector-based retrieval mechanism and the KG-based retrieval system, the latter of which was constructed specifically for this study. The amalgamation of these two contexts allows us to leverage the strengths of both approaches.',\n",
       " 'The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-richSarmah et al. contextual data. This combined context is then utilized as input for a LLM to generate the final responses. Details on the implementation of the HybridRAG will be provided in Section 4.4. 2.',\n",
       " '4 Evaluation Metrics To assess the efficacy of this integrated approach, we conducted a comparative analysis among the three approaches in a controlled ex- perimental set up: VectorRAG, GraphRAG and HybridRAG. The re- sponses generated using the combined VectorRAG and GraphRAG contexts were juxtaposed against those produced individually by VectorRAG and GraphRAG.',\n",
       " 'This comparative evaluation aimed to discern potential improvements in response quality, accuracy, and comprehensiveness that might arise from the synergistic integra- tion of these two RAG methodologies. To objectively evaluate different RAG approaches (VectorRAG and GraphRAG in their case), Ref. [ 22] utilized metrics such as comprehensiveness (i.e., the amount of details the answer provides to cover all aspects and details of the question?); diversity (i.e.',\n",
       " ', the richness of the answer in providing different perspectives and insights on the question); empowerment (i.e., the helpfulness of the answer to the reader understand and make informed judgements about the topic); and, directness (i.e., clearness of the answer in addressing the question). here, the LLM was provided tuples of question, target metric, and a pair of answers, and was asked to assess which answer was better according to the metric and why.',\n",
       " 'These metrics though compare the final generated answers, do not necessarily directly evaluate the retrieval and generation parts separately. Instead, here we implement a comprehensive set of evaluation metrics which are designed to capture different aspects of a given RAG system’s output quality, focusing on faithfulness, answer relevance, and context relevance [ 30]. Each metric provides unique insights into the system’s capabilities and limitations. 2.4.1 Faithfulness.',\n",
       " 'Faithfulness is a crucial metric that measures the extent to which the generated answer can be inferred from the provided context. Our implementation of the faithfulness metric involves a two-step process: Statement Extraction:- We use an LLM to decompose the gener- ated answer into a set of concise statements. This step is crucial for breaking down complex answers into more manageable and verifiable units.',\n",
       " 'The prompt used for this step is: \"Given a question and answer, create one or more statements from each sentence in the given answer. question: [question] an- swer: [answer]\". Statement Verification:- For each extracted statement, we employ the LLM to determine if it can be inferred from the given context.',\n",
       " 'This verification process uses the following prompt: \"Consider the given context and following statements, then de- termine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. statement: [statement 1] ... statement: [statement n]\".',\n",
       " 'The faithfulness score ( 𝐹) is𝐹=|𝑉|/|𝑆|, where |𝑉|is the number of supported statements and |𝑆|is the total number of statements.2.4.2 Answer Relevance:-. The answer relevance metric assesses how well the generated answer addresses the original question, irrespective of factual accuracy. This metric helps identify cases of incomplete answers or responses containing irrelevant information.',\n",
       " 'Our implementation involves the following steps: Question Generation: We prompt the LLM to generate n potential questions based on the given answer: \"Generate a question for the given answer. answer: [answer]\". Then, we obtain embeddings for all generated questions and the original question using OpenAI’s text-embedding-ada-002 model2. We then calculate the cosine similarity between each generated question’s embedding and the original question’s embedding.',\n",
       " 'Finally, the answer relevance score (AR) is computed as the aver- age similarity across all generated questions: 𝐴𝑅=1 𝑛Í(𝑠𝑖𝑚(𝑞,𝑞𝑖)), where𝑠𝑖𝑚(𝑞,𝑞𝑖)is the cosine similarity between the embedding of the original question 𝑞and the embeddings of each of the 𝑛 generated questions 𝑞𝑖. 2.4.3 Context Precision. It is a metric used to evaluate the relevance of retrieved context chunks in relation to a specified ground truth for a given question3.',\n",
       " 'It calculates the proportion of relevant items that appear in the top ranks of the context. The formula for context precision at K is the sum of the products of precision at each rank k and a binary relevance indicator v_k, divided by the total number of relevant items in the top K results. Precision at each rank k is determined by the ratio of true positives at k to the sum of true positives and false positives at k.',\n",
       " 'This metric helps in assessing how well the context supports the ground truth, aiming for higher scores which indicate better precision. 2.4.4 Context Recall. It is a metric used to evaluate how well the retrieved context aligns with the ground truth answer, which is considered the definitive correct response4. It is quantified by com- paring each sentence in the ground truth answer to see if it can be traced back to the retrieved context.',\n",
       " 'The formula for context recall is the ratio of the number of ground truth sentences that can be attributed to the context to the total number of sentences in the ground truth. Higher values, ranging from 0 to 1, indicate bet- ter alignment and thus better context recall. This metric is crucial for assessing the effectiveness of information retrieval systems in providing relevant context.',\n",
       " '3 DATA DESCRIPTION Although there do exist some public financial datasets, none of them were suitable for the present experiments: e.g., FinQA [ 31], TAT- QA [ 32], FIQA [ 33], FinanceBench [ 34], etc. datasets are limited to specific usecases such as benchmarking LLMs’ abilities to perform complex numerical reasoning or sentiment analysis. On the other hand, FinTextQA [ 35] dataset was not publicly available at the time of writing the present work.',\n",
       " 'In addition, in most of these datasets, access to the actual documents from which the ground- truth Q&As were created is not available, making it impossible to use them for our RAG techniques evaluation purposes. Hence, we resorted to a dataset of our own though through publicly available 2https://platform.openai.com/docs/guides/embeddings/embedding-models 3https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html 4https://docs.ragas.io/en/stable/concepts/metrics/context_recall.',\n",
       " 'htmlHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction documents but such that we finally have access to both the actual financial documents and the ground-truth Q&As. Datasets like FinanceBench5provides question-context-answer triplets but they are not useful as here we are comparing VectorRAG, GraphRAG and HybridRAG and they do not provide the context generated from a KG.',\n",
       " 'A recent paper [ 22] has not made the KG and triplets constructed by their algorithm public to the best of our knowledge either. In short, there is no publicly available benchmark dataset to compare VectorRAG and GraphRAG either for financial or general domains to the best of our knowledge. Hence, we had to rely on our own dataset constructed as explained below. We used transcripts from earnings calls of Nifty 50 constituents for our analysis.',\n",
       " 'The NIFTY 50 is popular index in the Indian stock market that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange (NSE). The dataset of the earning call documents of Nifty 50 companies is widely recognized in the investment realm and is esteemed as an authoritative and extensive collection of earnings call transcripts. In our investigation, we focus on data spanning the quarter ending in June, 2023 i.e.',\n",
       " 'the earnings reports for Q1 of the financial year 2024 (A financial year in India starts on the 1st April and ends in 31st March, so the quarter from 1st April to 30th June is the first quarter of 2024 for the Indian market).',\n",
       " 'Our dataset encompasses 50 transcripts for this quarter, span- ning over 50 companies within Nifty 50 universe from diverse range of sectors including Infrastructure, Healthcare, Consumer Durables, Banking, Automobile, Financial Services, Energy - Oil & Gas, Telecommunication, Consumer Goods, Pharmaceuticals, Energy - Coal, Materials, Information Technology, Construction, Diversified, Metals, Energy - Power and Chemicals providing a substantial and diverse foundation for our study.',\n",
       " 'We start the data collection process focused on acquiring earn- ings reports from company websites within the Nifty 50 universe by developing and deploying a custom web scraping tool to navigate through the websites of each company within the Nifty 50 index, systematically retrieving the pertinent earnings reports for Q1 of the financial year 2024. By utilizing this web scraping approach, we aimed to compile a comprehensive dataset encompassing the earnings reports of the constituent companies.',\n",
       " 'Table 1 summarizes basic statistics of the documents we will be experimenting with in the remainder of this work. Number of companies/documents 50 Average number of pages 27 Average number of questions 16 Average number of tokens 60,000 Table 1: Summary Statistics for the call transcript documents used in the present work.',\n",
       " 'These call transcripts documents consist of questions and an- swers between financial analysts and the company representatives for the respective companies, hence, there already exist certain Q&A pairs within these documents along with additional text. We examined the earnings reports within the Nifty50 universe, system- atically curated a comprehensive array of randomly selected 400 5https://huggingface.',\n",
       " 'co/datasets/PatronusAI/financebench-testquestions posed during the earnings calls from all the documents, and gathered the exact responses corresponding to these questions. These questions constitute the specific queries articulated by finan- cial analysts to the management during these calls. 4 IMPLEMENTATION DETAILS In this Section, we provide details of implementation of the pro- posed methodology. 4.',\n",
       " '1 Knowledge Graph Construction The initial phase of our approach centers on document preprocess- ing. We utilize the PyPDFLoader6to import PDF documents, which are subsequently segmented into manageable chunks using the RecursiveCharacterTextSplitter. This chunking strategy employs a size of 2024 characters with an overlap of 204 characters, ensuring comprehensive coverage while maintaining context across segment boundaries.',\n",
       " 'Following the preprocessing stage, we implement the two-tiered language model chain for content refinement and information ex- traction. It is not possible to include the exact prompt here due to the limited space, but a baseline prompt can be found in Ref. [18].',\n",
       " 'Entity Type Examples Companies and Corpo- rationsOfficial names, abbreviations, infor- mal references Financial Metrics and IndicatorsRevenue, profit margins, EBITDA Corporate Executives and Key PersonnelCEOs, CFOs, board members Products and Services Tangible products and intangible ser- vices Geographical Locations Headquarters, operational regions, markets Corporate Events Mergers, acquisitions, product launches, earnings calls Legal and Regulatory InformationLegal cases, regulatory compliance Table 2: Entities extracted from earnings call transcripts Table 2 summarizes details on entities extracted from the earn- ing calls transcripts using our prompt based method.',\n",
       " 'Concurrently, LLM identifies relationships between these entities using a curated set of verbs, capturing the nuanced interactions within the cor- porate narrative. A key improvement in our methodology is the enhanced prompt engineering to generate the structured output format for knowledge triplets.',\n",
       " 'Each triplet is represented as a nested list [’h’, ’type’, ’r’, ’o’, ’type’, ’metadata’], where ’h’ and ’o’ denote the head and object entities respectively, ’type’ specifies the entity category, ’r’ represents the relationship, and ’metadata’ encapsu- lates additional contextual information. This format allows for a rich, multidimensional representation of information, facilitating more nuanced downstream analysis. 6https://python.langchain.com/v0.',\n",
       " '1/docs/modules/data_connection/document_ loaders/pdf/HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc.',\n",
       " 'New York, NY, USADhagash Mehta dhagash.mehta@blackrock.com BlackRock, Inc.',\n",
       " 'New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.',\n",
       " 'We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.',\n",
       " 'Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.',\n",
       " 'The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.',\n",
       " 'However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.',\n",
       " 'Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].',\n",
       " 'Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.',\n",
       " 'In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.',\n",
       " 'Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.',\n",
       " 'VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.',\n",
       " 'For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].',\n",
       " 'Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.',\n",
       " 'Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.',\n",
       " 'KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.',\n",
       " 'However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].',\n",
       " 'Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.',\n",
       " 'However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.',\n",
       " 'By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.',\n",
       " 'In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.',\n",
       " '1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].',\n",
       " 'Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.',\n",
       " 'We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.',\n",
       " '2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.',\n",
       " 'This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.',\n",
       " 'This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.',\n",
       " 'In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.',\n",
       " 'The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.',\n",
       " 'The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.',\n",
       " ', a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.',\n",
       " 'htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Figure 1: A schematic diagram describing the vector database creation of a RAG application. improvement, and knowledge adaptation [ 28]. Here, we do not use knowledge adaptation and treat the KGs as static graphs.',\n",
       " 'Knowledge Extraction:- This step aims to extract structured in- formation from unstructured or semi-structured data, such as text, databases, and existing ontologies. The main tasks in this step are entity recognition, relationship extraction, and co-reference reso- lution. Entity recognition and relationship extraction techniques use typical NLP tasks to identify entities and their relationships from textual sources [ 29].',\n",
       " 'Coreference resolution identifies and connects different references of the same entity, keeping coherence within the knowledge graph. For example, if the text refers to a company as both \"the company\" and \"it\", coreference resolution can link these mentions to the same entity node in the graph. Knowledge Improvement:- This step aims to enhance the quality and completeness of the KG by removing redundancies and address- ing gaps in the extracted information.',\n",
       " 'The primary tasks in this step are KG completion and fusion. KG completion technique infers missing entities and relationships within the graph using meth- ods such as link prediction and entity resolution. Link prediction predicts the existence and type of a relation between two entities based on the graph structure and features, while entity resolution matches and merges different representations of the same entity from different sources.',\n",
       " 'Knowledge fusion combines information from multiple sources to create a coherent and unified KG. This involves resolving conflicts and redundancies among the sources, such as contradictory or duplicate facts, and aggregating or reconciling the information based on rules, probabilities, or semantic similarity. We utilized a robust methodology for creating KG triplets from unstructured text data, specifically focusing on corporate docu- ments such as earnings call transcripts, adapted from Ref.',\n",
       " '[ 18?]. This process involves several interconnected stages, each designed to extract, refine, and structure information effectively. We implement a two-tiered LLM chain for content refinement and information extraction. The first tier employs an LLM to gen- erate an abstract representation of each document chunk.',\n",
       " 'This refinement process is crucial as it distills the essential information while preserving the original meaning and key relationships be- tween concepts that serves as a more focused input for subsequent processing, enhancing the overall efficiency and accuracy of ourtriplet extraction pipeline. The second tier of our LLM chain is dedicated to entity extraction and relationship identification. Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM.',\n",
       " 'A detailed discussion on imple- mentation of the methodology will be provided in Section 4.1 2.3 GraphRAG KG based RAG [ 22], or GraphRAG, also begins with a query based on the user’s input same as VectorRAG. The main difference be- tween VectorRAG and GraphRAG lies in the retrieval part. The query here is now used to search the KG to retrieve relevant nodes (entities) and edges (relationships) related to the query.',\n",
       " 'A subgraph, which consists of these relevant nodes and edges, is extracted from the full KG to provide context. This subgraph is then integrated with the language model’s internal knowledge, by encoding the graph structure into embeddings that the model can interpret. The language model uses this combined context to generate responses that are informed by both the structured information from the KG and its pre-trained knowledge.',\n",
       " 'Crucially, when responding to user queries about a particular company, we leveraged the metadata information to selectively filter and retrieve only those document segments pertinent to the queried company [ 8]. This integration helps ensure that the generated outputs are accurate, contextually relevant, and grounded in verifiable information. A schematic diagram of the retrieval methodology of GraphRAG is given in Figure 2.',\n",
       " 'Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section 4.1 Figure 2: A schematic diagram describing knowledge graph creation process of GraphRAG. 2.3.1 HybridRAG. For the HybridRAG technique, we propose to integrate the aforementioned two distinct RAG techniques: Vec- torRAG and GraphRAG.',\n",
       " 'This integration involves a systematic combination of contextual information retrieved from both the traditional vector-based retrieval mechanism and the KG-based retrieval system, the latter of which was constructed specifically for this study. The amalgamation of these two contexts allows us to leverage the strengths of both approaches.',\n",
       " 'The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-richSarmah et al. contextual data. This combined context is then utilized as input for a LLM to generate the final responses. Details on the implementation of the HybridRAG will be provided in Section 4.4. 2.',\n",
       " '4 Evaluation Metrics To assess the efficacy of this integrated approach, we conducted a comparative analysis among the three approaches in a controlled ex- perimental set up: VectorRAG, GraphRAG and HybridRAG. The re- sponses generated using the combined VectorRAG and GraphRAG contexts were juxtaposed against those produced individually by VectorRAG and GraphRAG.',\n",
       " 'This comparative evaluation aimed to discern potential improvements in response quality, accuracy, and comprehensiveness that might arise from the synergistic integra- tion of these two RAG methodologies. To objectively evaluate different RAG approaches (VectorRAG and GraphRAG in their case), Ref. [ 22] utilized metrics such as comprehensiveness (i.e., the amount of details the answer provides to cover all aspects and details of the question?); diversity (i.e.',\n",
       " ', the richness of the answer in providing different perspectives and insights on the question); empowerment (i.e., the helpfulness of the answer to the reader understand and make informed judgements about the topic); and, directness (i.e., clearness of the answer in addressing the question). here, the LLM was provided tuples of question, target metric, and a pair of answers, and was asked to assess which answer was better according to the metric and why.',\n",
       " 'These metrics though compare the final generated answers, do not necessarily directly evaluate the retrieval and generation parts separately. Instead, here we implement a comprehensive set of evaluation metrics which are designed to capture different aspects of a given RAG system’s output quality, focusing on faithfulness, answer relevance, and context relevance [ 30]. Each metric provides unique insights into the system’s capabilities and limitations. 2.4.1 Faithfulness.',\n",
       " 'Faithfulness is a crucial metric that measures the extent to which the generated answer can be inferred from the provided context. Our implementation of the faithfulness metric involves a two-step process: Statement Extraction:- We use an LLM to decompose the gener- ated answer into a set of concise statements. This step is crucial for breaking down complex answers into more manageable and verifiable units.',\n",
       " 'The prompt used for this step is: \"Given a question and answer, create one or more statements from each sentence in the given answer. question: [question] an- swer: [answer]\". Statement Verification:- For each extracted statement, we employ the LLM to determine if it can be inferred from the given context.',\n",
       " 'This verification process uses the following prompt: \"Consider the given context and following statements, then de- termine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. statement: [statement 1] ... statement: [statement n]\".',\n",
       " 'The faithfulness score ( 𝐹) is𝐹=|𝑉|/|𝑆|, where |𝑉|is the number of supported statements and |𝑆|is the total number of statements.2.4.2 Answer Relevance:-. The answer relevance metric assesses how well the generated answer addresses the original question, irrespective of factual accuracy. This metric helps identify cases of incomplete answers or responses containing irrelevant information.',\n",
       " 'Our implementation involves the following steps: Question Generation: We prompt the LLM to generate n potential questions based on the given answer: \"Generate a question for the given answer. answer: [answer]\". Then, we obtain embeddings for all generated questions and the original question using OpenAI’s text-embedding-ada-002 model2. We then calculate the cosine similarity between each generated question’s embedding and the original question’s embedding.',\n",
       " 'Finally, the answer relevance score (AR) is computed as the aver- age similarity across all generated questions: 𝐴𝑅=1 𝑛Í(𝑠𝑖𝑚(𝑞,𝑞𝑖)), where𝑠𝑖𝑚(𝑞,𝑞𝑖)is the cosine similarity between the embedding of the original question 𝑞and the embeddings of each of the 𝑛 generated questions 𝑞𝑖. 2.4.3 Context Precision. It is a metric used to evaluate the relevance of retrieved context chunks in relation to a specified ground truth for a given question3.',\n",
       " 'It calculates the proportion of relevant items that appear in the top ranks of the context. The formula for context precision at K is the sum of the products of precision at each rank k and a binary relevance indicator v_k, divided by the total number of relevant items in the top K results. Precision at each rank k is determined by the ratio of true positives at k to the sum of true positives and false positives at k.',\n",
       " 'This metric helps in assessing how well the context supports the ground truth, aiming for higher scores which indicate better precision. 2.4.4 Context Recall. It is a metric used to evaluate how well the retrieved context aligns with the ground truth answer, which is considered the definitive correct response4. It is quantified by com- paring each sentence in the ground truth answer to see if it can be traced back to the retrieved context.',\n",
       " 'The formula for context recall is the ratio of the number of ground truth sentences that can be attributed to the context to the total number of sentences in the ground truth. Higher values, ranging from 0 to 1, indicate bet- ter alignment and thus better context recall. This metric is crucial for assessing the effectiveness of information retrieval systems in providing relevant context.',\n",
       " '3 DATA DESCRIPTION Although there do exist some public financial datasets, none of them were suitable for the present experiments: e.g., FinQA [ 31], TAT- QA [ 32], FIQA [ 33], FinanceBench [ 34], etc. datasets are limited to specific usecases such as benchmarking LLMs’ abilities to perform complex numerical reasoning or sentiment analysis. On the other hand, FinTextQA [ 35] dataset was not publicly available at the time of writing the present work.',\n",
       " 'In addition, in most of these datasets, access to the actual documents from which the ground- truth Q&As were created is not available, making it impossible to use them for our RAG techniques evaluation purposes. Hence, we resorted to a dataset of our own though through publicly available 2https://platform.openai.com/docs/guides/embeddings/embedding-models 3https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html 4https://docs.ragas.io/en/stable/concepts/metrics/context_recall.',\n",
       " 'htmlHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction documents but such that we finally have access to both the actual financial documents and the ground-truth Q&As. Datasets like FinanceBench5provides question-context-answer triplets but they are not useful as here we are comparing VectorRAG, GraphRAG and HybridRAG and they do not provide the context generated from a KG.',\n",
       " 'A recent paper [ 22] has not made the KG and triplets constructed by their algorithm public to the best of our knowledge either. In short, there is no publicly available benchmark dataset to compare VectorRAG and GraphRAG either for financial or general domains to the best of our knowledge. Hence, we had to rely on our own dataset constructed as explained below. We used transcripts from earnings calls of Nifty 50 constituents for our analysis.',\n",
       " 'The NIFTY 50 is popular index in the Indian stock market that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange (NSE). The dataset of the earning call documents of Nifty 50 companies is widely recognized in the investment realm and is esteemed as an authoritative and extensive collection of earnings call transcripts. In our investigation, we focus on data spanning the quarter ending in June, 2023 i.e.',\n",
       " 'the earnings reports for Q1 of the financial year 2024 (A financial year in India starts on the 1st April and ends in 31st March, so the quarter from 1st April to 30th June is the first quarter of 2024 for the Indian market).',\n",
       " 'Our dataset encompasses 50 transcripts for this quarter, span- ning over 50 companies within Nifty 50 universe from diverse range of sectors including Infrastructure, Healthcare, Consumer Durables, Banking, Automobile, Financial Services, Energy - Oil & Gas, Telecommunication, Consumer Goods, Pharmaceuticals, Energy - Coal, Materials, Information Technology, Construction, Diversified, Metals, Energy - Power and Chemicals providing a substantial and diverse foundation for our study.',\n",
       " 'We start the data collection process focused on acquiring earn- ings reports from company websites within the Nifty 50 universe by developing and deploying a custom web scraping tool to navigate through the websites of each company within the Nifty 50 index, systematically retrieving the pertinent earnings reports for Q1 of the financial year 2024. By utilizing this web scraping approach, we aimed to compile a comprehensive dataset encompassing the earnings reports of the constituent companies.',\n",
       " 'Table 1 summarizes basic statistics of the documents we will be experimenting with in the remainder of this work. Number of companies/documents 50 Average number of pages 27 Average number of questions 16 Average number of tokens 60,000 Table 1: Summary Statistics for the call transcript documents used in the present work.',\n",
       " 'These call transcripts documents consist of questions and an- swers between financial analysts and the company representatives for the respective companies, hence, there already exist certain Q&A pairs within these documents along with additional text. We examined the earnings reports within the Nifty50 universe, system- atically curated a comprehensive array of randomly selected 400 5https://huggingface.',\n",
       " 'co/datasets/PatronusAI/financebench-testquestions posed during the earnings calls from all the documents, and gathered the exact responses corresponding to these questions. These questions constitute the specific queries articulated by finan- cial analysts to the management during these calls. 4 IMPLEMENTATION DETAILS In this Section, we provide details of implementation of the pro- posed methodology. 4.',\n",
       " '1 Knowledge Graph Construction The initial phase of our approach centers on document preprocess- ing. We utilize the PyPDFLoader6to import PDF documents, which are subsequently segmented into manageable chunks using the RecursiveCharacterTextSplitter. This chunking strategy employs a size of 2024 characters with an overlap of 204 characters, ensuring comprehensive coverage while maintaining context across segment boundaries.',\n",
       " 'Following the preprocessing stage, we implement the two-tiered language model chain for content refinement and information ex- traction. It is not possible to include the exact prompt here due to the limited space, but a baseline prompt can be found in Ref. [18].',\n",
       " 'Entity Type Examples Companies and Corpo- rationsOfficial names, abbreviations, infor- mal references Financial Metrics and IndicatorsRevenue, profit margins, EBITDA Corporate Executives and Key PersonnelCEOs, CFOs, board members Products and Services Tangible products and intangible ser- vices Geographical Locations Headquarters, operational regions, markets Corporate Events Mergers, acquisitions, product launches, earnings calls Legal and Regulatory InformationLegal cases, regulatory compliance Table 2: Entities extracted from earnings call transcripts Table 2 summarizes details on entities extracted from the earn- ing calls transcripts using our prompt based method.',\n",
       " 'Concurrently, LLM identifies relationships between these entities using a curated set of verbs, capturing the nuanced interactions within the cor- porate narrative. A key improvement in our methodology is the enhanced prompt engineering to generate the structured output format for knowledge triplets.',\n",
       " 'Each triplet is represented as a nested list [’h’, ’type’, ’r’, ’o’, ’type’, ’metadata’], where ’h’ and ’o’ denote the head and object entities respectively, ’type’ specifies the entity category, ’r’ represents the relationship, and ’metadata’ encapsu- lates additional contextual information. This format allows for a rich, multidimensional representation of information, facilitating more nuanced downstream analysis. 6https://python.langchain.com/v0.',\n",
       " '1/docs/modules/data_connection/document_ loaders/pdf/Sarmah et al. Our process incorporates several advanced features to enhance the quality and utility of the extracted triplets. Entity disambigua- tion techniques are employed to consolidate different references to the same entity, improving consistency across the KG.',\n",
       " 'We also pri- oritize conciseness in entity representation, aiming for descriptions of less than four words where possible, which aids in maintaining a clean and navigable graph structure. The extraction pipeline is applied iteratively to each document chunk, with results aggregated to form a comprehensive knowledge graph representation of the entire document, allowing for scalable processing of large documents while maintaining local context within each chunk.',\n",
       " 'We have added explicit instruction on obtaining metadata following Ref. [8] for both VectorRAG and GraphRAG. Finally, we implement a data persistence strategy, converting the extracted triplets from their initial string format to Python data structures and storing them in a pickle file. This facilitates easy retrieval and further manipulation of the knowledge graph data in subsequent analysis stages.',\n",
       " 'Our methodology represents a significant advancement in auto- mated knowledge extraction from corporate documents. By com- bining advanced NLP techniques with a structured approach to information representation, we create a rich, queryable knowledge base that captures the complex relationships and key information present in corporate narratives.',\n",
       " 'This approach opens up new pos- sibilities for financial analysis and automated reasoning in the business domain that will be explored further in the future. 4.2 VectorRAG Our methodology builds upon the concept of RAG [ 9] which al- lows for the creation of a system that can provide context-aware, accurate responses to queries about company financial informa- tion, leveraging both the power of large language models and the efficiency of semantic search.',\n",
       " 'At the core of our system is a Pinecone vector database7, which serves as the foundation for our information retrieval process. We employ OpenAI’s text-embedding-ada-002 model to transform tex- tual data from earnings call transcripts into high-dimensional vec- tor representations. This vectorization process enables semantic similarity searches, significantly enhancing the relevance and ac- curacy of retrieved information.',\n",
       " 'Table 3 provides summary of the configuration of the set up in use for our experiments. LLM GPT-3.5-Turbo LLM Temperature 0 Embedding Model text-embedding-ada-002 Framework LangChain Vector Database Pinecone Chunk Size 1024 Chunk Overlap 0 Maximum Output Tokens 1024 Chunks for Similarity Algorithm 20 Number of Context Retrieved 4 Table 3: VectorRAG Configuration 7https://www.pinecone.io/The Q&A pipeline is constructed using the LangChain frame- work8.',\n",
       " 'The begins with a context retrieval step, where we query the Pinecone vector store to obtain the most relevant document chunks for a given question. This retrieval process is fine-tuned with spe- cific filters for quarters, years, and company names, ensuring that the retrieved information is both relevant and current. Following retrieval, we implement a context formatting step that consolidates the retrieved document chunks into a coherent context string.',\n",
       " 'This formatted context serves as the informational basis for the language model’s response generation. We have developed a sophisticated prompt template, that instructs the language model to function as an expert Q&A system, emphasizing the importance of utilizing only the provided context information and avoiding direct references to the context in the generated responses. For the core language processing task, we integrate OpenAI’s GPT-3.',\n",
       " '5-turbo model which processes the formatted context and query to generate natural language responses that are informative, coherent, and contextually appropriate. To evaluate the performance of our system, we developed a comprehensive framework that includes the preparation of a cus- tom dataset of question-answer pairs specific to each company’s earnings call. Our system processes each question in this dataset, generating answers based on the retrieved context.',\n",
       " 'The evaluation results, including the original question, generated answer, retrieved contexts, and ground truth, are compiled into structured formats (CSV and JSON) to facilitate further analysis. The outputs generated by our system are stored in both CSV and JSON formats, enabling easy integration with various analysis tools and dashboards.',\n",
       " 'This approach facilitates both quantitative performance metrics and qualitative assessment of the system’s responses, providing a com- prehensive view of its effectiveness. By parameterizing company names, quarters, and years, we can easily adapt the system to different datasets and time periods. This design choice allows for seamless integration of new data and expansion to cover multiple companies and earnings calls. 4.',\n",
       " '3 GraphRAG For GraphRAG, we developed an Q&A system specifically designed for corporate earnings call transcripts. Our implementation of GraphRAG leverages several key components and techniques: LLM GPT-3.5-Turbo LLM Temperature 0 Framework LangChain KG Manipulation Networkx Chunk Size 1024 Chunk Overlap 0 Number of Triplets 13950 Number of nodes 11405 Number of edges 13883 DFS Depth 1 Table 4: GraphRAG Configuration 8https://docs.smith.langchain.',\n",
       " 'com/old/cookbook/hub-examples/retrieval-qa-chainHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc.',\n",
       " 'New York, NY, USADhagash Mehta dhagash.mehta@blackrock.com BlackRock, Inc.',\n",
       " 'New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.',\n",
       " 'We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.',\n",
       " 'Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.',\n",
       " 'The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.',\n",
       " 'However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.',\n",
       " 'Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].',\n",
       " 'Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.',\n",
       " 'In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.',\n",
       " 'Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.',\n",
       " 'VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.',\n",
       " 'For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].',\n",
       " 'Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.',\n",
       " 'Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.',\n",
       " 'KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.',\n",
       " 'However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].',\n",
       " 'Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.',\n",
       " 'However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.',\n",
       " 'By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.',\n",
       " 'In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.',\n",
       " '1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].',\n",
       " 'Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.',\n",
       " 'We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.',\n",
       " '2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.',\n",
       " 'This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.',\n",
       " 'This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.',\n",
       " 'In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.',\n",
       " 'The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.',\n",
       " 'The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.',\n",
       " ', a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.',\n",
       " 'htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Figure 1: A schematic diagram describing the vector database creation of a RAG application. improvement, and knowledge adaptation [ 28]. Here, we do not use knowledge adaptation and treat the KGs as static graphs.',\n",
       " 'Knowledge Extraction:- This step aims to extract structured in- formation from unstructured or semi-structured data, such as text, databases, and existing ontologies. The main tasks in this step are entity recognition, relationship extraction, and co-reference reso- lution. Entity recognition and relationship extraction techniques use typical NLP tasks to identify entities and their relationships from textual sources [ 29].',\n",
       " 'Coreference resolution identifies and connects different references of the same entity, keeping coherence within the knowledge graph. For example, if the text refers to a company as both \"the company\" and \"it\", coreference resolution can link these mentions to the same entity node in the graph. Knowledge Improvement:- This step aims to enhance the quality and completeness of the KG by removing redundancies and address- ing gaps in the extracted information.',\n",
       " 'The primary tasks in this step are KG completion and fusion. KG completion technique infers missing entities and relationships within the graph using meth- ods such as link prediction and entity resolution. Link prediction predicts the existence and type of a relation between two entities based on the graph structure and features, while entity resolution matches and merges different representations of the same entity from different sources.',\n",
       " 'Knowledge fusion combines information from multiple sources to create a coherent and unified KG. This involves resolving conflicts and redundancies among the sources, such as contradictory or duplicate facts, and aggregating or reconciling the information based on rules, probabilities, or semantic similarity. We utilized a robust methodology for creating KG triplets from unstructured text data, specifically focusing on corporate docu- ments such as earnings call transcripts, adapted from Ref.',\n",
       " '[ 18?]. This process involves several interconnected stages, each designed to extract, refine, and structure information effectively. We implement a two-tiered LLM chain for content refinement and information extraction. The first tier employs an LLM to gen- erate an abstract representation of each document chunk.',\n",
       " 'This refinement process is crucial as it distills the essential information while preserving the original meaning and key relationships be- tween concepts that serves as a more focused input for subsequent processing, enhancing the overall efficiency and accuracy of ourtriplet extraction pipeline. The second tier of our LLM chain is dedicated to entity extraction and relationship identification. Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM.',\n",
       " 'A detailed discussion on imple- mentation of the methodology will be provided in Section 4.1 2.3 GraphRAG KG based RAG [ 22], or GraphRAG, also begins with a query based on the user’s input same as VectorRAG. The main difference be- tween VectorRAG and GraphRAG lies in the retrieval part. The query here is now used to search the KG to retrieve relevant nodes (entities) and edges (relationships) related to the query.',\n",
       " 'A subgraph, which consists of these relevant nodes and edges, is extracted from the full KG to provide context. This subgraph is then integrated with the language model’s internal knowledge, by encoding the graph structure into embeddings that the model can interpret. The language model uses this combined context to generate responses that are informed by both the structured information from the KG and its pre-trained knowledge.',\n",
       " 'Crucially, when responding to user queries about a particular company, we leveraged the metadata information to selectively filter and retrieve only those document segments pertinent to the queried company [ 8]. This integration helps ensure that the generated outputs are accurate, contextually relevant, and grounded in verifiable information. A schematic diagram of the retrieval methodology of GraphRAG is given in Figure 2.',\n",
       " 'Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section 4.1 Figure 2: A schematic diagram describing knowledge graph creation process of GraphRAG. 2.3.1 HybridRAG. For the HybridRAG technique, we propose to integrate the aforementioned two distinct RAG techniques: Vec- torRAG and GraphRAG.',\n",
       " 'This integration involves a systematic combination of contextual information retrieved from both the traditional vector-based retrieval mechanism and the KG-based retrieval system, the latter of which was constructed specifically for this study. The amalgamation of these two contexts allows us to leverage the strengths of both approaches.',\n",
       " 'The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-richSarmah et al. contextual data. This combined context is then utilized as input for a LLM to generate the final responses. Details on the implementation of the HybridRAG will be provided in Section 4.4. 2.',\n",
       " '4 Evaluation Metrics To assess the efficacy of this integrated approach, we conducted a comparative analysis among the three approaches in a controlled ex- perimental set up: VectorRAG, GraphRAG and HybridRAG. The re- sponses generated using the combined VectorRAG and GraphRAG contexts were juxtaposed against those produced individually by VectorRAG and GraphRAG.',\n",
       " 'This comparative evaluation aimed to discern potential improvements in response quality, accuracy, and comprehensiveness that might arise from the synergistic integra- tion of these two RAG methodologies. To objectively evaluate different RAG approaches (VectorRAG and GraphRAG in their case), Ref. [ 22] utilized metrics such as comprehensiveness (i.e., the amount of details the answer provides to cover all aspects and details of the question?); diversity (i.e.',\n",
       " ', the richness of the answer in providing different perspectives and insights on the question); empowerment (i.e., the helpfulness of the answer to the reader understand and make informed judgements about the topic); and, directness (i.e., clearness of the answer in addressing the question). here, the LLM was provided tuples of question, target metric, and a pair of answers, and was asked to assess which answer was better according to the metric and why.',\n",
       " 'These metrics though compare the final generated answers, do not necessarily directly evaluate the retrieval and generation parts separately. Instead, here we implement a comprehensive set of evaluation metrics which are designed to capture different aspects of a given RAG system’s output quality, focusing on faithfulness, answer relevance, and context relevance [ 30]. Each metric provides unique insights into the system’s capabilities and limitations. 2.4.1 Faithfulness.',\n",
       " 'Faithfulness is a crucial metric that measures the extent to which the generated answer can be inferred from the provided context. Our implementation of the faithfulness metric involves a two-step process: Statement Extraction:- We use an LLM to decompose the gener- ated answer into a set of concise statements. This step is crucial for breaking down complex answers into more manageable and verifiable units.',\n",
       " 'The prompt used for this step is: \"Given a question and answer, create one or more statements from each sentence in the given answer. question: [question] an- swer: [answer]\". Statement Verification:- For each extracted statement, we employ the LLM to determine if it can be inferred from the given context.',\n",
       " 'This verification process uses the following prompt: \"Consider the given context and following statements, then de- termine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. statement: [statement 1] ... statement: [statement n]\".',\n",
       " 'The faithfulness score ( 𝐹) is𝐹=|𝑉|/|𝑆|, where |𝑉|is the number of supported statements and |𝑆|is the total number of statements.2.4.2 Answer Relevance:-. The answer relevance metric assesses how well the generated answer addresses the original question, irrespective of factual accuracy. This metric helps identify cases of incomplete answers or responses containing irrelevant information.',\n",
       " 'Our implementation involves the following steps: Question Generation: We prompt the LLM to generate n potential questions based on the given answer: \"Generate a question for the given answer. answer: [answer]\". Then, we obtain embeddings for all generated questions and the original question using OpenAI’s text-embedding-ada-002 model2. We then calculate the cosine similarity between each generated question’s embedding and the original question’s embedding.',\n",
       " 'Finally, the answer relevance score (AR) is computed as the aver- age similarity across all generated questions: 𝐴𝑅=1 𝑛Í(𝑠𝑖𝑚(𝑞,𝑞𝑖)), where𝑠𝑖𝑚(𝑞,𝑞𝑖)is the cosine similarity between the embedding of the original question 𝑞and the embeddings of each of the 𝑛 generated questions 𝑞𝑖. 2.4.3 Context Precision. It is a metric used to evaluate the relevance of retrieved context chunks in relation to a specified ground truth for a given question3.',\n",
       " 'It calculates the proportion of relevant items that appear in the top ranks of the context. The formula for context precision at K is the sum of the products of precision at each rank k and a binary relevance indicator v_k, divided by the total number of relevant items in the top K results. Precision at each rank k is determined by the ratio of true positives at k to the sum of true positives and false positives at k.',\n",
       " 'This metric helps in assessing how well the context supports the ground truth, aiming for higher scores which indicate better precision. 2.4.4 Context Recall. It is a metric used to evaluate how well the retrieved context aligns with the ground truth answer, which is considered the definitive correct response4. It is quantified by com- paring each sentence in the ground truth answer to see if it can be traced back to the retrieved context.',\n",
       " 'The formula for context recall is the ratio of the number of ground truth sentences that can be attributed to the context to the total number of sentences in the ground truth. Higher values, ranging from 0 to 1, indicate bet- ter alignment and thus better context recall. This metric is crucial for assessing the effectiveness of information retrieval systems in providing relevant context.',\n",
       " '3 DATA DESCRIPTION Although there do exist some public financial datasets, none of them were suitable for the present experiments: e.g., FinQA [ 31], TAT- QA [ 32], FIQA [ 33], FinanceBench [ 34], etc. datasets are limited to specific usecases such as benchmarking LLMs’ abilities to perform complex numerical reasoning or sentiment analysis. On the other hand, FinTextQA [ 35] dataset was not publicly available at the time of writing the present work.',\n",
       " 'In addition, in most of these datasets, access to the actual documents from which the ground- truth Q&As were created is not available, making it impossible to use them for our RAG techniques evaluation purposes. Hence, we resorted to a dataset of our own though through publicly available 2https://platform.openai.com/docs/guides/embeddings/embedding-models 3https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html 4https://docs.ragas.io/en/stable/concepts/metrics/context_recall.',\n",
       " 'htmlHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction documents but such that we finally have access to both the actual financial documents and the ground-truth Q&As. Datasets like FinanceBench5provides question-context-answer triplets but they are not useful as here we are comparing VectorRAG, GraphRAG and HybridRAG and they do not provide the context generated from a KG.',\n",
       " 'A recent paper [ 22] has not made the KG and triplets constructed by their algorithm public to the best of our knowledge either. In short, there is no publicly available benchmark dataset to compare VectorRAG and GraphRAG either for financial or general domains to the best of our knowledge. Hence, we had to rely on our own dataset constructed as explained below. We used transcripts from earnings calls of Nifty 50 constituents for our analysis.',\n",
       " 'The NIFTY 50 is popular index in the Indian stock market that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange (NSE). The dataset of the earning call documents of Nifty 50 companies is widely recognized in the investment realm and is esteemed as an authoritative and extensive collection of earnings call transcripts. In our investigation, we focus on data spanning the quarter ending in June, 2023 i.e.',\n",
       " 'the earnings reports for Q1 of the financial year 2024 (A financial year in India starts on the 1st April and ends in 31st March, so the quarter from 1st April to 30th June is the first quarter of 2024 for the Indian market).',\n",
       " 'Our dataset encompasses 50 transcripts for this quarter, span- ning over 50 companies within Nifty 50 universe from diverse range of sectors including Infrastructure, Healthcare, Consumer Durables, Banking, Automobile, Financial Services, Energy - Oil & Gas, Telecommunication, Consumer Goods, Pharmaceuticals, Energy - Coal, Materials, Information Technology, Construction, Diversified, Metals, Energy - Power and Chemicals providing a substantial and diverse foundation for our study.',\n",
       " 'We start the data collection process focused on acquiring earn- ings reports from company websites within the Nifty 50 universe by developing and deploying a custom web scraping tool to navigate through the websites of each company within the Nifty 50 index, systematically retrieving the pertinent earnings reports for Q1 of the financial year 2024. By utilizing this web scraping approach, we aimed to compile a comprehensive dataset encompassing the earnings reports of the constituent companies.',\n",
       " 'Table 1 summarizes basic statistics of the documents we will be experimenting with in the remainder of this work. Number of companies/documents 50 Average number of pages 27 Average number of questions 16 Average number of tokens 60,000 Table 1: Summary Statistics for the call transcript documents used in the present work.',\n",
       " 'These call transcripts documents consist of questions and an- swers between financial analysts and the company representatives for the respective companies, hence, there already exist certain Q&A pairs within these documents along with additional text. We examined the earnings reports within the Nifty50 universe, system- atically curated a comprehensive array of randomly selected 400 5https://huggingface.',\n",
       " 'co/datasets/PatronusAI/financebench-testquestions posed during the earnings calls from all the documents, and gathered the exact responses corresponding to these questions. These questions constitute the specific queries articulated by finan- cial analysts to the management during these calls. 4 IMPLEMENTATION DETAILS In this Section, we provide details of implementation of the pro- posed methodology. 4.',\n",
       " '1 Knowledge Graph Construction The initial phase of our approach centers on document preprocess- ing. We utilize the PyPDFLoader6to import PDF documents, which are subsequently segmented into manageable chunks using the RecursiveCharacterTextSplitter. This chunking strategy employs a size of 2024 characters with an overlap of 204 characters, ensuring comprehensive coverage while maintaining context across segment boundaries.',\n",
       " 'Following the preprocessing stage, we implement the two-tiered language model chain for content refinement and information ex- traction. It is not possible to include the exact prompt here due to the limited space, but a baseline prompt can be found in Ref. [18].',\n",
       " 'Entity Type Examples Companies and Corpo- rationsOfficial names, abbreviations, infor- mal references Financial Metrics and IndicatorsRevenue, profit margins, EBITDA Corporate Executives and Key PersonnelCEOs, CFOs, board members Products and Services Tangible products and intangible ser- vices Geographical Locations Headquarters, operational regions, markets Corporate Events Mergers, acquisitions, product launches, earnings calls Legal and Regulatory InformationLegal cases, regulatory compliance Table 2: Entities extracted from earnings call transcripts Table 2 summarizes details on entities extracted from the earn- ing calls transcripts using our prompt based method.',\n",
       " 'Concurrently, LLM identifies relationships between these entities using a curated set of verbs, capturing the nuanced interactions within the cor- porate narrative. A key improvement in our methodology is the enhanced prompt engineering to generate the structured output format for knowledge triplets.',\n",
       " 'Each triplet is represented as a nested list [’h’, ’type’, ’r’, ’o’, ’type’, ’metadata’], where ’h’ and ’o’ denote the head and object entities respectively, ’type’ specifies the entity category, ’r’ represents the relationship, and ’metadata’ encapsu- lates additional contextual information. This format allows for a rich, multidimensional representation of information, facilitating more nuanced downstream analysis. 6https://python.langchain.com/v0.',\n",
       " '1/docs/modules/data_connection/document_ loaders/pdf/Sarmah et al. Our process incorporates several advanced features to enhance the quality and utility of the extracted triplets. Entity disambigua- tion techniques are employed to consolidate different references to the same entity, improving consistency across the KG.',\n",
       " 'We also pri- oritize conciseness in entity representation, aiming for descriptions of less than four words where possible, which aids in maintaining a clean and navigable graph structure. The extraction pipeline is applied iteratively to each document chunk, with results aggregated to form a comprehensive knowledge graph representation of the entire document, allowing for scalable processing of large documents while maintaining local context within each chunk.',\n",
       " 'We have added explicit instruction on obtaining metadata following Ref. [8] for both VectorRAG and GraphRAG. Finally, we implement a data persistence strategy, converting the extracted triplets from their initial string format to Python data structures and storing them in a pickle file. This facilitates easy retrieval and further manipulation of the knowledge graph data in subsequent analysis stages.',\n",
       " 'Our methodology represents a significant advancement in auto- mated knowledge extraction from corporate documents. By com- bining advanced NLP techniques with a structured approach to information representation, we create a rich, queryable knowledge base that captures the complex relationships and key information present in corporate narratives.',\n",
       " 'This approach opens up new pos- sibilities for financial analysis and automated reasoning in the business domain that will be explored further in the future. 4.2 VectorRAG Our methodology builds upon the concept of RAG [ 9] which al- lows for the creation of a system that can provide context-aware, accurate responses to queries about company financial informa- tion, leveraging both the power of large language models and the efficiency of semantic search.',\n",
       " 'At the core of our system is a Pinecone vector database7, which serves as the foundation for our information retrieval process. We employ OpenAI’s text-embedding-ada-002 model to transform tex- tual data from earnings call transcripts into high-dimensional vec- tor representations. This vectorization process enables semantic similarity searches, significantly enhancing the relevance and ac- curacy of retrieved information.',\n",
       " 'Table 3 provides summary of the configuration of the set up in use for our experiments. LLM GPT-3.5-Turbo LLM Temperature 0 Embedding Model text-embedding-ada-002 Framework LangChain Vector Database Pinecone Chunk Size 1024 Chunk Overlap 0 Maximum Output Tokens 1024 Chunks for Similarity Algorithm 20 Number of Context Retrieved 4 Table 3: VectorRAG Configuration 7https://www.pinecone.io/The Q&A pipeline is constructed using the LangChain frame- work8.',\n",
       " 'The begins with a context retrieval step, where we query the Pinecone vector store to obtain the most relevant document chunks for a given question. This retrieval process is fine-tuned with spe- cific filters for quarters, years, and company names, ensuring that the retrieved information is both relevant and current. Following retrieval, we implement a context formatting step that consolidates the retrieved document chunks into a coherent context string.',\n",
       " 'This formatted context serves as the informational basis for the language model’s response generation. We have developed a sophisticated prompt template, that instructs the language model to function as an expert Q&A system, emphasizing the importance of utilizing only the provided context information and avoiding direct references to the context in the generated responses. For the core language processing task, we integrate OpenAI’s GPT-3.',\n",
       " '5-turbo model which processes the formatted context and query to generate natural language responses that are informative, coherent, and contextually appropriate. To evaluate the performance of our system, we developed a comprehensive framework that includes the preparation of a cus- tom dataset of question-answer pairs specific to each company’s earnings call. Our system processes each question in this dataset, generating answers based on the retrieved context.',\n",
       " 'The evaluation results, including the original question, generated answer, retrieved contexts, and ground truth, are compiled into structured formats (CSV and JSON) to facilitate further analysis. The outputs generated by our system are stored in both CSV and JSON formats, enabling easy integration with various analysis tools and dashboards.',\n",
       " 'This approach facilitates both quantitative performance metrics and qualitative assessment of the system’s responses, providing a com- prehensive view of its effectiveness. By parameterizing company names, quarters, and years, we can easily adapt the system to different datasets and time periods. This design choice allows for seamless integration of new data and expansion to cover multiple companies and earnings calls. 4.',\n",
       " '3 GraphRAG For GraphRAG, we developed an Q&A system specifically designed for corporate earnings call transcripts. Our implementation of GraphRAG leverages several key components and techniques: LLM GPT-3.5-Turbo LLM Temperature 0 Framework LangChain KG Manipulation Networkx Chunk Size 1024 Chunk Overlap 0 Number of Triplets 13950 Number of nodes 11405 Number of edges 13883 DFS Depth 1 Table 4: GraphRAG Configuration 8https://docs.smith.langchain.',\n",
       " 'com/old/cookbook/hub-examples/retrieval-qa-chainHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Knowledge Graph Construction:- We begin by constructing a KG from a set of knowledge triplets extracted from corporate documents using the prompt engineering based methodology as described in Section 4.1.',\n",
       " 'These triplets, stored in a pickle file, repre- sent structured information in the form of subject-predicate-object relationships. We use the NetworkxEntityGraph class from the LangChain library to create and manage this graph structure. Each triple is added to the graph, which encapsulates the head entity, relation, tail entity, and additional metadata. We implement the Q&A functionality using the GraphQAChain class from LangChain.',\n",
       " 'This chain combines the KG with an LLM (in our case, OpenAI’s GPT-3.5-turbo) to generate responses. The GraphQAChain traverses the KG to find relevant information and uses the language model to formulate coherent answers based on the retrieved context. A summary of configuration of our LLM models and other libraries used for GraphRAG is shown in Table 4.',\n",
       " 'In KG as the information is stored in the form of entities and relationships and there can be multiple relations emanating from one single entity, in this experiment, to extract relevant information from the KG, we employ a depth-first search strategy constrained by a depth of one from the specified entity.',\n",
       " 'To prepare for assessing the performance of our GraphRAG system, we follow the below steps: Dataset Preparation:- We use a pre-generated CSV file containing question-answer pairs specific to the earnings call transcript. Iterative Processing:- For each question in the dataset, we run the GraphQAChain to generate an answer. Result Compilation:- We compile the results, including the origi- nal questions, generated answers, retrieved contexts, and ground truth answers, into a structured format.',\n",
       " 'Finally, the evaluation results are saved in both CSV and JSON formats for further analysis and comparison. We then fed these outputs into our RAG evaluation pipeline. For each Q&A pair in our dataset, we compute all three metrics: faithfulness, answer relevance, context precision and context recall. 4.',\n",
       " '4 HybridRAG For the proposed HybridRAG technique, upon obtaining all the contextual information from VectorRAG and GraphRAG, we con- catenate these contexts to form a unified context utilizing both techniques. This combined context is then fed into the answer gen- erator model to produce a response. The context used for response generation is relatively larger, which affects the precision of the generated response.',\n",
       " 'The context from VectorRAG is appended first, followed by the context from GraphRAG. Consequently, the preci- sion of the generated answer depends on the source context. If the answer is generated from the GraphRAG context, it will have lower precision, as the GraphRAG context is added last in the sequence of contexts provided to the answer generator model, and vice versa. 5 RESULTS We evaluate both the retrieval and generation parts of RAG for the three different RAG pipelines.',\n",
       " 'Evaluating the RAG outputs is also an active area of research there is no standard tool which is universally accepted as of yet, though we use a currently popular framework RAGAS[ 30] to evaluate the three RAG pipelines in thepresent work where we have modified them a bit to make more precise comparisons. The results of our comparative analysis reveal notable differences in performance among VectorRAG, GraphRAG, and HybridRAG approaches as summarized in Table 5.',\n",
       " 'In terms of Faithfulness, GraphRAG and HybridRAG demonstrated superior performance, both achieving a score of 0.96, while VectorRAG trailed slightly with a score of 0.94. Answer relevancy scores varied across the meth- ods, with HybridRAG outperforming the others at 0.96, followed by VectorRAG at 0.91, and GraphRAG at 0.89. Context precision was highest for GraphRAG at 0.96, significantly surpassing Vec- torRAG (0.84) and HybridRAG (0.79).',\n",
       " 'However, in context recall, both VectorRAG and HybridRAG achieved perfect scores of 1, while GraphRAG lagged behind at 0.85. Overall, these results suggest that GraphRAG offers improve- ments over VectorRAG, particularly in faithfulness and context pre- cision. Furthermore, HybridRAG emerges as the most balanced and effective approach, outperforming both VectorRAG and GraphRAG in key metrics such as faithfulness and answer relevancy, while maintaining high context recall.',\n",
       " 'The relatively lower context precision observed for HybridRAG (0.79) can be attributed to its unique approach of combining con- texts from both VectorRAG and GraphRAG methods. While this integration allows for more comprehensive information retrieval, it also introduces additional content that may not align precisely with the ground truth, thus affecting the context precision met- ric.',\n",
       " 'Despite this trade-off, HybridRAG’s superior performance in faithfulness, answer relevancy, and context recall underscores its effectiveness. When considering the overall evaluation metrics, HybridRAG emerges as the most promising approach, balancing high-quality answers with comprehensive context retrieval. Overall GraphRAG performs better in extractive questions com- pared to VectorRAG.',\n",
       " 'And VectorRAG does better in abstractive questions where information is not explicitly mentioned in the raw data. And also GraphRAG sometimes fails to answer ques- tions correctly whenever there is no entity explicitly mentioned in the question. So HybridRAG does a good job overall, as whenever VectorRAG fails to fetch correct context in extractive questions it falls back to GraphRAG to generate the answer.',\n",
       " 'And whenever GraphRAG fails to fetch correct context in abstractive questions it falls back to VectorRAG to generate the answer. VectorRAG GraphRAG HybridRAG F 0.94 0.96 0.96 AR 0.91 0.89 0.96 CP 0.84 0.96 0.79 CR 1 0.85 1 Table 5: Performance Metrics for Different RAG Pipelines. Here, F, AR, CP and CR refer to Faithfulness, Answer Relevence, Context Precision and Context Recall.',\n",
       " '6 CONCLUSION AND FUTURE DIRECTIONS Among the current approaches to mitigate issues regarding infor- mation extraction from external documents that were not part ofHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.',\n",
       " 'com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc. New York, NY, USADhagash Mehta dhagash.mehta@blackrock.com BlackRock, Inc.',\n",
       " 'New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.',\n",
       " 'We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.',\n",
       " 'Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.',\n",
       " 'The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.',\n",
       " 'However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.',\n",
       " 'Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].',\n",
       " 'Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.',\n",
       " 'In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.',\n",
       " 'Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.',\n",
       " 'VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.',\n",
       " 'For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].',\n",
       " 'Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.',\n",
       " 'Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.',\n",
       " 'KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.',\n",
       " 'However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].',\n",
       " 'Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.',\n",
       " 'However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.',\n",
       " 'By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.',\n",
       " 'In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.',\n",
       " '1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].',\n",
       " 'Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.',\n",
       " 'We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.',\n",
       " '2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.',\n",
       " 'This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.',\n",
       " 'This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.',\n",
       " 'In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.',\n",
       " 'The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.',\n",
       " 'The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.',\n",
       " ', a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.',\n",
       " 'htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Figure 1: A schematic diagram describing the vector database creation of a RAG application. improvement, and knowledge adaptation [ 28]. Here, we do not use knowledge adaptation and treat the KGs as static graphs.',\n",
       " 'Knowledge Extraction:- This step aims to extract structured in- formation from unstructured or semi-structured data, such as text, databases, and existing ontologies. The main tasks in this step are entity recognition, relationship extraction, and co-reference reso- lution. Entity recognition and relationship extraction techniques use typical NLP tasks to identify entities and their relationships from textual sources [ 29].',\n",
       " 'Coreference resolution identifies and connects different references of the same entity, keeping coherence within the knowledge graph. For example, if the text refers to a company as both \"the company\" and \"it\", coreference resolution can link these mentions to the same entity node in the graph. Knowledge Improvement:- This step aims to enhance the quality and completeness of the KG by removing redundancies and address- ing gaps in the extracted information.',\n",
       " 'The primary tasks in this step are KG completion and fusion. KG completion technique infers missing entities and relationships within the graph using meth- ods such as link prediction and entity resolution. Link prediction predicts the existence and type of a relation between two entities based on the graph structure and features, while entity resolution matches and merges different representations of the same entity from different sources.',\n",
       " 'Knowledge fusion combines information from multiple sources to create a coherent and unified KG. This involves resolving conflicts and redundancies among the sources, such as contradictory or duplicate facts, and aggregating or reconciling the information based on rules, probabilities, or semantic similarity. We utilized a robust methodology for creating KG triplets from unstructured text data, specifically focusing on corporate docu- ments such as earnings call transcripts, adapted from Ref.',\n",
       " '[ 18?]. This process involves several interconnected stages, each designed to extract, refine, and structure information effectively. We implement a two-tiered LLM chain for content refinement and information extraction. The first tier employs an LLM to gen- erate an abstract representation of each document chunk.',\n",
       " 'This refinement process is crucial as it distills the essential information while preserving the original meaning and key relationships be- tween concepts that serves as a more focused input for subsequent processing, enhancing the overall efficiency and accuracy of ourtriplet extraction pipeline. The second tier of our LLM chain is dedicated to entity extraction and relationship identification. Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM.',\n",
       " 'A detailed discussion on imple- mentation of the methodology will be provided in Section 4.1 2.3 GraphRAG KG based RAG [ 22], or GraphRAG, also begins with a query based on the user’s input same as VectorRAG. The main difference be- tween VectorRAG and GraphRAG lies in the retrieval part. The query here is now used to search the KG to retrieve relevant nodes (entities) and edges (relationships) related to the query.',\n",
       " 'A subgraph, which consists of these relevant nodes and edges, is extracted from the full KG to provide context. This subgraph is then integrated with the language model’s internal knowledge, by encoding the graph structure into embeddings that the model can interpret. The language model uses this combined context to generate responses that are informed by both the structured information from the KG and its pre-trained knowledge.',\n",
       " 'Crucially, when responding to user queries about a particular company, we leveraged the metadata information to selectively filter and retrieve only those document segments pertinent to the queried company [ 8]. This integration helps ensure that the generated outputs are accurate, contextually relevant, and grounded in verifiable information. A schematic diagram of the retrieval methodology of GraphRAG is given in Figure 2.',\n",
       " 'Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section 4.1 Figure 2: A schematic diagram describing knowledge graph creation process of GraphRAG. 2.3.1 HybridRAG. For the HybridRAG technique, we propose to integrate the aforementioned two distinct RAG techniques: Vec- torRAG and GraphRAG.',\n",
       " 'This integration involves a systematic combination of contextual information retrieved from both the traditional vector-based retrieval mechanism and the KG-based retrieval system, the latter of which was constructed specifically for this study. The amalgamation of these two contexts allows us to leverage the strengths of both approaches.',\n",
       " 'The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-richSarmah et al. contextual data. This combined context is then utilized as input for a LLM to generate the final responses. Details on the implementation of the HybridRAG will be provided in Section 4.4. 2.',\n",
       " '4 Evaluation Metrics To assess the efficacy of this integrated approach, we conducted a comparative analysis among the three approaches in a controlled ex- perimental set up: VectorRAG, GraphRAG and HybridRAG. The re- sponses generated using the combined VectorRAG and GraphRAG contexts were juxtaposed against those produced individually by VectorRAG and GraphRAG.',\n",
       " 'This comparative evaluation aimed to discern potential improvements in response quality, accuracy, and comprehensiveness that might arise from the synergistic integra- tion of these two RAG methodologies. To objectively evaluate different RAG approaches (VectorRAG and GraphRAG in their case), Ref. [ 22] utilized metrics such as comprehensiveness (i.e., the amount of details the answer provides to cover all aspects and details of the question?); diversity (i.e.',\n",
       " ', the richness of the answer in providing different perspectives and insights on the question); empowerment (i.e., the helpfulness of the answer to the reader understand and make informed judgements about the topic); and, directness (i.e., clearness of the answer in addressing the question). here, the LLM was provided tuples of question, target metric, and a pair of answers, and was asked to assess which answer was better according to the metric and why.',\n",
       " 'These metrics though compare the final generated answers, do not necessarily directly evaluate the retrieval and generation parts separately. Instead, here we implement a comprehensive set of evaluation metrics which are designed to capture different aspects of a given RAG system’s output quality, focusing on faithfulness, answer relevance, and context relevance [ 30]. Each metric provides unique insights into the system’s capabilities and limitations. 2.4.1 Faithfulness.',\n",
       " 'Faithfulness is a crucial metric that measures the extent to which the generated answer can be inferred from the provided context. Our implementation of the faithfulness metric involves a two-step process: Statement Extraction:- We use an LLM to decompose the gener- ated answer into a set of concise statements. This step is crucial for breaking down complex answers into more manageable and verifiable units.',\n",
       " 'The prompt used for this step is: \"Given a question and answer, create one or more statements from each sentence in the given answer. question: [question] an- swer: [answer]\". Statement Verification:- For each extracted statement, we employ the LLM to determine if it can be inferred from the given context.',\n",
       " 'This verification process uses the following prompt: \"Consider the given context and following statements, then de- termine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. statement: [statement 1] ... statement: [statement n]\".',\n",
       " 'The faithfulness score ( 𝐹) is𝐹=|𝑉|/|𝑆|, where |𝑉|is the number of supported statements and |𝑆|is the total number of statements.2.4.2 Answer Relevance:-. The answer relevance metric assesses how well the generated answer addresses the original question, irrespective of factual accuracy. This metric helps identify cases of incomplete answers or responses containing irrelevant information.',\n",
       " 'Our implementation involves the following steps: Question Generation: We prompt the LLM to generate n potential questions based on the given answer: \"Generate a question for the given answer. answer: [answer]\". Then, we obtain embeddings for all generated questions and the original question using OpenAI’s text-embedding-ada-002 model2. We then calculate the cosine similarity between each generated question’s embedding and the original question’s embedding.',\n",
       " 'Finally, the answer relevance score (AR) is computed as the aver- age similarity across all generated questions: 𝐴𝑅=1 𝑛Í(𝑠𝑖𝑚(𝑞,𝑞𝑖)), where𝑠𝑖𝑚(𝑞,𝑞𝑖)is the cosine similarity between the embedding of the original question 𝑞and the embeddings of each of the 𝑛 generated questions 𝑞𝑖. 2.4.3 Context Precision. It is a metric used to evaluate the relevance of retrieved context chunks in relation to a specified ground truth for a given question3.',\n",
       " 'It calculates the proportion of relevant items that appear in the top ranks of the context. The formula for context precision at K is the sum of the products of precision at each rank k and a binary relevance indicator v_k, divided by the total number of relevant items in the top K results. Precision at each rank k is determined by the ratio of true positives at k to the sum of true positives and false positives at k.',\n",
       " 'This metric helps in assessing how well the context supports the ground truth, aiming for higher scores which indicate better precision. 2.4.4 Context Recall. It is a metric used to evaluate how well the retrieved context aligns with the ground truth answer, which is considered the definitive correct response4. It is quantified by com- paring each sentence in the ground truth answer to see if it can be traced back to the retrieved context.',\n",
       " 'The formula for context recall is the ratio of the number of ground truth sentences that can be attributed to the context to the total number of sentences in the ground truth. Higher values, ranging from 0 to 1, indicate bet- ter alignment and thus better context recall. This metric is crucial for assessing the effectiveness of information retrieval systems in providing relevant context.',\n",
       " '3 DATA DESCRIPTION Although there do exist some public financial datasets, none of them were suitable for the present experiments: e.g., FinQA [ 31], TAT- QA [ 32], FIQA [ 33], FinanceBench [ 34], etc. datasets are limited to specific usecases such as benchmarking LLMs’ abilities to perform complex numerical reasoning or sentiment analysis. On the other hand, FinTextQA [ 35] dataset was not publicly available at the time of writing the present work.',\n",
       " 'In addition, in most of these datasets, access to the actual documents from which the ground- truth Q&As were created is not available, making it impossible to use them for our RAG techniques evaluation purposes. Hence, we resorted to a dataset of our own though through publicly available 2https://platform.openai.com/docs/guides/embeddings/embedding-models 3https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html 4https://docs.ragas.io/en/stable/concepts/metrics/context_recall.',\n",
       " 'htmlHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction documents but such that we finally have access to both the actual financial documents and the ground-truth Q&As. Datasets like FinanceBench5provides question-context-answer triplets but they are not useful as here we are comparing VectorRAG, GraphRAG and HybridRAG and they do not provide the context generated from a KG.',\n",
       " 'A recent paper [ 22] has not made the KG and triplets constructed by their algorithm public to the best of our knowledge either. In short, there is no publicly available benchmark dataset to compare VectorRAG and GraphRAG either for financial or general domains to the best of our knowledge. Hence, we had to rely on our own dataset constructed as explained below. We used transcripts from earnings calls of Nifty 50 constituents for our analysis.',\n",
       " 'The NIFTY 50 is popular index in the Indian stock market that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange (NSE). The dataset of the earning call documents of Nifty 50 companies is widely recognized in the investment realm and is esteemed as an authoritative and extensive collection of earnings call transcripts. In our investigation, we focus on data spanning the quarter ending in June, 2023 i.e.',\n",
       " 'the earnings reports for Q1 of the financial year 2024 (A financial year in India starts on the 1st April and ends in 31st March, so the quarter from 1st April to 30th June is the first quarter of 2024 for the Indian market).',\n",
       " 'Our dataset encompasses 50 transcripts for this quarter, span- ning over 50 companies within Nifty 50 universe from diverse range of sectors including Infrastructure, Healthcare, Consumer Durables, Banking, Automobile, Financial Services, Energy - Oil & Gas, Telecommunication, Consumer Goods, Pharmaceuticals, Energy - Coal, Materials, Information Technology, Construction, Diversified, Metals, Energy - Power and Chemicals providing a substantial and diverse foundation for our study.',\n",
       " 'We start the data collection process focused on acquiring earn- ings reports from company websites within the Nifty 50 universe by developing and deploying a custom web scraping tool to navigate through the websites of each company within the Nifty 50 index, systematically retrieving the pertinent earnings reports for Q1 of the financial year 2024. By utilizing this web scraping approach, we aimed to compile a comprehensive dataset encompassing the earnings reports of the constituent companies.',\n",
       " 'Table 1 summarizes basic statistics of the documents we will be experimenting with in the remainder of this work. Number of companies/documents 50 Average number of pages 27 Average number of questions 16 Average number of tokens 60,000 Table 1: Summary Statistics for the call transcript documents used in the present work.',\n",
       " 'These call transcripts documents consist of questions and an- swers between financial analysts and the company representatives for the respective companies, hence, there already exist certain Q&A pairs within these documents along with additional text. We examined the earnings reports within the Nifty50 universe, system- atically curated a comprehensive array of randomly selected 400 5https://huggingface.',\n",
       " 'co/datasets/PatronusAI/financebench-testquestions posed during the earnings calls from all the documents, and gathered the exact responses corresponding to these questions. These questions constitute the specific queries articulated by finan- cial analysts to the management during these calls. 4 IMPLEMENTATION DETAILS In this Section, we provide details of implementation of the pro- posed methodology. 4.',\n",
       " '1 Knowledge Graph Construction The initial phase of our approach centers on document preprocess- ing. We utilize the PyPDFLoader6to import PDF documents, which are subsequently segmented into manageable chunks using the RecursiveCharacterTextSplitter. This chunking strategy employs a size of 2024 characters with an overlap of 204 characters, ensuring comprehensive coverage while maintaining context across segment boundaries.',\n",
       " 'Following the preprocessing stage, we implement the two-tiered language model chain for content refinement and information ex- traction. It is not possible to include the exact prompt here due to the limited space, but a baseline prompt can be found in Ref. [18].',\n",
       " 'Entity Type Examples Companies and Corpo- rationsOfficial names, abbreviations, infor- mal references Financial Metrics and IndicatorsRevenue, profit margins, EBITDA Corporate Executives and Key PersonnelCEOs, CFOs, board members Products and Services Tangible products and intangible ser- vices Geographical Locations Headquarters, operational regions, markets Corporate Events Mergers, acquisitions, product launches, earnings calls Legal and Regulatory InformationLegal cases, regulatory compliance Table 2: Entities extracted from earnings call transcripts Table 2 summarizes details on entities extracted from the earn- ing calls transcripts using our prompt based method.',\n",
       " 'Concurrently, LLM identifies relationships between these entities using a curated set of verbs, capturing the nuanced interactions within the cor- porate narrative. A key improvement in our methodology is the enhanced prompt engineering to generate the structured output format for knowledge triplets.',\n",
       " 'Each triplet is represented as a nested list [’h’, ’type’, ’r’, ’o’, ’type’, ’metadata’], where ’h’ and ’o’ denote the head and object entities respectively, ’type’ specifies the entity category, ’r’ represents the relationship, and ’metadata’ encapsu- lates additional contextual information. This format allows for a rich, multidimensional representation of information, facilitating more nuanced downstream analysis. 6https://python.langchain.com/v0.',\n",
       " '1/docs/modules/data_connection/document_ loaders/pdf/Sarmah et al. Our process incorporates several advanced features to enhance the quality and utility of the extracted triplets. Entity disambigua- tion techniques are employed to consolidate different references to the same entity, improving consistency across the KG.',\n",
       " 'We also pri- oritize conciseness in entity representation, aiming for descriptions of less than four words where possible, which aids in maintaining a clean and navigable graph structure. The extraction pipeline is applied iteratively to each document chunk, with results aggregated to form a comprehensive knowledge graph representation of the entire document, allowing for scalable processing of large documents while maintaining local context within each chunk.',\n",
       " 'We have added explicit instruction on obtaining metadata following Ref. [8] for both VectorRAG and GraphRAG. Finally, we implement a data persistence strategy, converting the extracted triplets from their initial string format to Python data structures and storing them in a pickle file. This facilitates easy retrieval and further manipulation of the knowledge graph data in subsequent analysis stages.',\n",
       " 'Our methodology represents a significant advancement in auto- mated knowledge extraction from corporate documents. By com- bining advanced NLP techniques with a structured approach to information representation, we create a rich, queryable knowledge base that captures the complex relationships and key information present in corporate narratives.',\n",
       " 'This approach opens up new pos- sibilities for financial analysis and automated reasoning in the business domain that will be explored further in the future. 4.2 VectorRAG Our methodology builds upon the concept of RAG [ 9] which al- lows for the creation of a system that can provide context-aware, accurate responses to queries about company financial informa- tion, leveraging both the power of large language models and the efficiency of semantic search.',\n",
       " 'At the core of our system is a Pinecone vector database7, which serves as the foundation for our information retrieval process. We employ OpenAI’s text-embedding-ada-002 model to transform tex- tual data from earnings call transcripts into high-dimensional vec- tor representations. This vectorization process enables semantic similarity searches, significantly enhancing the relevance and ac- curacy of retrieved information.',\n",
       " 'Table 3 provides summary of the configuration of the set up in use for our experiments. LLM GPT-3.5-Turbo LLM Temperature 0 Embedding Model text-embedding-ada-002 Framework LangChain Vector Database Pinecone Chunk Size 1024 Chunk Overlap 0 Maximum Output Tokens 1024 Chunks for Similarity Algorithm 20 Number of Context Retrieved 4 Table 3: VectorRAG Configuration 7https://www.pinecone.io/The Q&A pipeline is constructed using the LangChain frame- work8.',\n",
       " 'The begins with a context retrieval step, where we query the Pinecone vector store to obtain the most relevant document chunks for a given question. This retrieval process is fine-tuned with spe- cific filters for quarters, years, and company names, ensuring that the retrieved information is both relevant and current. Following retrieval, we implement a context formatting step that consolidates the retrieved document chunks into a coherent context string.',\n",
       " 'This formatted context serves as the informational basis for the language model’s response generation. We have developed a sophisticated prompt template, that instructs the language model to function as an expert Q&A system, emphasizing the importance of utilizing only the provided context information and avoiding direct references to the context in the generated responses. For the core language processing task, we integrate OpenAI’s GPT-3.',\n",
       " '5-turbo model which processes the formatted context and query to generate natural language responses that are informative, coherent, and contextually appropriate. To evaluate the performance of our system, we developed a comprehensive framework that includes the preparation of a cus- tom dataset of question-answer pairs specific to each company’s earnings call. Our system processes each question in this dataset, generating answers based on the retrieved context.',\n",
       " 'The evaluation results, including the original question, generated answer, retrieved contexts, and ground truth, are compiled into structured formats (CSV and JSON) to facilitate further analysis. The outputs generated by our system are stored in both CSV and JSON formats, enabling easy integration with various analysis tools and dashboards.',\n",
       " 'This approach facilitates both quantitative performance metrics and qualitative assessment of the system’s responses, providing a com- prehensive view of its effectiveness. By parameterizing company names, quarters, and years, we can easily adapt the system to different datasets and time periods. This design choice allows for seamless integration of new data and expansion to cover multiple companies and earnings calls. 4.',\n",
       " '3 GraphRAG For GraphRAG, we developed an Q&A system specifically designed for corporate earnings call transcripts. Our implementation of GraphRAG leverages several key components and techniques: LLM GPT-3.5-Turbo LLM Temperature 0 Framework LangChain KG Manipulation Networkx Chunk Size 1024 Chunk Overlap 0 Number of Triplets 13950 Number of nodes 11405 Number of edges 13883 DFS Depth 1 Table 4: GraphRAG Configuration 8https://docs.smith.langchain.',\n",
       " 'com/old/cookbook/hub-examples/retrieval-qa-chainHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Knowledge Graph Construction:- We begin by constructing a KG from a set of knowledge triplets extracted from corporate documents using the prompt engineering based methodology as described in Section 4.1.',\n",
       " 'These triplets, stored in a pickle file, repre- sent structured information in the form of subject-predicate-object relationships. We use the NetworkxEntityGraph class from the LangChain library to create and manage this graph structure. Each triple is added to the graph, which encapsulates the head entity, relation, tail entity, and additional metadata. We implement the Q&A functionality using the GraphQAChain class from LangChain.',\n",
       " 'This chain combines the KG with an LLM (in our case, OpenAI’s GPT-3.5-turbo) to generate responses. The GraphQAChain traverses the KG to find relevant information and uses the language model to formulate coherent answers based on the retrieved context. A summary of configuration of our LLM models and other libraries used for GraphRAG is shown in Table 4.',\n",
       " 'In KG as the information is stored in the form of entities and relationships and there can be multiple relations emanating from one single entity, in this experiment, to extract relevant information from the KG, we employ a depth-first search strategy constrained by a depth of one from the specified entity.',\n",
       " 'To prepare for assessing the performance of our GraphRAG system, we follow the below steps: Dataset Preparation:- We use a pre-generated CSV file containing question-answer pairs specific to the earnings call transcript. Iterative Processing:- For each question in the dataset, we run the GraphQAChain to generate an answer. Result Compilation:- We compile the results, including the origi- nal questions, generated answers, retrieved contexts, and ground truth answers, into a structured format.',\n",
       " 'Finally, the evaluation results are saved in both CSV and JSON formats for further analysis and comparison. We then fed these outputs into our RAG evaluation pipeline. For each Q&A pair in our dataset, we compute all three metrics: faithfulness, answer relevance, context precision and context recall. 4.',\n",
       " '4 HybridRAG For the proposed HybridRAG technique, upon obtaining all the contextual information from VectorRAG and GraphRAG, we con- catenate these contexts to form a unified context utilizing both techniques. This combined context is then fed into the answer gen- erator model to produce a response. The context used for response generation is relatively larger, which affects the precision of the generated response.',\n",
       " 'The context from VectorRAG is appended first, followed by the context from GraphRAG. Consequently, the preci- sion of the generated answer depends on the source context. If the answer is generated from the GraphRAG context, it will have lower precision, as the GraphRAG context is added last in the sequence of contexts provided to the answer generator model, and vice versa. 5 RESULTS We evaluate both the retrieval and generation parts of RAG for the three different RAG pipelines.',\n",
       " 'Evaluating the RAG outputs is also an active area of research there is no standard tool which is universally accepted as of yet, though we use a currently popular framework RAGAS[ 30] to evaluate the three RAG pipelines in thepresent work where we have modified them a bit to make more precise comparisons. The results of our comparative analysis reveal notable differences in performance among VectorRAG, GraphRAG, and HybridRAG approaches as summarized in Table 5.',\n",
       " 'In terms of Faithfulness, GraphRAG and HybridRAG demonstrated superior performance, both achieving a score of 0.96, while VectorRAG trailed slightly with a score of 0.94. Answer relevancy scores varied across the meth- ods, with HybridRAG outperforming the others at 0.96, followed by VectorRAG at 0.91, and GraphRAG at 0.89. Context precision was highest for GraphRAG at 0.96, significantly surpassing Vec- torRAG (0.84) and HybridRAG (0.79).',\n",
       " 'However, in context recall, both VectorRAG and HybridRAG achieved perfect scores of 1, while GraphRAG lagged behind at 0.85. Overall, these results suggest that GraphRAG offers improve- ments over VectorRAG, particularly in faithfulness and context pre- cision. Furthermore, HybridRAG emerges as the most balanced and effective approach, outperforming both VectorRAG and GraphRAG in key metrics such as faithfulness and answer relevancy, while maintaining high context recall.',\n",
       " 'The relatively lower context precision observed for HybridRAG (0.79) can be attributed to its unique approach of combining con- texts from both VectorRAG and GraphRAG methods. While this integration allows for more comprehensive information retrieval, it also introduces additional content that may not align precisely with the ground truth, thus affecting the context precision met- ric.',\n",
       " 'Despite this trade-off, HybridRAG’s superior performance in faithfulness, answer relevancy, and context recall underscores its effectiveness. When considering the overall evaluation metrics, HybridRAG emerges as the most promising approach, balancing high-quality answers with comprehensive context retrieval. Overall GraphRAG performs better in extractive questions com- pared to VectorRAG.',\n",
       " 'And VectorRAG does better in abstractive questions where information is not explicitly mentioned in the raw data. And also GraphRAG sometimes fails to answer ques- tions correctly whenever there is no entity explicitly mentioned in the question. So HybridRAG does a good job overall, as whenever VectorRAG fails to fetch correct context in extractive questions it falls back to GraphRAG to generate the answer.',\n",
       " 'And whenever GraphRAG fails to fetch correct context in abstractive questions it falls back to VectorRAG to generate the answer. VectorRAG GraphRAG HybridRAG F 0.94 0.96 0.96 AR 0.91 0.89 0.96 CP 0.84 0.96 0.79 CR 1 0.85 1 Table 5: Performance Metrics for Different RAG Pipelines. Here, F, AR, CP and CR refer to Faithfulness, Answer Relevence, Context Precision and Context Recall.',\n",
       " '6 CONCLUSION AND FUTURE DIRECTIONS Among the current approaches to mitigate issues regarding infor- mation extraction from external documents that were not part ofSarmah et al. training data for the LLM, Retrieval Augmented Generation (RAG) techniques have emerged as the most popular ones that aim to improve the performance of LLMs by incorporating relevant re- trieval mechanisms.',\n",
       " 'RAG methods enhance the LLMs’ capabilities by retrieving pertinent documents or text to provide additional context during the generation process. However, these approaches encounter significant limitations when applied to the specialized and intricate domain of financial documents. Furthermore, the qual- ity of the retrieved context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses.',\n",
       " 'These challenges highlight the need for more sophisticated methods that can effectively integrate and process the detailed and domain- specific information found in financial documents, ensuring more reliable and accurate outputs for informed decision-making. In the present work, we have introduced a novel approach that significantly advances the field of information extraction from finan- cial documents through the development of a hybrid RAG system.',\n",
       " 'This system, called HybridRAG, which integrates the strengths of both Knowledge Graphs (KGs) and advanced language models, represents a leap forward in our ability to extract and interpret complex information from unstructured financial texts. The hybrid RAG system, by combining traditional vector-based RAG and KG- based RAG, has shown superior performance in terms of retrieval accuracy and answer generation, marking a pivotal step towards more effective financial analysis tools.',\n",
       " 'Through a comparative analysis using objecive evaluation met- rics, we have highlighted the distinct performance advantages of the HybridRAG approach over its vector-based and KG-based coun- terparts. The HybridRAG system excels in faithfulness, answer relevancy, and context recall, demonstrating the benefits of inte- grating contexts from both VectorRAG and GraphRAG methods, despite potential trade-offs in context precision.',\n",
       " 'The implications of this research extend beyond the immedi- ate realm of financial analysis. By developing a system capable of understanding and responding to nuanced queries about com- plex financial documents, we pave the way for more sophisticated AI-assisted financial decision-making tools that could potentially democratize access to financial insights, allowing a broader range of stakeholders to engage with and understand financial information.',\n",
       " 'Future directions for this research include expanding the system to handle multi-modal inputs, incorporating numerical data analysis capabilities, and developing more sophisticated evaluation metrics that capture the nuances of financial language and the accuracy of numerical information in the responses. Additionally, exploring the integration of this system with real-time financial data streams could further enhance its utility in dynamic financial environments.',\n",
       " '7 ACKNOWLEDGEMENT The views expressed here are those of the authors alone and not of BlackRock, Inc or NVIDIA. We are grateful to Emma Lind for her invaluable support for this collaboration. REFERENCES [1] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. 2013. [2]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need.',\n",
       " 'Advances inneural information processing systems, 30, 2017.[3]Yi Yang, Mark Christopher Siy Uy, and Allen Huang. Finbert: A pretrained language model for financial communications. arXiv preprint arXiv:2006.08097 , 2020. [4]Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Se- bastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann. Bloomberggpt: A large language model for finance. arXiv preprint arXiv:2303.17564, 2023.',\n",
       " '[5] Yuqi Nie, Yaxuan Kong, Xiaowen Dong, John M Mulvey, H Vincent Poor, Qing- song Wen, and Stefan Zohren. A survey of large language models for financial ap- plications: Progress, prospects and challenges. arXiv preprint arXiv:2406.11903 , 2024. [6]Huaqin Zhao, Zhengliang Liu, Zihao Wu, Yiwei Li, Tianze Yang, Peng Shu, Shaochen Xu, Haixing Dai, Lin Zhao, Gengchen Mai, Ninghao Liu, and Tianming Liu. Revolutionizing finance with llms: An overview of applications and insights, 2024.',\n",
       " '[7] Chen Ling, Xujiang Zhao, Jiaying Lu, Chengyuan Deng, Can Zheng, Junxiang Wang, Tanmoy Chowdhury, Yun Li, Hejie Cui, Xuchao Zhang, et al. Domain spe- cialization as the key to make large language models disruptive: A comprehensive survey. arXiv preprint arXiv:2305.18703, 2023. [8] Bhaskarjit Sarmah, Dhagash Mehta, Stefano Pasquali, and Tianjie Zhu. Towards reducing hallucination in extracting information from financial reports using large language models.',\n",
       " 'In Proceedings oftheThird International Conference onAI-ML Systems, pages 1–5, 2023. [9]Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances inNeural Information Processing Systems , 33:9459–9474, 2020. [10] Gautier Izacard and Edouard Grave.',\n",
       " 'Leveraging passage retrieval with generative models for open domain question answering. arXiv preprint arXiv:2007.01282 , 2021. [11] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. Realm: Retrieval-augmented language model pre-training. arXiv preprint arXiv:2002.08909, 2020. [12] Antonio Jose Jimeno Yepes et al. Financial report chunking for effective retrieval augmented generation. arXiv preprint arXiv:2402.05131, 2024. [13] SuperAcc.',\n",
       " 'Retrieval-augmented generation on financial statements. SuperAcc Insights, 2024. [14] Shaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, and S Yu Philip. A survey on knowledge graphs: Representation, acquisition, and applications. IEEE transactions onneural networks andlearning systems, 33(2):494–514, 2021. [15] Heiko Paulheim. Knowledge graphs: State of the art and future directions. Semantic Web Journal, 10(4):1–20, 2017.',\n",
       " '[16] Aidan Hogan, Eva Blomqvist, Michael Cochez, Claudia D’Amato, Gerard de Melo, Claudio Gutiérrez, and Maria ... Maleshkova. Knowledge graphs. arXiv preprint arXiv:2003.02320, 2021. [17] Lisa Ehrlinger and Wolfram Wöß. Towards a definition of knowledge graphs. In SEMANTiCS (Posters, Demos, SuCCESS), pages 1–4, 2016. [18] Xiaohui Victor Li and Francesco Sanna Passino. Findkg: Dynamic knowledge graphs with large language models for detecting global trends in financial mar- kets.',\n",
       " 'arXiv preprint arXiv:2407.10909, 2024. [19] Shourya De, Anima Aggarwal, and Anna Cinzia Squicciarini. Financial knowl- edge graphs: A novel approach to empower data-driven financial applications. In IEEE International Conference onBigData (Big Data), pages 1311–1320, 2018. [20] Marina Petrova and Birgit Reinwald. Knowledge graphs in finance: Applications and opportunities. Journal ofFinancial Data Science, 2(2):10–19, 2020. [21] Wei Liu, Jun Zhang, and Li Pan.',\n",
       " 'Utilizing knowledge graphs for financial data integration and analysis. Data Science Journal, 18(1):1–15, 2019. [22] Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, and Jonathan Larson. From local to global: A graph rag approach to query-focused summarization. arXiv preprint arXiv:2404.16130 , 2024. [23] Xuchen Yao, Yanan Sun, Zhen Huang, and Dong Li. Retrieval-augmented gener- ation for knowledge-intensive nlp tasks. arXiv preprint arXiv:2101.',\n",
       " '07554 , 2021. [24] Weizhi Zhao, Haoyu Chen, Kai Liu, and Jun Zhao. Graph-based retrieval- augmented generation for open-domain question answering. In Proceedings oftheAAAI Conference onArtificial Intelligence , volume 36, pages 3098–3106, 2022. [25] Bill Yuchen Lin, Yuanhe Liu, Ming Shen, and Xiang Ren. Kgpt: Knowledge- grounded pre-training for data-to-text generation. In Findings oftheAssociation forComputational Linguistics: EMNLP 2020, pages 710–724, 2020.',\n",
       " '[26] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Ji- awei Sun, and Haofen Wang. Retrieval-augmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997, 2023. [27] Tyler Procko. Graph retrieval-augmented generation for large language models: A survey. Available atSSRN, 2024. [28] Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, and Xindong Wu. A comprehensive survey on automatic knowledge graph construction.',\n",
       " 'ACM Computing Surveys , 56(4):1–62, 2023.HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Bhaskarjit Sarmah bhaskarjit.sarmah@blackrock.com BlackRock, Inc. Gurugram, IndiaBenika Hall bhall@nvidia.com NVIDIA Santa Clara, CA, USARohan Rao rohrao@nvidia.com NVIDIA Santa Clara, CA, USA Sunil Patel supatel@nvidia.com NVIDIA Santa Clara, CA, USAStefano Pasquali stefano.pasquali@blackrock.com BlackRock, Inc.',\n",
       " 'New York, NY, USADhagash Mehta dhagash.mehta@blackrock.com BlackRock, Inc.',\n",
       " 'New York, NY, USA ABSTRACT Extraction and interpretation of intricate information from unstruc- tured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Re- trieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents.',\n",
       " 'We introduce a novel approach based on a combination, called HybridRAG , of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for infor- mation extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers.',\n",
       " 'Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG indi- vidually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation.',\n",
       " 'The proposed technique has applications beyond the financial domain. 1 INTRODUCTION For the financial analyst, it is crucial to extract and analyze infor- mation from unstructured data sources like news articles, earnings reports, and other financial documents to have at least some chance to be on the better side of potential information asymmetry. These sources hold valuable insights that can impact investment decisions, market predictions, and overall sentiment.',\n",
       " 'However, traditional data analysis methods struggle to effectively extract and utilize this information due to its unstructured nature. Large language models (LLMs) [ 1–4] have emerged as powerful tools for financial services and investment management. Their ability to process and understand vast amounts of textual data makes them invaluable for tasks such as sentiment analysis, market trend predictions, and automated report generation.',\n",
       " 'Specifically, extracting information from annual reports and other financial documents can greatly en- hance the efficiency and accuracy of financial analysts [ 5]. A robust information extraction system can help analysts quickly gather relevant data, identify market trends, and make informed decisions, leading to better investment strategies and risk management [6].',\n",
       " 'Although LLMs have substantial potential in financial applica- tions, there are notable challenges in using pre-trained models to extract information from financial documents outside their training data while also reducing hallucination [ 7,8]. Financial documents typically contain domain-specific language, multiple data formats, and unique contextual relationships that general purpose-trained LLMs do not handle well.',\n",
       " 'In addition, extracting consistent and coherent information from multiple financial documents can be challenging due to variations in terminology, format, and context across different textual sources. The specialized terminology and complex data formats in financial documents make it difficult for models to extract meaningful insights, in turn, causing inaccurate predictions, overlooked insights, and unreliable analysis, which ultimately hinder the ability to make well-informed decisions.',\n",
       " 'Current approaches to mitigate these issues include various Retrieval-Augmented Generation (RAG) techniques [ 9], which aim to improve the performance of LLMs by incorporating relevant retrieval techniques. VectorRAG (the traditional RAG techniques that are based on vector databases) focuses on improving Natural Language Processing (NLP) tasks by retrieving relevant textual information to support the generation tasks.',\n",
       " 'VectorRAG excels in situations where context from related textual documents is crucial for generating meaningful and coherent responses [ 9–11]. RAG- based methods ensure the LLMs generate relevant and coherent responses that are aligned with the original input query. How- ever, for financial documents, these approaches have significant challenges as a standalone solution.',\n",
       " 'For instance, traditional RAG systems often use paragraph-level chunking techniques, which assume the text in those documents are uniform in length. This approach neglects the hierarchical nature of financial statements and can result in the loss of critical contextual information for an accurate analysis[ 12,13].',\n",
       " 'Due to the complexities in analyzing fi- nancial documents, the quality of the LLM retrieved-context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses. These challenges demon- strate the need for more sophisticated methods that can effectively integrate and process the detailed and domain-specific information found in financial documents, ensuring more reliable and accurate results for informed decision-making.',\n",
       " 'Knowledge graphs (KGs) [ 14] may provide a different point of view to looking at the financial documents where the documentsarXiv:2408.04948v1 [cs.CL] 9 Aug 2024Sarmah et al. are viewed as a collection of triplets of entities and their relation- ships as depicted in the text of the documents.',\n",
       " 'KGs have become a pivotal technology in data management and analysis, provid- ing a structured way to represent knowledge through entities and relationships and have been widely adopted in various domains, including search engines, recommendation systems, and biomedical research [ 15–17]. The primary advantage of KGs lies in their ability to offer a structured representation, which facilitates efficient query- ing and reasoning.',\n",
       " 'However, building and maintaining KGs and integrating data from different sources, such as documents, news articles, and other external sources, into a coherent knowledge graph poses significant challenges. The financial services industry has recognized the potential of KGs in enhancing data integration of heterogeneous data sources, risk management, and predictive analytics [ 18?–21].',\n",
       " 'Financial KGs integrate various financial data sources such as market data, fi- nancial reports, and news articles, creating a comprehensive view of financial entities and their relationships. This unified view im- proves the accuracy and comprehensiveness of financial analysis, facilitates risk management by identifying hidden relationships, and supports advanced predictive analytics for more accurate mar- ket predictions and investment decisions.',\n",
       " 'However, handling large volumes of financial data and continuously updating the knowledge graph to reflect the dynamic nature of financial markets can be challenging and resource-intensive. GraphRAG (Graph-based Retrieval-Augmented Generation) [ 22– 27] is a novel approach that leverages knowledge graphs (KGs) to enhance the performance of NLP tasks such as Q&A systems.',\n",
       " 'By integrating KGs with RAG techniques, GraphRAG enables more accurate and context-aware generation of responses based on the structured information extracted from financial documents. But GraphRAG generally underperforms in abstractive Q&A tasks or when there is not explicit entity mentioned in the question.',\n",
       " 'In the present work, we propose a combination of VectorRAG and GraphRAG, called HybridRAG, to retrieve the relevant information from external documents for a given query to the LLM that brings advantages of both the RAGs together to provide demonstrably more accurate answers to the queries. 1.',\n",
       " '1 Prior Work and Our Contribution VectorRAG has been extensively investigated in the recent years and focuses on enhancing NLP tasks by retrieving relevant textual information to support generation processes [ 9–11,26]. However, the effectiveness of the retrieval mechanism across multiple docu- ments and longer contexts poses a significant challenge in extract- ing relevant responses. GraphRAG combines the capabilities of KGs with RAG to improve traditional NLP tasks [ 23–25].',\n",
       " 'Within our implementations of both VectorRAG GraphRAG techniques, we explicitly add information on the metadata of the documents that is also shown to improve the performance of VectorRAG [8]. To the best of our knowledge the present work is the first work that proposes a RAG approach that is hybrid of both VectorRAG and GraphRAG and demonstrates its potential of more effective analysis and utilization of financial documents by leveraging the combined strengths of VectorRAG and GraphRAG.',\n",
       " 'We also utilize a novel ground-truth Q&A dataset extracted from publicly availablefinancial call transcripts of the companies included in the Nifty-50 index which is an Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange1.',\n",
       " '2 METHODOLOGY In this Section, we provide details of the proposed methodology by first discussing details of VectorRAG, then methodologies of constructing KGs from given documents and our proposed method- ology of GraphRAG and finally the HybridGraph technique. 2.1 VectorRAG The traditional RAG [ 9] process begins with a query that is related to the information possessed within external document(s) that are not a part of the training dataset for the LLM.',\n",
       " 'This query is used to search an external repository, such as a vector database or indexed corpus, to fetch relevant documents or passages containing useful information. These retrieved documents are then fed back into the LLM as additional context. Hence, in turn, for the given query, the language model generates a response based not only on its inter- nal training data but also by incorporating the retrieved external information.',\n",
       " 'This integration ensures that the generated content is grounded in more recent and verifiable data, improving the accu- racy and contextual relevance of the responses. By combining the retrieval of external information with the generative capabilities of large language models, RAG enhances the overall quality and reliability of the generated text.',\n",
       " 'In traditional VectorRAG, the given external documents are di- vided into multiple chunks because of the limitation of context size of the language model. Those chunks are converted into embed- dings using an embeddings model and then stored into a vector database. After that, the retrieval component performs a similarity search within the vector database to identify and rank the chunks most relevant to the query.',\n",
       " 'The top-ranked chunks are retrieved and aggregated to provide context for the generative model. Then, the generative model takes this retrieved context along with the original query and synthesizes a response. Thus, it merges the real-time information from the retrieved chunks with its pre- existing knowledge, ensuring that the response is both contextually relevant and detailed.',\n",
       " 'The schematic diagram in Figure 1 provides details on the part of RAG that generates vector database from given external docu- ments in the traditional VectorRAG methodology where we also include explicit reference of metadata [8]. Section 4.2 will provide implementation details for our experiments. 2.2 Knowledge Graph Construction A KG is a structured representation of real-world entities, their attributes, and their relations, usually stored in a graph database or a triplet store, i.e.',\n",
       " ', a KG consists of nodes that represent entities and edges that represent relations, as well as labels and attributes for both. A graph triplet is a basic unit of information in a KG, consisting of a subject, a predicate, and an object. In most methodologies to build a KG from given documents, three main steps are involved: knowledge extraction, knowledge 1https://www.nseindia.com/products/content/equities/indices/nifty_50.',\n",
       " 'htmHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Figure 1: A schematic diagram describing the vector database creation of a RAG application. improvement, and knowledge adaptation [ 28]. Here, we do not use knowledge adaptation and treat the KGs as static graphs.',\n",
       " 'Knowledge Extraction:- This step aims to extract structured in- formation from unstructured or semi-structured data, such as text, databases, and existing ontologies. The main tasks in this step are entity recognition, relationship extraction, and co-reference reso- lution. Entity recognition and relationship extraction techniques use typical NLP tasks to identify entities and their relationships from textual sources [ 29].',\n",
       " 'Coreference resolution identifies and connects different references of the same entity, keeping coherence within the knowledge graph. For example, if the text refers to a company as both \"the company\" and \"it\", coreference resolution can link these mentions to the same entity node in the graph. Knowledge Improvement:- This step aims to enhance the quality and completeness of the KG by removing redundancies and address- ing gaps in the extracted information.',\n",
       " 'The primary tasks in this step are KG completion and fusion. KG completion technique infers missing entities and relationships within the graph using meth- ods such as link prediction and entity resolution. Link prediction predicts the existence and type of a relation between two entities based on the graph structure and features, while entity resolution matches and merges different representations of the same entity from different sources.',\n",
       " 'Knowledge fusion combines information from multiple sources to create a coherent and unified KG. This involves resolving conflicts and redundancies among the sources, such as contradictory or duplicate facts, and aggregating or reconciling the information based on rules, probabilities, or semantic similarity. We utilized a robust methodology for creating KG triplets from unstructured text data, specifically focusing on corporate docu- ments such as earnings call transcripts, adapted from Ref.',\n",
       " '[ 18?]. This process involves several interconnected stages, each designed to extract, refine, and structure information effectively. We implement a two-tiered LLM chain for content refinement and information extraction. The first tier employs an LLM to gen- erate an abstract representation of each document chunk.',\n",
       " 'This refinement process is crucial as it distills the essential information while preserving the original meaning and key relationships be- tween concepts that serves as a more focused input for subsequent processing, enhancing the overall efficiency and accuracy of ourtriplet extraction pipeline. The second tier of our LLM chain is dedicated to entity extraction and relationship identification. Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM.',\n",
       " 'A detailed discussion on imple- mentation of the methodology will be provided in Section 4.1 2.3 GraphRAG KG based RAG [ 22], or GraphRAG, also begins with a query based on the user’s input same as VectorRAG. The main difference be- tween VectorRAG and GraphRAG lies in the retrieval part. The query here is now used to search the KG to retrieve relevant nodes (entities) and edges (relationships) related to the query.',\n",
       " 'A subgraph, which consists of these relevant nodes and edges, is extracted from the full KG to provide context. This subgraph is then integrated with the language model’s internal knowledge, by encoding the graph structure into embeddings that the model can interpret. The language model uses this combined context to generate responses that are informed by both the structured information from the KG and its pre-trained knowledge.',\n",
       " 'Crucially, when responding to user queries about a particular company, we leveraged the metadata information to selectively filter and retrieve only those document segments pertinent to the queried company [ 8]. This integration helps ensure that the generated outputs are accurate, contextually relevant, and grounded in verifiable information. A schematic diagram of the retrieval methodology of GraphRAG is given in Figure 2.',\n",
       " 'Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section 4.1 Figure 2: A schematic diagram describing knowledge graph creation process of GraphRAG. 2.3.1 HybridRAG. For the HybridRAG technique, we propose to integrate the aforementioned two distinct RAG techniques: Vec- torRAG and GraphRAG.',\n",
       " 'This integration involves a systematic combination of contextual information retrieved from both the traditional vector-based retrieval mechanism and the KG-based retrieval system, the latter of which was constructed specifically for this study. The amalgamation of these two contexts allows us to leverage the strengths of both approaches.',\n",
       " 'The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-richSarmah et al. contextual data. This combined context is then utilized as input for a LLM to generate the final responses. Details on the implementation of the HybridRAG will be provided in Section 4.4. 2.',\n",
       " '4 Evaluation Metrics To assess the efficacy of this integrated approach, we conducted a comparative analysis among the three approaches in a controlled ex- perimental set up: VectorRAG, GraphRAG and HybridRAG. The re- sponses generated using the combined VectorRAG and GraphRAG contexts were juxtaposed against those produced individually by VectorRAG and GraphRAG.',\n",
       " 'This comparative evaluation aimed to discern potential improvements in response quality, accuracy, and comprehensiveness that might arise from the synergistic integra- tion of these two RAG methodologies. To objectively evaluate different RAG approaches (VectorRAG and GraphRAG in their case), Ref. [ 22] utilized metrics such as comprehensiveness (i.e., the amount of details the answer provides to cover all aspects and details of the question?); diversity (i.e.',\n",
       " ', the richness of the answer in providing different perspectives and insights on the question); empowerment (i.e., the helpfulness of the answer to the reader understand and make informed judgements about the topic); and, directness (i.e., clearness of the answer in addressing the question). here, the LLM was provided tuples of question, target metric, and a pair of answers, and was asked to assess which answer was better according to the metric and why.',\n",
       " 'These metrics though compare the final generated answers, do not necessarily directly evaluate the retrieval and generation parts separately. Instead, here we implement a comprehensive set of evaluation metrics which are designed to capture different aspects of a given RAG system’s output quality, focusing on faithfulness, answer relevance, and context relevance [ 30]. Each metric provides unique insights into the system’s capabilities and limitations. 2.4.1 Faithfulness.',\n",
       " 'Faithfulness is a crucial metric that measures the extent to which the generated answer can be inferred from the provided context. Our implementation of the faithfulness metric involves a two-step process: Statement Extraction:- We use an LLM to decompose the gener- ated answer into a set of concise statements. This step is crucial for breaking down complex answers into more manageable and verifiable units.',\n",
       " 'The prompt used for this step is: \"Given a question and answer, create one or more statements from each sentence in the given answer. question: [question] an- swer: [answer]\". Statement Verification:- For each extracted statement, we employ the LLM to determine if it can be inferred from the given context.',\n",
       " 'This verification process uses the following prompt: \"Consider the given context and following statements, then de- termine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. statement: [statement 1] ... statement: [statement n]\".',\n",
       " 'The faithfulness score ( 𝐹) is𝐹=|𝑉|/|𝑆|, where |𝑉|is the number of supported statements and |𝑆|is the total number of statements.2.4.2 Answer Relevance:-. The answer relevance metric assesses how well the generated answer addresses the original question, irrespective of factual accuracy. This metric helps identify cases of incomplete answers or responses containing irrelevant information.',\n",
       " 'Our implementation involves the following steps: Question Generation: We prompt the LLM to generate n potential questions based on the given answer: \"Generate a question for the given answer. answer: [answer]\". Then, we obtain embeddings for all generated questions and the original question using OpenAI’s text-embedding-ada-002 model2. We then calculate the cosine similarity between each generated question’s embedding and the original question’s embedding.',\n",
       " 'Finally, the answer relevance score (AR) is computed as the aver- age similarity across all generated questions: 𝐴𝑅=1 𝑛Í(𝑠𝑖𝑚(𝑞,𝑞𝑖)), where𝑠𝑖𝑚(𝑞,𝑞𝑖)is the cosine similarity between the embedding of the original question 𝑞and the embeddings of each of the 𝑛 generated questions 𝑞𝑖. 2.4.3 Context Precision. It is a metric used to evaluate the relevance of retrieved context chunks in relation to a specified ground truth for a given question3.',\n",
       " 'It calculates the proportion of relevant items that appear in the top ranks of the context. The formula for context precision at K is the sum of the products of precision at each rank k and a binary relevance indicator v_k, divided by the total number of relevant items in the top K results. Precision at each rank k is determined by the ratio of true positives at k to the sum of true positives and false positives at k.',\n",
       " 'This metric helps in assessing how well the context supports the ground truth, aiming for higher scores which indicate better precision. 2.4.4 Context Recall. It is a metric used to evaluate how well the retrieved context aligns with the ground truth answer, which is considered the definitive correct response4. It is quantified by com- paring each sentence in the ground truth answer to see if it can be traced back to the retrieved context.',\n",
       " 'The formula for context recall is the ratio of the number of ground truth sentences that can be attributed to the context to the total number of sentences in the ground truth. Higher values, ranging from 0 to 1, indicate bet- ter alignment and thus better context recall. This metric is crucial for assessing the effectiveness of information retrieval systems in providing relevant context.',\n",
       " '3 DATA DESCRIPTION Although there do exist some public financial datasets, none of them were suitable for the present experiments: e.g., FinQA [ 31], TAT- QA [ 32], FIQA [ 33], FinanceBench [ 34], etc. datasets are limited to specific usecases such as benchmarking LLMs’ abilities to perform complex numerical reasoning or sentiment analysis. On the other hand, FinTextQA [ 35] dataset was not publicly available at the time of writing the present work.',\n",
       " 'In addition, in most of these datasets, access to the actual documents from which the ground- truth Q&As were created is not available, making it impossible to use them for our RAG techniques evaluation purposes. Hence, we resorted to a dataset of our own though through publicly available 2https://platform.openai.com/docs/guides/embeddings/embedding-models 3https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html 4https://docs.ragas.io/en/stable/concepts/metrics/context_recall.',\n",
       " 'htmlHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction documents but such that we finally have access to both the actual financial documents and the ground-truth Q&As. Datasets like FinanceBench5provides question-context-answer triplets but they are not useful as here we are comparing VectorRAG, GraphRAG and HybridRAG and they do not provide the context generated from a KG.',\n",
       " 'A recent paper [ 22] has not made the KG and triplets constructed by their algorithm public to the best of our knowledge either. In short, there is no publicly available benchmark dataset to compare VectorRAG and GraphRAG either for financial or general domains to the best of our knowledge. Hence, we had to rely on our own dataset constructed as explained below. We used transcripts from earnings calls of Nifty 50 constituents for our analysis.',\n",
       " 'The NIFTY 50 is popular index in the Indian stock market that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange (NSE). The dataset of the earning call documents of Nifty 50 companies is widely recognized in the investment realm and is esteemed as an authoritative and extensive collection of earnings call transcripts. In our investigation, we focus on data spanning the quarter ending in June, 2023 i.e.',\n",
       " 'the earnings reports for Q1 of the financial year 2024 (A financial year in India starts on the 1st April and ends in 31st March, so the quarter from 1st April to 30th June is the first quarter of 2024 for the Indian market).',\n",
       " 'Our dataset encompasses 50 transcripts for this quarter, span- ning over 50 companies within Nifty 50 universe from diverse range of sectors including Infrastructure, Healthcare, Consumer Durables, Banking, Automobile, Financial Services, Energy - Oil & Gas, Telecommunication, Consumer Goods, Pharmaceuticals, Energy - Coal, Materials, Information Technology, Construction, Diversified, Metals, Energy - Power and Chemicals providing a substantial and diverse foundation for our study.',\n",
       " 'We start the data collection process focused on acquiring earn- ings reports from company websites within the Nifty 50 universe by developing and deploying a custom web scraping tool to navigate through the websites of each company within the Nifty 50 index, systematically retrieving the pertinent earnings reports for Q1 of the financial year 2024. By utilizing this web scraping approach, we aimed to compile a comprehensive dataset encompassing the earnings reports of the constituent companies.',\n",
       " 'Table 1 summarizes basic statistics of the documents we will be experimenting with in the remainder of this work. Number of companies/documents 50 Average number of pages 27 Average number of questions 16 Average number of tokens 60,000 Table 1: Summary Statistics for the call transcript documents used in the present work.',\n",
       " 'These call transcripts documents consist of questions and an- swers between financial analysts and the company representatives for the respective companies, hence, there already exist certain Q&A pairs within these documents along with additional text. We examined the earnings reports within the Nifty50 universe, system- atically curated a comprehensive array of randomly selected 400 5https://huggingface.',\n",
       " 'co/datasets/PatronusAI/financebench-testquestions posed during the earnings calls from all the documents, and gathered the exact responses corresponding to these questions. These questions constitute the specific queries articulated by finan- cial analysts to the management during these calls. 4 IMPLEMENTATION DETAILS In this Section, we provide details of implementation of the pro- posed methodology. 4.',\n",
       " '1 Knowledge Graph Construction The initial phase of our approach centers on document preprocess- ing. We utilize the PyPDFLoader6to import PDF documents, which are subsequently segmented into manageable chunks using the RecursiveCharacterTextSplitter. This chunking strategy employs a size of 2024 characters with an overlap of 204 characters, ensuring comprehensive coverage while maintaining context across segment boundaries.',\n",
       " 'Following the preprocessing stage, we implement the two-tiered language model chain for content refinement and information ex- traction. It is not possible to include the exact prompt here due to the limited space, but a baseline prompt can be found in Ref. [18].',\n",
       " 'Entity Type Examples Companies and Corpo- rationsOfficial names, abbreviations, infor- mal references Financial Metrics and IndicatorsRevenue, profit margins, EBITDA Corporate Executives and Key PersonnelCEOs, CFOs, board members Products and Services Tangible products and intangible ser- vices Geographical Locations Headquarters, operational regions, markets Corporate Events Mergers, acquisitions, product launches, earnings calls Legal and Regulatory InformationLegal cases, regulatory compliance Table 2: Entities extracted from earnings call transcripts Table 2 summarizes details on entities extracted from the earn- ing calls transcripts using our prompt based method.',\n",
       " 'Concurrently, LLM identifies relationships between these entities using a curated set of verbs, capturing the nuanced interactions within the cor- porate narrative. A key improvement in our methodology is the enhanced prompt engineering to generate the structured output format for knowledge triplets.',\n",
       " 'Each triplet is represented as a nested list [’h’, ’type’, ’r’, ’o’, ’type’, ’metadata’], where ’h’ and ’o’ denote the head and object entities respectively, ’type’ specifies the entity category, ’r’ represents the relationship, and ’metadata’ encapsu- lates additional contextual information. This format allows for a rich, multidimensional representation of information, facilitating more nuanced downstream analysis. 6https://python.langchain.com/v0.',\n",
       " '1/docs/modules/data_connection/document_ loaders/pdf/Sarmah et al. Our process incorporates several advanced features to enhance the quality and utility of the extracted triplets. Entity disambigua- tion techniques are employed to consolidate different references to the same entity, improving consistency across the KG.',\n",
       " 'We also pri- oritize conciseness in entity representation, aiming for descriptions of less than four words where possible, which aids in maintaining a clean and navigable graph structure. The extraction pipeline is applied iteratively to each document chunk, with results aggregated to form a comprehensive knowledge graph representation of the entire document, allowing for scalable processing of large documents while maintaining local context within each chunk.',\n",
       " 'We have added explicit instruction on obtaining metadata following Ref. [8] for both VectorRAG and GraphRAG. Finally, we implement a data persistence strategy, converting the extracted triplets from their initial string format to Python data structures and storing them in a pickle file. This facilitates easy retrieval and further manipulation of the knowledge graph data in subsequent analysis stages.',\n",
       " 'Our methodology represents a significant advancement in auto- mated knowledge extraction from corporate documents. By com- bining advanced NLP techniques with a structured approach to information representation, we create a rich, queryable knowledge base that captures the complex relationships and key information present in corporate narratives.',\n",
       " 'This approach opens up new pos- sibilities for financial analysis and automated reasoning in the business domain that will be explored further in the future. 4.2 VectorRAG Our methodology builds upon the concept of RAG [ 9] which al- lows for the creation of a system that can provide context-aware, accurate responses to queries about company financial informa- tion, leveraging both the power of large language models and the efficiency of semantic search.',\n",
       " 'At the core of our system is a Pinecone vector database7, which serves as the foundation for our information retrieval process. We employ OpenAI’s text-embedding-ada-002 model to transform tex- tual data from earnings call transcripts into high-dimensional vec- tor representations. This vectorization process enables semantic similarity searches, significantly enhancing the relevance and ac- curacy of retrieved information.',\n",
       " 'Table 3 provides summary of the configuration of the set up in use for our experiments. LLM GPT-3.5-Turbo LLM Temperature 0 Embedding Model text-embedding-ada-002 Framework LangChain Vector Database Pinecone Chunk Size 1024 Chunk Overlap 0 Maximum Output Tokens 1024 Chunks for Similarity Algorithm 20 Number of Context Retrieved 4 Table 3: VectorRAG Configuration 7https://www.pinecone.io/The Q&A pipeline is constructed using the LangChain frame- work8.',\n",
       " 'The begins with a context retrieval step, where we query the Pinecone vector store to obtain the most relevant document chunks for a given question. This retrieval process is fine-tuned with spe- cific filters for quarters, years, and company names, ensuring that the retrieved information is both relevant and current. Following retrieval, we implement a context formatting step that consolidates the retrieved document chunks into a coherent context string.',\n",
       " 'This formatted context serves as the informational basis for the language model’s response generation. We have developed a sophisticated prompt template, that instructs the language model to function as an expert Q&A system, emphasizing the importance of utilizing only the provided context information and avoiding direct references to the context in the generated responses. For the core language processing task, we integrate OpenAI’s GPT-3.',\n",
       " '5-turbo model which processes the formatted context and query to generate natural language responses that are informative, coherent, and contextually appropriate. To evaluate the performance of our system, we developed a comprehensive framework that includes the preparation of a cus- tom dataset of question-answer pairs specific to each company’s earnings call. Our system processes each question in this dataset, generating answers based on the retrieved context.',\n",
       " 'The evaluation results, including the original question, generated answer, retrieved contexts, and ground truth, are compiled into structured formats (CSV and JSON) to facilitate further analysis. The outputs generated by our system are stored in both CSV and JSON formats, enabling easy integration with various analysis tools and dashboards.',\n",
       " 'This approach facilitates both quantitative performance metrics and qualitative assessment of the system’s responses, providing a com- prehensive view of its effectiveness. By parameterizing company names, quarters, and years, we can easily adapt the system to different datasets and time periods. This design choice allows for seamless integration of new data and expansion to cover multiple companies and earnings calls. 4.',\n",
       " '3 GraphRAG For GraphRAG, we developed an Q&A system specifically designed for corporate earnings call transcripts. Our implementation of GraphRAG leverages several key components and techniques: LLM GPT-3.5-Turbo LLM Temperature 0 Framework LangChain KG Manipulation Networkx Chunk Size 1024 Chunk Overlap 0 Number of Triplets 13950 Number of nodes 11405 Number of edges 13883 DFS Depth 1 Table 4: GraphRAG Configuration 8https://docs.smith.langchain.',\n",
       " 'com/old/cookbook/hub-examples/retrieval-qa-chainHybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction Knowledge Graph Construction:- We begin by constructing a KG from a set of knowledge triplets extracted from corporate documents using the prompt engineering based methodology as described in Section 4.1.',\n",
       " 'These triplets, stored in a pickle file, repre- sent structured information in the form of subject-predicate-object relationships. We use the NetworkxEntityGraph class from the LangChain library to create and manage this graph structure. Each triple is added to the graph, which encapsulates the head entity, relation, tail entity, and additional metadata. We implement the Q&A functionality using the GraphQAChain class from LangChain.',\n",
       " 'This chain combines the KG with an LLM (in our case, OpenAI’s GPT-3.5-turbo) to generate responses. The GraphQAChain traverses the KG to find relevant information and uses the language model to formulate coherent answers based on the retrieved context. A summary of configuration of our LLM models and other libraries used for GraphRAG is shown in Table 4.',\n",
       " 'In KG as the information is stored in the form of entities and relationships and there can be multiple relations emanating from one single entity, in this experiment, to extract relevant information from the KG, we employ a depth-first search strategy constrained by a depth of one from the specified entity.',\n",
       " 'To prepare for assessing the performance of our GraphRAG system, we follow the below steps: Dataset Preparation:- We use a pre-generated CSV file containing question-answer pairs specific to the earnings call transcript. Iterative Processing:- For each question in the dataset, we run the GraphQAChain to generate an answer. Result Compilation:- We compile the results, including the origi- nal questions, generated answers, retrieved contexts, and ground truth answers, into a structured format.',\n",
       " 'Finally, the evaluation results are saved in both CSV and JSON formats for further analysis and comparison. We then fed these outputs into our RAG evaluation pipeline. For each Q&A pair in our dataset, we compute all three metrics: faithfulness, answer relevance, context precision and context recall. 4.',\n",
       " '4 HybridRAG For the proposed HybridRAG technique, upon obtaining all the contextual information from VectorRAG and GraphRAG, we con- catenate these contexts to form a unified context utilizing both techniques. This combined context is then fed into the answer gen- erator model to produce a response. The context used for response generation is relatively larger, which affects the precision of the generated response.',\n",
       " 'The context from VectorRAG is appended first, followed by the context from GraphRAG. Consequently, the preci- sion of the generated answer depends on the source context. If the answer is generated from the GraphRAG context, it will have lower precision, as the GraphRAG context is added last in the sequence of contexts provided to the answer generator model, and vice versa. 5 RESULTS We evaluate both the retrieval and generation parts of RAG for the three different RAG pipelines.',\n",
       " 'Evaluating the RAG outputs is also an active area of research there is no standard tool which is universally accepted as of yet, though we use a currently popular framework RAGAS[ 30] to evaluate the three RAG pipelines in thepresent work where we have modified them a bit to make more precise comparisons. The results of our comparative analysis reveal notable differences in performance among VectorRAG, GraphRAG, and HybridRAG approaches as summarized in Table 5.',\n",
       " 'In terms of Faithfulness, GraphRAG and HybridRAG demonstrated superior performance, both achieving a score of 0.96, while VectorRAG trailed slightly with a score of 0.94. Answer relevancy scores varied across the meth- ods, with HybridRAG outperforming the others at 0.96, followed by VectorRAG at 0.91, and GraphRAG at 0.89. Context precision was highest for GraphRAG at 0.96, significantly surpassing Vec- torRAG (0.84) and HybridRAG (0.79).',\n",
       " 'However, in context recall, both VectorRAG and HybridRAG achieved perfect scores of 1, while GraphRAG lagged behind at 0.85. Overall, these results suggest that GraphRAG offers improve- ments over VectorRAG, particularly in faithfulness and context pre- cision. Furthermore, HybridRAG emerges as the most balanced and effective approach, outperforming both VectorRAG and GraphRAG in key metrics such as faithfulness and answer relevancy, while maintaining high context recall.',\n",
       " 'The relatively lower context precision observed for HybridRAG (0.79) can be attributed to its unique approach of combining con- texts from both VectorRAG and GraphRAG methods. While this integration allows for more comprehensive information retrieval, it also introduces additional content that may not align precisely with the ground truth, thus affecting the context precision met- ric.',\n",
       " 'Despite this trade-off, HybridRAG’s superior performance in faithfulness, answer relevancy, and context recall underscores its effectiveness. When considering the overall evaluation metrics, HybridRAG emerges as the most promising approach, balancing high-quality answers with comprehensive context retrieval. Overall GraphRAG performs better in extractive questions com- pared to VectorRAG.',\n",
       " 'And VectorRAG does better in abstractive questions where information is not explicitly mentioned in the raw data. And also GraphRAG sometimes fails to answer ques- tions correctly whenever there is no entity explicitly mentioned in the question. So HybridRAG does a good job overall, as whenever VectorRAG fails to fetch correct context in extractive questions it falls back to GraphRAG to generate the answer.',\n",
       " 'And whenever GraphRAG fails to fetch correct context in abstractive questions it falls back to VectorRAG to generate the answer. VectorRAG GraphRAG HybridRAG F 0.94 0.96 0.96 AR 0.91 0.89 0.96 CP 0.84 0.96 0.79 CR 1 0.85 1 Table 5: Performance Metrics for Different RAG Pipelines. Here, F, AR, CP and CR refer to Faithfulness, Answer Relevence, Context Precision and Context Recall.',\n",
       " '6 CONCLUSION AND FUTURE DIRECTIONS Among the current approaches to mitigate issues regarding infor- mation extraction from external documents that were not part ofSarmah et al. training data for the LLM, Retrieval Augmented Generation (RAG) techniques have emerged as the most popular ones that aim to improve the performance of LLMs by incorporating relevant re- trieval mechanisms.',\n",
       " 'RAG methods enhance the LLMs’ capabilities by retrieving pertinent documents or text to provide additional context during the generation process. However, these approaches encounter significant limitations when applied to the specialized and intricate domain of financial documents. Furthermore, the qual- ity of the retrieved context from a vast and heterogeneous corpus can be inconsistent, leading to inaccuracies and incomplete analyses.',\n",
       " 'These challenges highlight the need for more sophisticated methods that can effectively integrate and process the detailed and domain- specific information found in financial documents, ensuring more reliable and accurate outputs for informed decision-making. In the present work, we have introduced a novel approach that significantly advances the field of information extraction from finan- cial documents through the development of a hybrid RAG system.',\n",
       " 'This system, called HybridRAG, which integrates the strengths of both Knowledge Graphs (KGs) and advanced language models, represents a leap forward in our ability to extract and interpret complex information from unstructured financial texts. The hybrid RAG system, by combining traditional vector-based RAG and KG- based RAG, has shown superior performance in terms of retrieval accuracy and answer generation, marking a pivotal step towards more effective financial analysis tools.',\n",
       " 'Through a comparative analysis using objecive evaluation met- rics, we have highlighted the distinct performance advantages of the HybridRAG approach over its vector-based and KG-based coun- terparts. The HybridRAG system excels in faithfulness, answer relevancy, and context recall, demonstrating the benefits of inte- grating contexts from both VectorRAG and GraphRAG methods, despite potential trade-offs in context precision.',\n",
       " 'The implications of this research extend beyond the immedi- ate realm of financial analysis. By developing a system capable of understanding and responding to nuanced queries about com- plex financial documents, we pave the way for more sophisticated AI-assisted financial decision-making tools that could potentially democratize access to financial insights, allowing a broader range of stakeholders to engage with and understand financial information.',\n",
       " 'Future directions for this research include expanding the system to handle multi-modal inputs, incorporating numerical data analysis capabilities, and developing more sophisticated evaluation metrics that capture the nuances of financial language and the accuracy of numerical information in the responses. Additionally, exploring the integration of this system with real-time financial data streams could further enhance its utility in dynamic financial environments.',\n",
       " '7 ACKNOWLEDGEMENT The views expressed here are those of the authors alone and not of BlackRock, Inc or NVIDIA. We are grateful to Emma Lind for her invaluable support for this collaboration. REFERENCES [1] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. 2013. [2]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need.',\n",
       " 'Advances inneural information processing systems, 30, 2017.[3]Yi Yang, Mark Christopher Siy Uy, and Allen Huang. Finbert: A pretrained language model for financial communications. arXiv preprint arXiv:2006.08097 , 2020. [4]Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Se- bastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann. Bloomberggpt: A large language model for finance. arXiv preprint arXiv:2303.17564, 2023.',\n",
       " '[5] Yuqi Nie, Yaxuan Kong, Xiaowen Dong, John M Mulvey, H Vincent Poor, Qing- song Wen, and Stefan Zohren. A survey of large language models for financial ap- plications: Progress, prospects and challenges. arXiv preprint arXiv:2406.11903 , 2024. [6]Huaqin Zhao, Zhengliang Liu, Zihao Wu, Yiwei Li, Tianze Yang, Peng Shu, Shaochen Xu, Haixing Dai, Lin Zhao, Gengchen Mai, Ninghao Liu, and Tianming Liu. Revolutionizing finance with llms: An overview of applications and insights, 2024.',\n",
       " '[7] Chen Ling, Xujiang Zhao, Jiaying Lu, Chengyuan Deng, Can Zheng, Junxiang Wang, Tanmoy Chowdhury, Yun Li, Hejie Cui, Xuchao Zhang, et al. Domain spe- cialization as the key to make large language models disruptive: A comprehensive survey. arXiv preprint arXiv:2305.18703, 2023. [8] Bhaskarjit Sarmah, Dhagash Mehta, Stefano Pasquali, and Tianjie Zhu. Towards reducing hallucination in extracting information from financial reports using large language models.',\n",
       " 'In Proceedings oftheThird International Conference onAI-ML Systems, pages 1–5, 2023. [9]Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances inNeural Information Processing Systems , 33:9459–9474, 2020. [10] Gautier Izacard and Edouard Grave.',\n",
       " 'Leveraging passage retrieval with generative models for open domain question answering. arXiv preprint arXiv:2007.01282 , 2021. [11] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. Realm: Retrieval-augmented language model pre-training. arXiv preprint arXiv:2002.08909, 2020. [12] Antonio Jose Jimeno Yepes et al. Financial report chunking for effective retrieval augmented generation. arXiv preprint arXiv:2402.05131, 2024. [13] SuperAcc.',\n",
       " 'Retrieval-augmented generation on financial statements. SuperAcc Insights, 2024. [14] Shaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, and S Yu Philip. A survey on knowledge graphs: Representation, acquisition, and applications. IEEE transactions onneural networks andlearning systems, 33(2):494–514, 2021. [15] Heiko Paulheim. Knowledge graphs: State of the art and future directions. Semantic Web Journal, 10(4):1–20, 2017.',\n",
       " '[16] Aidan Hogan, Eva Blomqvist, Michael Cochez, Claudia D’Amato, Gerard de Melo, Claudio Gutiérrez, and Maria ... Maleshkova. Knowledge graphs. arXiv preprint arXiv:2003.02320, 2021. [17] Lisa Ehrlinger and Wolfram Wöß. Towards a definition of knowledge graphs. In SEMANTiCS (Posters, Demos, SuCCESS), pages 1–4, 2016. [18] Xiaohui Victor Li and Francesco Sanna Passino. Findkg: Dynamic knowledge graphs with large language models for detecting global trends in financial mar- kets.',\n",
       " 'arXiv preprint arXiv:2407.10909, 2024. [19] Shourya De, Anima Aggarwal, and Anna Cinzia Squicciarini. Financial knowl- edge graphs: A novel approach to empower data-driven financial applications. In IEEE International Conference onBigData (Big Data), pages 1311–1320, 2018. [20] Marina Petrova and Birgit Reinwald. Knowledge graphs in finance: Applications and opportunities. Journal ofFinancial Data Science, 2(2):10–19, 2020. [21] Wei Liu, Jun Zhang, and Li Pan.',\n",
       " 'Utilizing knowledge graphs for financial data integration and analysis. Data Science Journal, 18(1):1–15, 2019. [22] Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, and Jonathan Larson. From local to global: A graph rag approach to query-focused summarization. arXiv preprint arXiv:2404.16130 , 2024. [23] Xuchen Yao, Yanan Sun, Zhen Huang, and Dong Li. Retrieval-augmented gener- ation for knowledge-intensive nlp tasks. arXiv preprint arXiv:2101.',\n",
       " '07554 , 2021. [24] Weizhi Zhao, Haoyu Chen, Kai Liu, and Jun Zhao. Graph-based retrieval- augmented generation for open-domain question answering. In Proceedings oftheAAAI Conference onArtificial Intelligence , volume 36, pages 3098–3106, 2022. [25] Bill Yuchen Lin, Yuanhe Liu, Ming Shen, and Xiang Ren. Kgpt: Knowledge- grounded pre-training for data-to-text generation. In Findings oftheAssociation forComputational Linguistics: EMNLP 2020, pages 710–724, 2020.',\n",
       " '[26] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Ji- awei Sun, and Haofen Wang. Retrieval-augmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997, 2023. [27] Tyler Procko. Graph retrieval-augmented generation for large language models: A survey. Available atSSRN, 2024. [28] Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, and Xindong Wu. A comprehensive survey on automatic knowledge graph construction.',\n",
       " 'ACM Computing Surveys , 56(4):1–62, 2023.HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction [29] Ishani Mondal, Yufang Hou, and Charles Jochim. End-to-end nlp knowledge graph construction. arXiv preprint arXiv:2106.01167, 2021. [30] Shahul Es, Jithin James, Luis Espinosa-Anke, and Steven Schockaert. Ra- gas: Automated evaluation of retrieval augmented generation. arXiv preprint arXiv:2309.15217, 2023.',\n",
       " '[31] Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan Routledge, et al. Finqa: A dataset of numerical reasoning over financial data. arXiv preprint arXiv:2109.00122, 2021. [32] Macedo Maia, Siegfried Handschuh, André Freitas, Brian Davis, Ross McDermott, Manel Zarrouk, and Alexandra Balahur. Www’18 open challenge: financial opinion mining and question answering.',\n",
       " 'In Companion proceedings ofthetheweb conference 2018, pages 1941–1942, 2018. [33] Fengbin Zhu, Wenqiang Lei, Youcheng Huang, Chao Wang, Shuo Zhang, Jiancheng Lv, Fuli Feng, and Tat-Seng Chua. Tat-qa: A question answering benchmark on a hybrid of tabular and textual content in finance. arXiv preprint arXiv:2105.07624, 2021. [34] Pranab Islam, Anand Kannappan, Douwe Kiela, Rebecca Qian, Nino Scherrer, and Bertie Vidgen. Financebench: A new benchmark for financial question answering.',\n",
       " 'arXiv preprint arXiv:2311.11944, 2023. [35] Jian Chen, Peilin Zhou, Yining Hua, Yingxin Loh, Kehui Chen, Ziyuan Li, Bing Zhu, and Junwei Liang. Fintextqa: A dataset for long-form financial question answering. arXiv preprint arXiv:2405.09980, 2024.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERE_KEY = os.getenv('COHERE_KEY')\n",
    "co = cohere.Client(COHERE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "651"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [chunk for chunk in chunks if len(chunk) > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"embed-english-v3.0\"\n",
    "input_type = \"search_document\"\n",
    "\n",
    "chunk_embeddings = co.embed(\n",
    "    texts = chunks,\n",
    "    model = model,\n",
    "    input_type = input_type,\n",
    "    embedding_types=['float']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Who are the writers?','How are knowledge graphs constructed?','What is knowledge extraction?','What are the evaluation metrics?',\n",
    "             'Which library is used to import pdf documents?','Compare between vector rag and graph rag','Configuration for graphrag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_type = 'search_query'\n",
    "query = questions[-1]\n",
    "query_embedding = co.embed(\n",
    "    texts = [query],\n",
    "    model = model,\n",
    "    input_type = input_type,\n",
    "    embedding_types= ['float']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embedding_floats = chunk_embeddings.embeddings.float\n",
    "query_embedding_float = query_embedding.embeddings.float[0]\n",
    "similarities = []\n",
    "for chunk_embedding_float in chunk_embedding_floats:\n",
    "    similarity = calculate_similarity(chunk_embedding_float,query_embedding_float)\n",
    "    similarities.append(similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_np = np.array(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input prompt for the model\n",
    "prompt = f\"\"\"\n",
    "Use only the context provided to answer the following question. If you don't know the answer say you don't know.\n",
    "Context: {chunks[similarities_np.argmax()]}\n",
    "Question: {query}\n",
    "\"\"\"\n",
    "\n",
    "# Generate text\n",
    "response = co.generate(\n",
    "    model=\"command\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=200,  \n",
    "    temperature=0.2,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm sorry, the provided context did not mention anything about the specific configuration for GraphRAG. Therefore, I don't have any information on this aspect. If there is anything else you would like me to try and answer, please let me know! \n"
     ]
    }
   ],
   "source": [
    "# Access the generated text\n",
    "print(response.generations[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phrases = [\"i love soup\", \"soup is my favorite\", \"london is far away\"]\n",
    "# model = \"embed-english-v3.0\"\n",
    "# input_type = \"search_query\"\n",
    "# res = co.embed(\n",
    "#     texts=phrases,\n",
    "#     model=model,\n",
    "#     input_type=input_type,\n",
    "#     embedding_types=[\"float\"],\n",
    "# )\n",
    "# (soup1, soup2, london) = res.embeddings.float\n",
    "# calculate_similarity(soup1, soup2)  # 0.85 \n",
    "# calculate_similarity(soup1, london) # 0.164789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='llama3.2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
