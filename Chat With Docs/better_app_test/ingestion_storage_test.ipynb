{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = openai.OpenAI(api_key=OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programming\\Python\\AI\\Basics\\AMNIL Tech\\amniltech\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lancedb\n",
    "from lancedb.pydantic import LanceModel, Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate embeddings using OpenAI\n",
    "# text-embedding-ada-002\n",
    "def generate_embeddings(texts):        \n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        response = client.embeddings.create(input=text, model=\"text-embedding-3-small\")\n",
    "        embeddings.append(response.data[0].embedding)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query_embeddings(query):\n",
    "    response = client.embeddings.create(input=query, model=\"text-embedding-ada-002\")\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the LanceDB database\n",
    "db = lancedb.connect(\"mydb\")\n",
    "\n",
    "class KnowledgeBase(LanceModel):\n",
    "    kb_id: str  # Unique knowledge base ID\n",
    "    name: str  # Knowledge base name\n",
    "    description: str  # Optional description\n",
    "    model: str  # Embedding model used\n",
    "\n",
    "class Chunk(LanceModel):\n",
    "    chunk_id: str  # Unique chunk ID\n",
    "    kb_id: str  # Foreign key to `KnowledgeBase`    \n",
    "    text: str  # Chunked text\n",
    "    vector: Vector(1536)  # Embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.drop_all_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table if it doesn't already exist\n",
    "if \"KnowledgeBase\" not in db.table_names():\n",
    "    table = db.create_table(\"KnowledgeBase\", schema=KnowledgeBase)\n",
    "if \"Chunk\" not in db.table_names():\n",
    "    table = db.create_table(\"Chunk\", schema=Chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.auto import partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    }
   ],
   "source": [
    "elements_txt = partition(r\"D:\\Programming\\Python\\AI\\Basics\\AMNIL Tech\\Chat With Docs\\better_app_test\\data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Business intelligence (BI) consists of strategies, methodologies, and technologies used by enterprises for data analysis and management of business information.[1] Common functions of BI technologies include reporting, online analytical processing, analytics, dashboard development, data mining, process mining, complex event processing, business performance management, benchmarking, text mining, predictive analytics, and prescriptive analytics.\\n\\nBI tools can handle large amounts of structured and sometimes unstructured data to help organizations identify, develop, and otherwise create new strategic business opportunities. They aim to allow for the easy interpretation of these big data. Identifying new opportunities and implementing an effective strategy based on insights is assumed to potentially provide businesses with a competitive market advantage and long-term stability, and help them take strategic decisions.[2]\\n\\nBusiness intelligence can be used by enterprises to support a wide range of business decisions ranging from operational to strategic. Basic operating decisions include product positioning or pricing. Strategic business decisions involve priorities, goals, and directions at the broadest level. In all cases, BI is believed to be most effective when it combines data derived from the market in which a company operates (external data) with data from company sources internal to the business such as financial and operations data (internal data). When combined, external and internal data can provide a complete picture which, in effect, creates an \"intelligence\" that cannot be derived from any singular set of data.[3]\\n\\nAmong their many uses, business intelligence tools empower organizations to gain insight into new markets, to assess demand and suitability of products and services for different market segments, and to gauge the impact of marketing efforts.[4]\\n\\nBI applications use data gathered from a data warehouse (DW) or from a data mart, and the concepts of BI and DW combine as \"BI/DW\"[5] or as \"BIDW\". A data warehouse contains a copy of analytical data that facilitates decision support.\\n\\nHistory The earliest known use of the term business intelligence is in Richard Millar Devens\\' Cyclopædia of Commercial and Business Anecdotes (1865). Devens used the term to describe how the banker Sir Henry Furnese gained profit by receiving and acting upon information about his environment, prior to his competitors:\\n\\nThroughout Holland, Flanders, France, and Germany, he maintained a complete and perfect train of business intelligence. The news of the many battles fought was thus received first by him, and the fall of Namur added to his profits, owing to his early receipt of the news.\\n\\n—\\u200aDevens, p. 210 The ability to collect and react accordingly based on the information retrieved, Devens says, is central to business intelligence.[6]\\n\\nWhen Hans Peter Luhn, a researcher at IBM, used the term business intelligence in an article published in 1958, he employed the Webster\\'s Dictionary definition of intelligence: \"the ability to apprehend the interrelationships of presented facts in such a way as to guide action towards a desired goal.\"[7]\\n\\nIn 1989, Howard Dresner (later a Gartner analyst) proposed business intelligence as an umbrella term to describe \"concepts and methods to improve business decision making by using fact-based support systems.\"[8] It was not until the late 1990s that this usage was widespread.['"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\n\\n\".join([str(el) for el in elements_txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_img = partition(r\"D:\\Programming\\Python\\AI\\Basics\\AMNIL Tech\\Chat With Docs\\better_app_test\\test_img.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = partition(r\"D:\\Programming\\Python\\AI\\Basics\\AMNIL Tech\\Chat With Docs\\better_app_test\\energy.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHAPTER 3- PART 2\\n\\n1. Hydrogen Introduction\\n\\nThe electrical energy is the most convenient form of energy as it can be easily transported, controlled and converted to other useful forms. However, the major shortcoming of the electrical energy is its inability to be stored in large quantities. To address this shortcoming hydrogen fuel can be phenomenal. Hydrogen fuel can be stored in large quantities but has risk of being highly inflammable and requires special handling methods for safety concerns. Hydrogen is a secondary fuel that requires primary energy sources for production. Hydrogen can be produced from any energy source such as solar or hydro power. Also organic materials such as plants and fossil fuels are also source of hydrogen (Singal, 2011).\\n\\nHydrogen can be stored in compressed form in high pressure, It can also be stored in liquid form in low temperatures. Hydrogen form hydrides with various metals which can also be used to store and recover hydrogen as required. Hydrogen has the benefit of having high energy content per unit mass. It can be used as fuel directly in gas turbine or spark ignition engines. It can be used as fuel for transportation of vehicles which also reduces the problem of pollution. Hydrogen can be used in fuel cell to produce electricity. Hence the scope and potential of hydrogen is huge and is increasing at rapid rate in the world.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\n\\n\".join([str(el) for el in elements_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\\n\\n\".join([str(el) for el in elements])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create an instance of RecursiveCharacterTextSplitter\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Define the chunk size\n",
    "    chunk_overlap=100,  # Define the overlap size\n",
    "    length_function=len  # Defines how length is measured\n",
    ")\n",
    "with open('data.txt','r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "#Split the document into chunks\n",
    "chunks = recursive_splitter.split_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_chunks = generate_embeddings(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1536)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(embedded_chunks).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = db.open_table(\"KnowledgeBase\")\n",
    "table.create_fts_index(\"name\", use_tantivy=False,replace=True)\n",
    "table.search(\"DWBI\",vector_column_name='name').select([\"kb_id\"]).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_chunks(chunks, embedded_chunks,KB_NAME,model):\n",
    "    kb_table = db.open_table('KnowledgeBase')\n",
    "    kb_table.create_fts_index(\"name\", use_tantivy=False,replace=True)\n",
    "    existing_kb = kb_table.search(KB_NAME,vector_column_name='name').select([\"kb_id\"]).to_list()\n",
    "    if existing_kb:\n",
    "        print(f\"Knowledge base '{KB_NAME}' already exists.\")\n",
    "    else:    \n",
    "        kb_id=str(uuid.uuid4())\n",
    "        # Create a new knowledge base\n",
    "        kb_table.add([KnowledgeBase(\n",
    "            kb_id=kb_id,\n",
    "            name=KB_NAME,\n",
    "            description=\"A knowledge base for DWBI\",\n",
    "            model=model\n",
    "        )])\n",
    "        chunk_table = db.open_table('Chunk')\n",
    "        # Save each chunk and its vector into LanceDB\n",
    "        for chunk, embedding in zip(chunks, embedded_chunks):\n",
    "            padded_vector = np.pad(embedding, (0, 1536 - len(embedding)), 'constant', constant_values=0)\n",
    "            chunk_table.add([Chunk(chunk_id=str(uuid.uuid4()),kb_id=kb_id,text=chunk, vector=padded_vector)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_chunks(chunks, embedded_chunks,KB_NAME='DWBI',model=\"embed-english-v3.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kb_id(KB_NAME):\n",
    "    try:\n",
    "        table = db.open_table(\"KnowledgeBase\")\n",
    "        table.create_fts_index(\"name\", use_tantivy=False,replace=True)\n",
    "        return table.search(KB_NAME,vector_column_name='name').select([\"kb_id\"]).to_list()[0]['kb_id']    \n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_KB(KB_NAME):    \n",
    "    kb_id = get_kb_id(KB_NAME)\n",
    "    if kb_id is None:\n",
    "        return None\n",
    "    kb_table = db.open_table(\"Chunk\")\n",
    "    kb_table.create_fts_index(\"kb_id\", use_tantivy=False,replace=True)\n",
    "    chunk_df = kb_table.search(kb_id,vector_column_name='kb_id').select([\"chunk_id\",\"kb_id\",\"text\",\"vector\"]).to_pandas()    \n",
    "    return chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(query,chunk_df):\n",
    "    embedded_query = generate_query_embeddings(query) \n",
    "    chunk_df['similarity'] = chunk_df.apply(lambda x: calculate_similarity(embedded_query,x.iloc[3]),axis=1)    \n",
    "    df_top = chunk_df[chunk_df['similarity'] > chunk_df['similarity'].quantile(0.8)]      \n",
    "    context = ''\n",
    "    for txt in df_top['text']:\n",
    "        context+=txt\n",
    "        context+='\\n'\n",
    "    prompt = f\"\"\"\n",
    "    \"QUESTION:\" {query}\\n\n",
    "    \"CONTEXT:\" {context}\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt):\n",
    "    premable = 'You are a friendly bot. Don\\'t ask for extra context. Read the \"QUESTION:\" and reply. If the question demands some information, answer the question provided as \"QUESTION:\" using the context provided as \"CONTEXT:\" If the answer is not present, say you don\\'t know.'\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", \n",
    "        messages=[{'role':'system','content':premable},{'role':'user','content':prompt}],\n",
    "        max_tokens=150,  # You can adjust the max tokens based on your needs\n",
    "        temperature=0.5,  # Adjust temperature for randomness (optional)\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(KB_NAME,query):\n",
    "    chunk_df = retrieve_KB(KB_NAME)\n",
    "    if chunk_df is None:\n",
    "        return 'No Knowledge base found.'\n",
    "    chunk_df.drop(columns=['_score'],inplace=True)\n",
    "    prompt = generate_prompt(query,chunk_df)    \n",
    "    response = generate_response(prompt)    \n",
    "    generated_text = response.choices[0].message.content\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BI applications get their data from large amounts of structured and sometimes unstructured data.'"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond('DWBI',\"Where do BI applications get their data?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df = retrieve_KB('DWBI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amniltech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
